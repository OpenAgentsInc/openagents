# Adjutant

The agent that DOES THE WORK. Named after StarCraft's command & control AI.

## Overview

Adjutant is the core execution engine for autonomous coding tasks. It:
- Analyzes tasks to determine complexity and relevant files
- Uses tools directly (Read, Edit, Bash, Glob, Grep)
- Employs tiered inference for cost-effective execution
- Delegates to Claude Code for highly complex tasks

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AUTOPILOT CLI                          â”‚
â”‚  (user-facing: `autopilot run`, `autopilot issue claim`)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OANIX (background)                        â”‚
â”‚  (discovers environment, reads .openagents/)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ADJUTANT                              â”‚
â”‚  The actual agent that DOES THE WORK                        â”‚
â”‚  - Prioritizes Claude (Pro/Max) via claude-agent-sdk        â”‚
â”‚  - Falls back to Cerebras TieredExecutor                    â”‚
â”‚  - Uses tools directly (Read, Edit, Bash, Glob, Grep)       â”‚
â”‚  - Uses RLM for large context analysis                      â”‚
â”‚  - Delegates to Claude Code for very complex work           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

```bash
# Set Cerebras API key for AI-powered execution
export CEREBRAS_API_KEY="csk-your-key-here"

# Run a task (fast boot skips network/compute discovery)
cargo autopilot run "Add error handling to auth.rs"

# Full environment scan (slower)
cargo autopilot run "Add error handling to auth.rs" --full-boot

# Claim and work on a GitHub issue
cargo autopilot issue claim 123
```

### CLI Streaming Output

`autopilot run` streams the same ACP event flow used by the desktop app, formatted as concise CLI lines:

```
[DSPY] planning: complexity=Medium confidence=82%
[DSPY] files: src/auth.rs
[TOOL] start bash: command=rg "auth" src
[TOOL] done bash ok
[AI] Updated error handling and added tests.
```

Verbose logs (stderr) are opt-in via `RUST_LOG`:

```bash
RUST_LOG=adjutant=info cargo autopilot run "Summarize README.md"
```

## Execution Flow

1. **Planning**: Analyzes task, finds relevant files, estimates complexity
2. **DSPy Complexity Override**: If LM available and confidence > 0.7, uses DSPy classification
3. **DSPy Routing Decisions**:
   - `determine_use_rlm()` - Should RLM be used? (DSPy-first with fallback)
   - `determine_delegation()` - Should task be delegated? Where? (DSPy-first with fallback)
4. **Execution**: Runs the task using chosen strategy (priority order):
   - **Claude Pro/Max** (if `claude` CLI is installed) - Best quality, uses subscription
   - **Cerebras TieredExecutor** (if CEREBRAS_API_KEY set) - Cost-effective tiered inference
   - **Analysis-only** - Returns file analysis without making changes
5. **Synthesis**: Summarizes results, optionally commits changes
6. **Training Collection**: Records high-confidence DSPy decisions for optimization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Adjutant.execute() Flow                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. plan_task()                                             â”‚
â”‚     â””â”€â”€ Rule-based file discovery, initial complexity       â”‚
â”‚                                                              â”‚
â”‚  2. determine_complexity_dspy() [DSPy-first]                â”‚
â”‚     â””â”€â”€ Override complexity if confidence > 0.7             â”‚
â”‚                                                              â”‚
â”‚  3. determine_use_rlm() [DSPy-first]                        â”‚
â”‚     â””â”€â”€ RLM for large context analysis?                     â”‚
â”‚                                                              â”‚
â”‚  4. LM Provider Selection                                   â”‚
â”‚     â”œâ”€â”€ LlamaCpp â†’ execute_with_local_lm()                  â”‚
â”‚     â””â”€â”€ ClaudeSdk â†’ ClaudeExecutor (with optional RLM)      â”‚
â”‚                                                              â”‚
â”‚  5. determine_delegation() [DSPy-first]                     â”‚
â”‚     â”œâ”€â”€ claude_code â†’ delegate_to_claude_code()             â”‚
â”‚     â”œâ”€â”€ rlm â†’ execute_with_rlm_delegate()                   â”‚
â”‚     â””â”€â”€ local_tools â†’ execute_with_tools()                  â”‚
â”‚                                                              â”‚
â”‚  6. Legacy Fallback Rules (if DSPy confidence low)          â”‚
â”‚     â”œâ”€â”€ complexity >= High â†’ delegate                       â”‚
â”‚     â””â”€â”€ tokens > 100k â†’ RLM                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Execution Priority

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Execution Priority                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Claude CLI detected?  â”€â”€YESâ”€â”€â–º  ClaudeExecutor          â”‚
â”‚           â”‚                         (Pro/Max subscription)   â”‚
â”‚           NO                                                 â”‚
â”‚           â–¼                                                  â”‚
â”‚  2. CEREBRAS_API_KEY set? â”€â”€YESâ”€â”€â–º  TieredExecutor          â”‚
â”‚           â”‚                         (GLM 4.7 + Qwen-3-32B)   â”‚
â”‚           NO                                                 â”‚
â”‚           â–¼                                                  â”‚
â”‚  3. Fall back to analysis-only mode                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Components

### Task

```rust
pub struct Task {
    pub id: String,          // e.g., "#123" for issues
    pub title: String,
    pub description: String,
    pub files: Vec<PathBuf>, // Optional hints
    pub acceptance_criteria: Vec<String>,
}
```

### Complexity Levels

| Level | Characteristics | Strategy |
|-------|----------------|----------|
| `Low` | Single file, simple edit | TieredExecutor |
| `Medium` | Multi-file, moderate scope | TieredExecutor |
| `High` | Complex refactoring, many files | TieredExecutor or delegate |
| `VeryHigh` | Architectural changes, 30+ files | Claude Code delegation |

### Tools

Adjutant uses these core tools:

| Tool | Description |
|------|-------------|
| `Read` | Read file contents |
| `Edit` | Replace old_string with new_string |
| `Write` | Create new files |
| `Bash` | Execute shell commands |
| `Glob` | Find files by pattern |
| `Grep` | Search file contents (uses ripgrep if available) |

## Tiered Inference

Adjutant uses a two-tier model architecture for cost-effective execution:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PLANNING LAYER                          â”‚
â”‚              Cerebras GLM 4.7 (smart, $2.25/M)             â”‚
â”‚  "Break this task into subtasks, decide what to do"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SUBTASK 1  â”‚   â”‚  SUBTASK 2  â”‚   â”‚  SUBTASK 3  â”‚
â”‚  qwen-3-32b â”‚   â”‚  qwen-3-32b â”‚   â”‚  qwen-3-32b â”‚
â”‚  ($0.15/M)  â”‚   â”‚  ($0.15/M)  â”‚   â”‚  ($0.15/M)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **GLM 4.7**: Smart model for planning/orchestration and synthesis
- **Qwen-3-32B**: Cheaper model for subtask execution

See [TIERED-EXECUTOR.md](./TIERED-EXECUTOR.md) for detailed documentation.

## DSPy Integration

Adjutant integrates with [dsrs](../../dsrs/) (Rust DSPy implementation) for optimizable prompt engineering:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TieredExecutor                          â”‚
â”‚                                                              â”‚
â”‚  ExecutionMode::Gateway â”€â”€â–º Original hardcoded prompts       â”‚
â”‚  ExecutionMode::Dsrs    â”€â”€â–º Optimizable DSPy signatures      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Features

- **Typed Signatures**: Replace string prompts with `#[Signature]` structs
- **Automatic Optimization**: MIPROv2 improves prompts from training data
- **Training Collection**: Records successful executions and decisions for optimization
- **Evaluation Metrics**: Quantitative assessment of output quality
- **Decision Pipelines**: DSPy-first routing for complexity, delegation, and RLM decisions
- **LM Caching**: Lazy initialization and caching of decision LM for efficiency

### Quick Start

```rust
use adjutant::{Task, TieredExecutor, ExecutionMode, ToolRegistry};

// Create DSPy-powered executor
let mut executor = TieredExecutor::with_mode(ExecutionMode::Dsrs)?;

// Execute with training collection
let result = executor.execute_dsrs(&task, &context, &mut tools).await?;
```

### Signatures

**Task Execution Signatures:**

| Signature | Replaces | Purpose |
|-----------|----------|---------|
| `SubtaskPlanningSignature` | `PLANNER_SYSTEM_PROMPT` | Break tasks into subtasks |
| `SubtaskExecutionSignature` | `EXECUTOR_SYSTEM_PROMPT` | Execute individual subtasks |
| `ResultSynthesisSignature` | `SYNTHESIZER_SYSTEM_PROMPT` | Synthesize final results |

**Decision Pipeline Signatures:**

| Signature | Purpose | Fallback |
|-----------|---------|----------|
| `ComplexityClassificationSignature` | Classify task complexity (Low/Medium/High/VeryHigh) | Rule-based heuristics |
| `DelegationDecisionSignature` | Decide if/where to delegate (claude_code/rlm/local_tools) | Complexity thresholds |
| `RlmTriggerSignature` | Decide if RLM should be used | Token count + keywords |

Decision pipelines use a 0.7 confidence threshold - below that, they fall back to legacy rule-based logic.

See [DSPY-INTEGRATION.md](./DSPY-INTEGRATION.md) for detailed documentation.

## Configuration

### Execution Backends

**Priority 1: Claude Pro/Max** (Recommended)

Install the Claude CLI to use your existing Claude subscription:
```bash
# Install Claude CLI (see https://claude.ai/claude-code)
# Then authenticate:
claude auth login
```

**Priority 2: Cerebras API**

Set the API key for tiered inference:
```bash
export CEREBRAS_API_KEY="csk-your-key-here"
```

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `CEREBRAS_API_KEY` | No | Cerebras API key for tiered inference |
| `PYLON_MNEMONIC` | No | BIP-39 mnemonic for Pylon Swarm inference |
| `ADJUTANT_ENABLE_RLM` | No | Enable RLM tools in Claude sessions (1/true) |
| `RLM_BACKEND` | No | RLM backend selection (claude) |

### LM Provider Priority

Adjutant auto-detects available LM providers in this priority order:

| Priority | Provider | Requirements | Use Case |
|----------|----------|--------------|----------|
| 1 | **LlamaCpp** | `llama-server` on :8080 | Local execution with GPT-OSS |
| 2 | **Claude SDK** | `claude` CLI installed | Pro/Max subscription |
| 3 | **Pylon Swarm** | `PYLON_MNEMONIC` env var | Distributed NIP-90 inference |
| 4 | **Cerebras** | `CEREBRAS_API_KEY` env var | Fast cloud inference |
| 5 | **Pylon Local** | Ollama on :11434 | Local Ollama fallback |

*Without any provider, Adjutant falls back to analysis-only mode.

### .env.local

```bash
# Store in .env.local (auto-loaded)
CEREBRAS_API_KEY="csk-your-key-here"
```

Get your Cerebras API key at: https://cloud.cerebras.ai

## Fallback Behavior

If Cerebras is not configured:
1. Adjutant still analyzes the task and finds relevant files
2. Returns summary with file count and estimated tokens
3. Suggests setting CEREBRAS_API_KEY for AI-powered execution

## Delegation

For very complex tasks, Adjutant delegates to Claude Code:

```rust
// When complexity >= VeryHigh or files > 20
if plan.complexity >= Complexity::High || plan.files.len() > 20 {
    return self.delegate_to_claude_code(task).await;
}

// When context is too large
if plan.estimated_tokens > 100_000 {
    return self.execute_with_rlm(task, &plan).await;
}
```

## Module Structure

```
crates/adjutant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs           # Main Adjutant struct, LM caching, decision routing
â”‚   â”œâ”€â”€ planner.rs       # Task analysis and planning
â”‚   â”œâ”€â”€ executor.rs      # Task execution coordination
â”‚   â”œâ”€â”€ claude_executor.rs # Claude Pro/Max execution via SDK
â”‚   â”œâ”€â”€ rlm_agent.rs     # RLM custom agent definition
â”‚   â”œâ”€â”€ tiered.rs        # TieredExecutor (Gateway + DSPy modes)
â”‚   â”œâ”€â”€ delegate.rs      # Claude Code and RLM delegation
â”‚   â”œâ”€â”€ tools.rs         # Tool registry (Read, Edit, Bash, etc.)
â”‚   â”œâ”€â”€ auth.rs          # Claude CLI detection
â”‚   â”œâ”€â”€ autopilot_loop.rs # Autonomous loop with session tracking
â”‚   â”œâ”€â”€ cli/             # CLI commands
â”‚   â”‚   â”œâ”€â”€ mod.rs            # Command routing
â”‚   â”‚   â”œâ”€â”€ run.rs            # autopilot run
â”‚   â”‚   â”œâ”€â”€ status.rs         # autopilot status
â”‚   â”‚   â”œâ”€â”€ issue.rs          # autopilot issue
â”‚   â”‚   â””â”€â”€ dspy.rs           # autopilot dspy (sessions, performance, auto-optimize)
â”‚   â”œâ”€â”€ dspy/            # DSPy integration + self-improvement
â”‚   â”‚   â”œâ”€â”€ mod.rs            # Module exports
â”‚   â”‚   â”œâ”€â”€ lm_config.rs      # Multi-provider LM configuration
â”‚   â”‚   â”œâ”€â”€ module.rs         # AdjutantModule + task execution signatures
â”‚   â”‚   â”œâ”€â”€ decision_pipelines.rs # Decision routing signatures
â”‚   â”‚   â”œâ”€â”€ metrics.rs        # Evaluation metrics for MIPROv2
â”‚   â”‚   â”œâ”€â”€ training.rs       # Training data collection
â”‚   â”‚   â”œâ”€â”€ sessions.rs       # Session tracking (AutopilotSession, DecisionRecord)
â”‚   â”‚   â”œâ”€â”€ outcome_feedback.rs # Links outcomes to decision correctness
â”‚   â”‚   â”œâ”€â”€ performance.rs    # Rolling accuracy tracking per signature
â”‚   â”‚   â””â”€â”€ auto_optimizer.rs # Auto-triggers MIPROv2 optimization
â”‚   â””â”€â”€ bin/main.rs      # Autopilot binary entry point
â””â”€â”€ docs/
    â”œâ”€â”€ README.md            # This file
    â”œâ”€â”€ TIERED-EXECUTOR.md   # Tiered inference details
    â””â”€â”€ DSPY-INTEGRATION.md  # DSPy integration guide
```

## RLM Integration

Adjutant integrates with the RLM (Recursive Language Model) crate for complex analysis tasks:

### When RLM Mode is Used

RLM mode is automatically enabled when:
- Task complexity is `High` or higher
- Estimated tokens exceed 50,000
- Task description contains keywords: analyze, recursive, investigate, security, audit, review, deep dive, comprehensive

### RLM Custom Agent

Adjutant defines an `rlm-analyzer` custom agent for Claude:

```rust
// Read-only analysis agent
rlm_agent_definition() -> AgentDefinition

// Agent with write access (use with caution)
rlm_agent_with_write_access() -> AgentDefinition
```

The RLM agent follows the DECOMPOSE â†’ EXECUTE â†’ VERIFY â†’ ITERATE â†’ SYNTHESIZE pattern:
1. Breaks problems into verifiable sub-questions
2. Executes Python code to gather evidence
3. Verifies hypotheses against execution results
4. Iterates until confident answer is reached

### RLM MCP Tools

When executing with RLM support, Claude has access to:

| Tool | Description |
|------|-------------|
| `rlm_query` | Deep recursive analysis using prompt-execute loop |
| `rlm_fanout` | Distribute query across multiple workers (local/swarm/datacenter) |

Enable via environment variable:
```bash
export ADJUTANT_ENABLE_RLM=1
```

### Configuration

```bash
# Enable RLM tools in Claude sessions
export ADJUTANT_ENABLE_RLM=1

# Control RLM backend (optional)
export RLM_BACKEND=claude  # Use Claude as RLM LlmClient
```

## Coder Integration

Adjutant is the execution engine behind Coder's **Autopilot mode**. When you switch to Autopilot in Coder, it runs Adjutant in an **autonomous loop** until the task is complete:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Coder Autopilot Loop                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User: "Fix the auth bug"                                    â”‚
â”‚        â†“                                                     â”‚
â”‚  --- Iteration 1/10 ---                                      â”‚
â”‚  [Adjutant analyzes, identifies issue]                       â”‚
â”‚        â†“                                                     â”‚
â”‚  --- Iteration 2/10 ---                                      â”‚
â”‚  [Adjutant applies fix]                                      â”‚
â”‚  ğŸ” Verifying...                                             â”‚
â”‚    cargo check... OK                                         â”‚
â”‚    cargo test... FAILED                                      â”‚
â”‚  âš  Verification failed, continuing...                       â”‚
â”‚        â†“                                                     â”‚
â”‚  --- Iteration 3/10 ---                                      â”‚
â”‚  [Adjutant fixes failing test]                               â”‚
â”‚  ğŸ” Verifying...                                             â”‚
â”‚    cargo check... OK                                         â”‚
â”‚    cargo test... OK                                          â”‚
â”‚  âœ“ Verification passed                                       â”‚
â”‚  âœ“ Task completed                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Features

- **Autonomous Loop**: Keeps calling Adjutant until task succeeds or max iterations (10) reached
- **Verification**: After LLM reports success, runs `cargo check` + `cargo test` to verify
- **Interrupt**: Press Escape to stop the loop cleanly
- **Iteration Context**: Each iteration gets context from previous attempts

See `crates/adjutant/src/autopilot_loop.rs` for the implementation.

## Self-Improving Autopilot

The autopilot system now includes autonomous self-improvement capabilities. After each session completes, the system:

1. **Records Session Data** - Tracks all decisions made (complexity, delegation, RLM)
2. **Labels Decisions** - Links task outcomes to decision correctness
3. **Updates Performance** - Maintains rolling accuracy per signature type
4. **Triggers Optimization** - Auto-triggers MIPROv2 when accuracy drops or examples accumulate

```
Task Execution â†’ Session Recorded â†’ Decisions Labeled â†’ Performance Updated
                                                              â†“
                           Triggers Met? â†’ Auto-Optimize â†’ Better Decisions
```

### CLI Commands

```bash
# View recent sessions
autopilot dspy sessions
autopilot dspy sessions --failed  # Only failed sessions
autopilot dspy sessions --limit 20

# View performance metrics
autopilot dspy performance

# Configure auto-optimization
autopilot dspy auto-optimize --enable
autopilot dspy auto-optimize --min-examples 20
autopilot dspy auto-optimize --accuracy-threshold 0.7
```

### Auto-Optimization Triggers

Optimization is automatically triggered when:
- **Example Threshold**: 20+ new labeled examples accumulate (default)
- **Accuracy Drop**: Rolling accuracy drops below 70% (default)
- **Time-Based**: At least 24 hours since last optimization (default)

### Storage Layout

```
~/.openagents/adjutant/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ dataset.json           # Training examples
â”‚   â””â”€â”€ labeled/               # Labeled examples with outcomes
â”‚       â”œâ”€â”€ complexity.json
â”‚       â”œâ”€â”€ delegation.json
â”‚       â””â”€â”€ rlm_trigger.json
â”œâ”€â”€ sessions/
â”‚   â”œâ”€â”€ index.json             # Session index
â”‚   â””â”€â”€ <year>/<month>/<id>.json
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ performance.json       # Rolling accuracy data
â””â”€â”€ config/
    â””â”€â”€ auto_optimizer.json    # Auto-optimization settings
```

### Decision Correctness Logic

| Decision | Correct When |
|----------|--------------|
| Complexity | Task succeeded within expected iterations for that level |
| Delegation | Task succeeded (delegated failures are less "wrong") |
| RLM Trigger | Task succeeded; or large context + RLM used |

See [DSPY-INTEGRATION.md](./DSPY-INTEGRATION.md) for detailed documentation.

## See Also

- [TIERED-EXECUTOR.md](./TIERED-EXECUTOR.md) - Detailed tiered inference documentation
- [DSPY-INTEGRATION.md](./DSPY-INTEGRATION.md) - DSPy integration and optimization guide
- [../../dsrs/README.md](../../dsrs/README.md) - dsrs (Rust DSPy) documentation
- [../../gateway/docs/README.md](../../gateway/docs/README.md) - Gateway crate (Cerebras integration)
- [../../oanix/README.md](../../oanix/README.md) - OANIX environment discovery
- [../../coder/docs/ROADMAP.md](../../coder/docs/ROADMAP.md) - Coder implementation roadmap
