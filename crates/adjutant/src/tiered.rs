//! Tiered inference executor.
//!
//! Uses Cerebras GLM 4.7 for planning/orchestration, Qwen-3-32B for subtask execution.
//! This provides a cost-effective approach: smart model for planning, cheaper model for work.

use crate::dspy::{
    AdjutantModule, ExecutionTrainingExample, PlanningTrainingExample, SubtaskData,
    SynthesisTrainingExample, TrainingCollector,
};
use crate::{AdjutantError, Task, TaskResult, ToolRegistry};
use gateway::{CerebrasGateway, ChatRequest, InferenceGateway, Message};
use serde::{Deserialize, Serialize};
use std::sync::Arc;

/// Execution mode for the tiered executor.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum ExecutionMode {
    /// Use the original gateway-based execution (legacy fallback).
    Gateway,
    /// Use dsrs-powered execution with optimizable signatures.
    #[default]
    Dsrs,
}

/// Models for different tiers
const PLANNING_MODEL: &str = "zai-glm-4.7"; // Smart, for planning
const EXECUTION_MODEL: &str = "qwen-3-32b"; // Cheaper, for subtasks

/// A subtask generated by the planner.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Subtask {
    /// Subtask ID
    pub id: String,
    /// Action type: read, edit, bash
    pub action: String,
    /// Target file or path
    pub target: String,
    /// Instruction for what to do
    pub instruction: String,
}

/// Plan generated by the planning phase.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TieredPlan {
    /// List of subtasks to execute
    pub subtasks: Vec<Subtask>,
}

/// Result of a single subtask.
#[derive(Debug, Clone)]
pub struct SubtaskResult {
    /// Subtask ID
    pub id: String,
    /// Whether it succeeded
    pub success: bool,
    /// Output or result
    pub output: String,
    /// Error message if failed
    pub error: Option<String>,
}

/// Tiered executor that uses different models for planning vs execution.
pub struct TieredExecutor {
    /// Single Cerebras gateway, uses different models
    gateway: Arc<CerebrasGateway>,
    /// Execution mode (Gateway or Dsrs)
    mode: ExecutionMode,
    /// DSPy module for optimizable execution
    dsrs_module: Option<AdjutantModule>,
    /// Training data collector
    training_collector: Option<TrainingCollector>,
}

impl TieredExecutor {
    /// Create a new tiered executor with default (Gateway) mode.
    pub fn new() -> Result<Self, AdjutantError> {
        Self::with_mode(ExecutionMode::Gateway)
    }

    /// Create a tiered executor with a specific execution mode.
    pub fn with_mode(mode: ExecutionMode) -> Result<Self, AdjutantError> {
        let gateway = CerebrasGateway::from_env().map_err(|e| {
            AdjutantError::ExecutionFailed(format!("Failed to create gateway: {}", e))
        })?;

        let (dsrs_module, training_collector) = match mode {
            ExecutionMode::Dsrs => {
                let collector = TrainingCollector::new(true).map_err(|e| {
                    AdjutantError::ExecutionFailed(format!(
                        "Failed to create training collector: {}",
                        e
                    ))
                })?;
                (Some(AdjutantModule::new()), Some(collector))
            }
            ExecutionMode::Gateway => (None, None),
        };

        Ok(Self {
            gateway: Arc::new(gateway),
            mode,
            dsrs_module,
            training_collector,
        })
    }

    /// Get the current execution mode.
    pub fn mode(&self) -> ExecutionMode {
        self.mode
    }

    /// Execute a task using tiered inference.
    ///
    /// Routes to DSPy-powered execution (default) or gateway-based execution
    /// based on the configured mode. DSPy execution enables optimizable
    /// signatures and training data collection for MIPROv2 optimization.
    pub async fn execute(
        &mut self,
        task: &Task,
        context: &str,
        tools: &mut ToolRegistry,
    ) -> Result<TaskResult, AdjutantError> {
        match self.mode {
            ExecutionMode::Dsrs => {
                // Try DSPy-powered execution first
                match self.execute_dsrs(task, context, tools).await {
                    Ok(result) => Ok(result),
                    Err(e) => {
                        // Fallback to gateway if DSPy fails
                        tracing::warn!("DSPy execution failed, falling back to gateway: {}", e);
                        self.execute_gateway(task, context, tools).await
                    }
                }
            }
            ExecutionMode::Gateway => self.execute_gateway(task, context, tools).await,
        }
    }

    /// Execute a task using gateway-based inference (legacy path).
    async fn execute_gateway(
        &self,
        task: &Task,
        context: &str,
        tools: &mut ToolRegistry,
    ) -> Result<TaskResult, AdjutantError> {
        tracing::info!("TieredExecutor (Gateway): Starting task '{}'", task.title);

        // PHASE 1: Plan with GLM 4.7 (smart)
        tracing::info!("Phase 1: Planning with {}", PLANNING_MODEL);
        let plan = self.plan_task(task, context).await?;
        tracing::info!("Generated {} subtasks", plan.subtasks.len());

        if plan.subtasks.is_empty() {
            return Ok(TaskResult {
                success: true,
                summary:
                    "No subtasks generated - task may already be complete or no changes needed."
                        .to_string(),
                modified_files: Vec::new(),
                commit_hash: None,
                error: None,
                session_id: None,
            });
        }

        // PHASE 2: Execute subtasks with Qwen-3-32B (cheap)
        tracing::info!("Phase 2: Executing subtasks with {}", EXECUTION_MODEL);
        let results = self.execute_subtasks(&plan.subtasks, tools).await?;

        // PHASE 3: Synthesize with GLM 4.7 (smart)
        tracing::info!("Phase 3: Synthesizing results with {}", PLANNING_MODEL);
        let result = self.synthesize_results(task, &results).await?;

        Ok(result)
    }

    /// Use GLM 4.7 to break task into subtasks.
    async fn plan_task(&self, task: &Task, context: &str) -> Result<TieredPlan, AdjutantError> {
        let request = ChatRequest::new(
            PLANNING_MODEL,
            vec![
                Message::system(PLANNER_SYSTEM_PROMPT),
                Message::user(format!(
                    "Task: {}\n\nDescription: {}\n\nContext:\n{}",
                    task.title, task.description, context
                )),
            ],
        )
        .with_max_tokens(2000);

        let response = self
            .gateway
            .chat(request)
            .await
            .map_err(|e| AdjutantError::ExecutionFailed(format!("Planning failed: {}", e)))?;

        let content = response.content().unwrap_or("{}");
        parse_task_plan(content)
    }

    /// Execute subtasks sequentially (parallel would need careful tool handling).
    async fn execute_subtasks(
        &self,
        subtasks: &[Subtask],
        tools: &mut ToolRegistry,
    ) -> Result<Vec<SubtaskResult>, AdjutantError> {
        let mut results = Vec::new();

        for subtask in subtasks {
            tracing::info!(
                "Executing subtask {}: {} on {}",
                subtask.id,
                subtask.action,
                subtask.target
            );
            let result = self.execute_single_subtask(subtask, tools).await?;
            results.push(result);
        }

        Ok(results)
    }

    /// Execute a single subtask with Qwen-3-32B.
    async fn execute_single_subtask(
        &self,
        subtask: &Subtask,
        tools: &mut ToolRegistry,
    ) -> Result<SubtaskResult, AdjutantError> {
        // First, get context if it's a file operation
        let target_path = std::path::Path::new(&subtask.target);
        let file_context = if subtask.action == "edit" || subtask.action == "read" {
            let read_result = tools.read(target_path).await;
            match read_result {
                Ok(r) if r.success => r.content,
                _ => String::new(),
            }
        } else {
            String::new()
        };

        // Ask the execution model to generate the specific action
        let request = ChatRequest::new(
            EXECUTION_MODEL,
            vec![
                Message::system(EXECUTOR_SYSTEM_PROMPT),
                Message::user(format!(
                    "Action: {}\nTarget: {}\nInstruction: {}\n\nCurrent file content:\n{}",
                    subtask.action, subtask.target, subtask.instruction, file_context
                )),
            ],
        )
        .with_max_tokens(4000);

        let response = self.gateway.chat(request).await.map_err(|e| {
            AdjutantError::ExecutionFailed(format!("Subtask {} failed: {}", subtask.id, e))
        })?;

        let content = response.content().unwrap_or("");

        // Apply the action using tools
        self.apply_subtask_action(subtask, content, tools).await
    }

    /// Apply a subtask action using the tool registry.
    async fn apply_subtask_action(
        &self,
        subtask: &Subtask,
        llm_output: &str,
        tools: &mut ToolRegistry,
    ) -> Result<SubtaskResult, AdjutantError> {
        match subtask.action.as_str() {
            "read" => {
                // Read action - just summarize what was read
                Ok(SubtaskResult {
                    id: subtask.id.clone(),
                    success: true,
                    output: format!("Read and analyzed: {}", subtask.target),
                    error: None,
                })
            }
            "edit" => {
                // Parse the LLM output to extract edit instructions
                let edit_result = parse_edit_response(llm_output);
                let target_path = std::path::Path::new(&subtask.target);

                match edit_result {
                    Some((old_string, new_string)) => {
                        let result = tools.edit(target_path, &old_string, &new_string).await?;
                        if result.success {
                            Ok(SubtaskResult {
                                id: subtask.id.clone(),
                                success: true,
                                output: format!("Edited: {}", subtask.target),
                                error: None,
                            })
                        } else {
                            Ok(SubtaskResult {
                                id: subtask.id.clone(),
                                success: false,
                                output: String::new(),
                                error: result.error,
                            })
                        }
                    }
                    None => Ok(SubtaskResult {
                        id: subtask.id.clone(),
                        success: false,
                        output: String::new(),
                        error: Some(
                            "Could not parse edit instructions from LLM output".to_string(),
                        ),
                    }),
                }
            }
            "bash" => {
                // Execute bash command
                let command = extract_bash_command(llm_output);
                let result = tools.bash(&command).await?;
                Ok(SubtaskResult {
                    id: subtask.id.clone(),
                    success: result.success,
                    output: result.content,
                    error: result.error,
                })
            }
            _ => Ok(SubtaskResult {
                id: subtask.id.clone(),
                success: false,
                output: String::new(),
                error: Some(format!("Unknown action: {}", subtask.action)),
            }),
        }
    }

    /// Use GLM 4.7 to synthesize final result.
    async fn synthesize_results(
        &self,
        task: &Task,
        results: &[SubtaskResult],
    ) -> Result<TaskResult, AdjutantError> {
        let results_summary = results
            .iter()
            .map(|r| {
                if r.success {
                    format!("- [OK] {}: {}", r.id, r.output)
                } else {
                    format!(
                        "- [FAIL] {}: {}",
                        r.id,
                        r.error.as_deref().unwrap_or("unknown error")
                    )
                }
            })
            .collect::<Vec<_>>()
            .join("\n");

        let request = ChatRequest::new(
            PLANNING_MODEL,
            vec![
                Message::system(SYNTHESIZER_SYSTEM_PROMPT),
                Message::user(format!(
                    "Original task: {}\n\nSubtask results:\n{}",
                    task.title, results_summary
                )),
            ],
        )
        .with_max_tokens(1000);

        let response = self
            .gateway
            .chat(request)
            .await
            .map_err(|e| AdjutantError::ExecutionFailed(format!("Synthesis failed: {}", e)))?;

        let content = response.content().unwrap_or("");
        parse_synthesis_result(content, results)
    }

    // =========================================================================
    // DSPy-powered execution (new optimizable path)
    // =========================================================================

    /// Execute a task using DSPy-powered signatures.
    ///
    /// This is an alternative to the gateway-based `execute` method that uses
    /// typed, optimizable signatures via dsrs. Training data is collected
    /// for MIPROv2 optimization.
    pub async fn execute_dsrs(
        &mut self,
        task: &Task,
        context: &str,
        tools: &mut ToolRegistry,
    ) -> Result<TaskResult, AdjutantError> {
        tracing::info!("TieredExecutor (DSPy): Starting task '{}'", task.title);

        let module = self.dsrs_module.as_ref().ok_or_else(|| {
            AdjutantError::ExecutionFailed(
                "DSPy module not initialized. Use ExecutionMode::Dsrs".to_string(),
            )
        })?;

        // PHASE 1: Plan with DSPy signature
        tracing::info!("Phase 1: Planning with DSPy SubtaskPlanningSignature");
        let context_handle = "inline";
        let plan_prediction = module
            .plan(&task.title, &task.description, context_handle, context)
            .await
            .map_err(|e| AdjutantError::PlanningFailed(format!("DSPy planning failed: {}", e)))?;

        let subtasks_json = plan_prediction.get("subtasks", None);
        let subtasks: Vec<Subtask> =
            serde_json::from_str(subtasks_json.as_str().unwrap_or("[]")).unwrap_or_default();

        tracing::info!("Generated {} subtasks via DSPy", subtasks.len());

        // Record planning training example
        if let Some(ref mut collector) = self.training_collector {
            let example = PlanningTrainingExample {
                task_title: task.title.clone(),
                task_description: task.description.clone(),
                context_handle: context_handle.to_string(),
                context: context.to_string(),
                expected_subtasks: subtasks
                    .iter()
                    .map(|s| SubtaskData {
                        id: s.id.clone(),
                        action: s.action.clone(),
                        target: s.target.clone(),
                        instruction: s.instruction.clone(),
                    })
                    .collect(),
                success: !subtasks.is_empty(),
            };
            let _ = collector.record_planning(example);
        }

        if subtasks.is_empty() {
            return Ok(TaskResult {
                success: true,
                summary: "No subtasks generated - task may already be complete.".to_string(),
                modified_files: Vec::new(),
                commit_hash: None,
                error: None,
                session_id: None,
            });
        }

        // PHASE 2: Execute subtasks with DSPy signature
        tracing::info!(
            "Phase 2: Executing {} subtasks with DSPy SubtaskExecutionSignature",
            subtasks.len()
        );
        let mut results = Vec::new();
        let mut modified_files = Vec::new();

        for subtask in &subtasks {
            tracing::info!(
                "Executing subtask {}: {} on {}",
                subtask.id,
                subtask.action,
                subtask.target
            );

            // Get file context for edit/read operations
            let target_path = std::path::Path::new(&subtask.target);
            let file_context = if subtask.action == "edit" || subtask.action == "read" {
                match tools.read(target_path).await {
                    Ok(r) if r.success => r.content,
                    _ => String::new(),
                }
            } else {
                String::new()
            };

            // Execute with DSPy signature
            let exec_prediction = module
                .execute_subtask(
                    &subtask.action,
                    &subtask.target,
                    &subtask.instruction,
                    &file_context,
                )
                .await
                .map_err(|e| {
                    AdjutantError::ExecutionFailed(format!("DSPy execution failed: {}", e))
                })?;

            let result_json = exec_prediction.get("result", None);
            let _exec_success = exec_prediction
                .get("success", None)
                .as_bool()
                .unwrap_or(false);

            // Apply the action using tools
            let subtask_result = self.apply_dsrs_action(subtask, &result_json, tools).await?;

            // Track modified files
            if subtask_result.success && subtask.action == "edit" {
                modified_files.push(subtask.target.clone());
            }

            // Record execution training example
            if let Some(ref mut collector) = self.training_collector {
                let example = ExecutionTrainingExample {
                    action: subtask.action.clone(),
                    target: subtask.target.clone(),
                    instruction: subtask.instruction.clone(),
                    file_context: file_context.clone(),
                    expected_result: result_json.clone(),
                    success: subtask_result.success,
                };
                let _ = collector.record_execution(example);
            }

            results.push(subtask_result);
        }

        // PHASE 3: Synthesize with DSPy signature
        tracing::info!("Phase 3: Synthesizing results with DSPy ResultSynthesisSignature");

        let results_summary = results
            .iter()
            .map(|r| {
                if r.success {
                    format!("- [OK] {}: {}", r.id, r.output)
                } else {
                    format!(
                        "- [FAIL] {}: {}",
                        r.id,
                        r.error.as_deref().unwrap_or("unknown")
                    )
                }
            })
            .collect::<Vec<_>>()
            .join("\n");

        let synth_prediction = module
            .synthesize(&task.title, &results_summary)
            .await
            .map_err(|e| AdjutantError::ExecutionFailed(format!("DSPy synthesis failed: {}", e)))?;

        let success = synth_prediction
            .get("success", None)
            .as_bool()
            .unwrap_or_else(|| results.iter().all(|r| r.success));
        let summary = synth_prediction
            .get("summary", None)
            .as_str()
            .unwrap_or("Task completed.")
            .to_string();

        // Record synthesis training example
        if let Some(ref mut collector) = self.training_collector {
            let example = SynthesisTrainingExample {
                task_title: task.title.clone(),
                subtask_results: results_summary,
                expected_success: success,
                expected_summary: summary.clone(),
                expected_modified_files: modified_files.clone(),
            };
            let _ = collector.record_synthesis(example);
        }

        Ok(TaskResult {
            success,
            summary,
            modified_files,
            commit_hash: None,
            error: None,
            session_id: None,
        })
    }

    /// Apply a subtask action from DSPy output.
    async fn apply_dsrs_action(
        &self,
        subtask: &Subtask,
        result_json: &serde_json::Value,
        tools: &mut ToolRegistry,
    ) -> Result<SubtaskResult, AdjutantError> {
        match subtask.action.as_str() {
            "read" => Ok(SubtaskResult {
                id: subtask.id.clone(),
                success: true,
                output: format!("Read and analyzed: {}", subtask.target),
                error: None,
            }),
            "edit" => {
                // Parse result JSON for old_string/new_string
                let obj = if let Some(s) = result_json.as_str() {
                    serde_json::from_str::<serde_json::Value>(s).unwrap_or_default()
                } else {
                    result_json.clone()
                };

                let old_string = obj.get("old_string").and_then(|v| v.as_str());
                let new_string = obj.get("new_string").and_then(|v| v.as_str());

                match (old_string, new_string) {
                    (Some(old), Some(new)) => {
                        let target_path = std::path::Path::new(&subtask.target);
                        let result = tools.edit(target_path, old, new).await?;
                        if result.success {
                            Ok(SubtaskResult {
                                id: subtask.id.clone(),
                                success: true,
                                output: format!("Edited: {}", subtask.target),
                                error: None,
                            })
                        } else {
                            Ok(SubtaskResult {
                                id: subtask.id.clone(),
                                success: false,
                                output: String::new(),
                                error: result.error,
                            })
                        }
                    }
                    _ => Ok(SubtaskResult {
                        id: subtask.id.clone(),
                        success: false,
                        output: String::new(),
                        error: Some("Missing old_string/new_string in DSPy result".to_string()),
                    }),
                }
            }
            "bash" => {
                let obj = if let Some(s) = result_json.as_str() {
                    serde_json::from_str::<serde_json::Value>(s).unwrap_or_default()
                } else {
                    result_json.clone()
                };

                let command = obj.get("command").and_then(|v| v.as_str()).unwrap_or("");

                let result = tools.bash(command).await?;
                Ok(SubtaskResult {
                    id: subtask.id.clone(),
                    success: result.success,
                    output: result.content,
                    error: result.error,
                })
            }
            _ => Ok(SubtaskResult {
                id: subtask.id.clone(),
                success: false,
                output: String::new(),
                error: Some(format!("Unknown action: {}", subtask.action)),
            }),
        }
    }
}

/// Parse the planning response into a TieredPlan.
fn parse_task_plan(content: &str) -> Result<TieredPlan, AdjutantError> {
    // Try to extract JSON from the response
    let json_str = extract_json(content);

    #[derive(Deserialize)]
    struct PlanResponse {
        subtasks: Vec<Subtask>,
    }

    match serde_json::from_str::<PlanResponse>(&json_str) {
        Ok(plan) => Ok(TieredPlan {
            subtasks: plan.subtasks,
        }),
        Err(e) => {
            tracing::warn!("Failed to parse plan JSON: {}. Raw: {}", e, content);
            // Return empty plan on parse failure
            Ok(TieredPlan {
                subtasks: Vec::new(),
            })
        }
    }
}

/// Parse edit response to extract old_string and new_string.
fn parse_edit_response(content: &str) -> Option<(String, String)> {
    // Try to parse as JSON first
    #[derive(Deserialize)]
    struct EditResponse {
        old_string: Option<String>,
        new_string: Option<String>,
    }

    if let Ok(edit) = serde_json::from_str::<EditResponse>(&extract_json(content)) {
        if let (Some(old), Some(new)) = (edit.old_string, edit.new_string) {
            return Some((old, new));
        }
    }

    // Fallback: look for code blocks
    let old_marker = "<<<OLD>>>";
    let new_marker = "<<<NEW>>>";
    let end_marker = "<<<END>>>";

    if let (Some(old_start), Some(new_start), Some(end_pos)) = (
        content.find(old_marker),
        content.find(new_marker),
        content.find(end_marker),
    ) {
        let old_content = &content[old_start + old_marker.len()..new_start];
        let new_content = &content[new_start + new_marker.len()..end_pos];
        return Some((
            old_content.trim().to_string(),
            new_content.trim().to_string(),
        ));
    }

    None
}

/// Extract bash command from LLM output.
fn extract_bash_command(content: &str) -> String {
    // Try JSON first
    #[derive(Deserialize)]
    struct BashResponse {
        command: Option<String>,
    }

    if let Ok(resp) = serde_json::from_str::<BashResponse>(&extract_json(content)) {
        if let Some(cmd) = resp.command {
            return cmd;
        }
    }

    // Fallback: look for code block
    if let Some(start) = content.find("```bash") {
        if let Some(end) = content[start..]
            .find("```\n")
            .or_else(|| content[start..].rfind("```"))
        {
            let cmd_start = start + "```bash".len();
            return content[cmd_start..start + end].trim().to_string();
        }
    }

    // Last resort: use the whole content as command
    content.lines().next().unwrap_or("").trim().to_string()
}

/// Parse synthesis result into TaskResult.
fn parse_synthesis_result(
    content: &str,
    results: &[SubtaskResult],
) -> Result<TaskResult, AdjutantError> {
    #[derive(Deserialize)]
    struct SynthesisResponse {
        success: Option<bool>,
        summary: Option<String>,
        modified_files: Option<Vec<String>>,
    }

    let json_str = extract_json(content);

    let (success, summary, modified_files) =
        if let Ok(resp) = serde_json::from_str::<SynthesisResponse>(&json_str) {
            (
                resp.success.unwrap_or(false),
                resp.summary
                    .unwrap_or_else(|| "Task completed.".to_string()),
                resp.modified_files.unwrap_or_default(),
            )
        } else {
            // Fallback: determine success from subtask results
            let all_success = results.iter().all(|r| r.success);
            let summary = if all_success {
                format!("Completed {} subtasks successfully.", results.len())
            } else {
                let failed = results.iter().filter(|r| !r.success).count();
                format!(
                    "Completed with {} failures out of {} subtasks.",
                    failed,
                    results.len()
                )
            };
            (all_success, summary, Vec::new())
        };

    Ok(TaskResult {
        success,
        summary,
        modified_files,
        commit_hash: None,
        error: None,
        session_id: None,
    })
}

/// Extract JSON from a string that might contain markdown or other text.
fn extract_json(content: &str) -> String {
    // Look for ```json block
    if let Some(start) = content.find("```json") {
        let json_start = start + "```json".len();
        if let Some(end) = content[json_start..].find("```") {
            return content[json_start..json_start + end].trim().to_string();
        }
    }

    // Look for raw JSON object
    if let Some(start) = content.find('{') {
        if let Some(end) = content.rfind('}') {
            return content[start..=end].to_string();
        }
    }

    content.to_string()
}

const PLANNER_SYSTEM_PROMPT: &str = r#"You are a task planner. Break the given task into concrete, atomic subtasks.

Output ONLY valid JSON in this format:
{
  "subtasks": [
    {"id": "1", "action": "read", "target": "path/to/file.rs", "instruction": "Understand the current implementation"},
    {"id": "2", "action": "edit", "target": "path/to/file.rs", "instruction": "Add error handling to function X"},
    {"id": "3", "action": "bash", "target": "", "instruction": "Run cargo test to verify changes"}
  ]
}

Actions:
- "read": Read and analyze a file
- "edit": Modify a file (will receive old_string/new_string from executor)
- "bash": Run a shell command

Guidelines:
- Keep subtasks atomic and focused
- Order subtasks logically (read before edit, edit before test)
- Use specific file paths from the context
- Maximum 5 subtasks per task"#;

const EXECUTOR_SYSTEM_PROMPT: &str = r#"You are an executor. Perform the given action and return the result.

For "edit" actions, output JSON with the exact strings to find and replace:
{
  "old_string": "the exact text to find",
  "new_string": "the replacement text"
}

For "bash" actions, output JSON with the command:
{
  "command": "cargo test"
}

For "read" actions, summarize what you learned about the file.

Be precise with old_string - it must match exactly what's in the file."#;

const SYNTHESIZER_SYSTEM_PROMPT: &str = r#"You are a synthesis agent. Given subtask results, determine if the overall task succeeded and provide a summary.

Output JSON:
{
  "success": true/false,
  "summary": "Brief description of what was accomplished or what failed",
  "modified_files": ["list", "of", "modified", "files"]
}

Be concise but informative in the summary."#;

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_extract_json() {
        let input = r#"Here's the plan:
```json
{"subtasks": []}
```
Done."#;
        let result = extract_json(input);
        assert_eq!(result, r#"{"subtasks": []}"#);
    }

    #[test]
    fn test_parse_edit_response() {
        let input = r#"{"old_string": "foo", "new_string": "bar"}"#;
        let result = parse_edit_response(input);
        assert_eq!(result, Some(("foo".to_string(), "bar".to_string())));
    }
}
