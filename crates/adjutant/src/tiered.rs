//! Tiered inference executor.
//!
//! Uses Cerebras GLM 4.7 for planning/orchestration, Qwen-3-32B for subtask execution.
//! This provides a cost-effective approach: smart model for planning, cheaper model for work.

use crate::{AdjutantError, Task, TaskResult, ToolRegistry};
use gateway::{CerebrasGateway, ChatRequest, InferenceGateway, Message};
use serde::{Deserialize, Serialize};
use std::sync::Arc;

/// Models for different tiers
const PLANNING_MODEL: &str = "zai-glm-4.7"; // Smart, for planning
const EXECUTION_MODEL: &str = "qwen-3-32b"; // Cheaper, for subtasks

/// A subtask generated by the planner.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Subtask {
    /// Subtask ID
    pub id: String,
    /// Action type: read, edit, bash
    pub action: String,
    /// Target file or path
    pub target: String,
    /// Instruction for what to do
    pub instruction: String,
}

/// Plan generated by the planning phase.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TieredPlan {
    /// List of subtasks to execute
    pub subtasks: Vec<Subtask>,
}

/// Result of a single subtask.
#[derive(Debug, Clone)]
pub struct SubtaskResult {
    /// Subtask ID
    pub id: String,
    /// Whether it succeeded
    pub success: bool,
    /// Output or result
    pub output: String,
    /// Error message if failed
    pub error: Option<String>,
}

/// Tiered executor that uses different models for planning vs execution.
pub struct TieredExecutor {
    /// Single Cerebras gateway, uses different models
    gateway: Arc<CerebrasGateway>,
}

impl TieredExecutor {
    /// Create a new tiered executor.
    pub fn new() -> Result<Self, AdjutantError> {
        let gateway = CerebrasGateway::from_env()
            .map_err(|e| AdjutantError::ExecutionFailed(format!("Failed to create gateway: {}", e)))?;

        Ok(Self {
            gateway: Arc::new(gateway),
        })
    }

    /// Execute a task using tiered inference.
    pub async fn execute(
        &self,
        task: &Task,
        context: &str,
        tools: &mut ToolRegistry,
    ) -> Result<TaskResult, AdjutantError> {
        tracing::info!("TieredExecutor: Starting task '{}'", task.title);

        // PHASE 1: Plan with GLM 4.7 (smart)
        tracing::info!("Phase 1: Planning with {}", PLANNING_MODEL);
        let plan = self.plan_task(task, context).await?;
        tracing::info!("Generated {} subtasks", plan.subtasks.len());

        if plan.subtasks.is_empty() {
            return Ok(TaskResult {
                success: true,
                summary: "No subtasks generated - task may already be complete or no changes needed.".to_string(),
                modified_files: Vec::new(),
                commit_hash: None,
                error: None,
            });
        }

        // PHASE 2: Execute subtasks with Qwen-3-32B (cheap)
        tracing::info!("Phase 2: Executing subtasks with {}", EXECUTION_MODEL);
        let results = self.execute_subtasks(&plan.subtasks, tools).await?;

        // PHASE 3: Synthesize with GLM 4.7 (smart)
        tracing::info!("Phase 3: Synthesizing results with {}", PLANNING_MODEL);
        let result = self.synthesize_results(task, &results).await?;

        Ok(result)
    }

    /// Use GLM 4.7 to break task into subtasks.
    async fn plan_task(&self, task: &Task, context: &str) -> Result<TieredPlan, AdjutantError> {
        let request = ChatRequest::new(
            PLANNING_MODEL,
            vec![
                Message::system(PLANNER_SYSTEM_PROMPT),
                Message::user(format!(
                    "Task: {}\n\nDescription: {}\n\nContext:\n{}",
                    task.title, task.description, context
                )),
            ],
        )
        .with_max_tokens(2000);

        let response = self.gateway.chat(request).await.map_err(|e| {
            AdjutantError::ExecutionFailed(format!("Planning failed: {}", e))
        })?;

        let content = response.content().unwrap_or("{}");
        parse_task_plan(content)
    }

    /// Execute subtasks sequentially (parallel would need careful tool handling).
    async fn execute_subtasks(
        &self,
        subtasks: &[Subtask],
        tools: &mut ToolRegistry,
    ) -> Result<Vec<SubtaskResult>, AdjutantError> {
        let mut results = Vec::new();

        for subtask in subtasks {
            tracing::info!("Executing subtask {}: {} on {}", subtask.id, subtask.action, subtask.target);
            let result = self.execute_single_subtask(subtask, tools).await?;
            results.push(result);
        }

        Ok(results)
    }

    /// Execute a single subtask with Qwen-3-32B.
    async fn execute_single_subtask(
        &self,
        subtask: &Subtask,
        tools: &mut ToolRegistry,
    ) -> Result<SubtaskResult, AdjutantError> {
        // First, get context if it's a file operation
        let target_path = std::path::Path::new(&subtask.target);
        let file_context = if subtask.action == "edit" || subtask.action == "read" {
            let read_result = tools.read(target_path).await;
            match read_result {
                Ok(r) if r.success => r.content,
                _ => String::new(),
            }
        } else {
            String::new()
        };

        // Ask the execution model to generate the specific action
        let request = ChatRequest::new(
            EXECUTION_MODEL,
            vec![
                Message::system(EXECUTOR_SYSTEM_PROMPT),
                Message::user(format!(
                    "Action: {}\nTarget: {}\nInstruction: {}\n\nCurrent file content:\n{}",
                    subtask.action, subtask.target, subtask.instruction, file_context
                )),
            ],
        )
        .with_max_tokens(4000);

        let response = self.gateway.chat(request).await.map_err(|e| {
            AdjutantError::ExecutionFailed(format!("Subtask {} failed: {}", subtask.id, e))
        })?;

        let content = response.content().unwrap_or("");

        // Apply the action using tools
        self.apply_subtask_action(subtask, content, tools).await
    }

    /// Apply a subtask action using the tool registry.
    async fn apply_subtask_action(
        &self,
        subtask: &Subtask,
        llm_output: &str,
        tools: &mut ToolRegistry,
    ) -> Result<SubtaskResult, AdjutantError> {
        match subtask.action.as_str() {
            "read" => {
                // Read action - just summarize what was read
                Ok(SubtaskResult {
                    id: subtask.id.clone(),
                    success: true,
                    output: format!("Read and analyzed: {}", subtask.target),
                    error: None,
                })
            }
            "edit" => {
                // Parse the LLM output to extract edit instructions
                let edit_result = parse_edit_response(llm_output);
                let target_path = std::path::Path::new(&subtask.target);

                match edit_result {
                    Some((old_string, new_string)) => {
                        let result = tools.edit(target_path, &old_string, &new_string).await?;
                        if result.success {
                            Ok(SubtaskResult {
                                id: subtask.id.clone(),
                                success: true,
                                output: format!("Edited: {}", subtask.target),
                                error: None,
                            })
                        } else {
                            Ok(SubtaskResult {
                                id: subtask.id.clone(),
                                success: false,
                                output: String::new(),
                                error: result.error,
                            })
                        }
                    }
                    None => Ok(SubtaskResult {
                        id: subtask.id.clone(),
                        success: false,
                        output: String::new(),
                        error: Some("Could not parse edit instructions from LLM output".to_string()),
                    }),
                }
            }
            "bash" => {
                // Execute bash command
                let command = extract_bash_command(llm_output);
                let result = tools.bash(&command).await?;
                Ok(SubtaskResult {
                    id: subtask.id.clone(),
                    success: result.success,
                    output: result.content,
                    error: result.error,
                })
            }
            _ => Ok(SubtaskResult {
                id: subtask.id.clone(),
                success: false,
                output: String::new(),
                error: Some(format!("Unknown action: {}", subtask.action)),
            }),
        }
    }

    /// Use GLM 4.7 to synthesize final result.
    async fn synthesize_results(
        &self,
        task: &Task,
        results: &[SubtaskResult],
    ) -> Result<TaskResult, AdjutantError> {
        let results_summary = results
            .iter()
            .map(|r| {
                if r.success {
                    format!("- [OK] {}: {}", r.id, r.output)
                } else {
                    format!("- [FAIL] {}: {}", r.id, r.error.as_deref().unwrap_or("unknown error"))
                }
            })
            .collect::<Vec<_>>()
            .join("\n");

        let request = ChatRequest::new(
            PLANNING_MODEL,
            vec![
                Message::system(SYNTHESIZER_SYSTEM_PROMPT),
                Message::user(format!(
                    "Original task: {}\n\nSubtask results:\n{}",
                    task.title, results_summary
                )),
            ],
        )
        .with_max_tokens(1000);

        let response = self.gateway.chat(request).await.map_err(|e| {
            AdjutantError::ExecutionFailed(format!("Synthesis failed: {}", e))
        })?;

        let content = response.content().unwrap_or("");
        parse_synthesis_result(content, results)
    }
}

/// Parse the planning response into a TieredPlan.
fn parse_task_plan(content: &str) -> Result<TieredPlan, AdjutantError> {
    // Try to extract JSON from the response
    let json_str = extract_json(content);

    #[derive(Deserialize)]
    struct PlanResponse {
        subtasks: Vec<Subtask>,
    }

    match serde_json::from_str::<PlanResponse>(&json_str) {
        Ok(plan) => Ok(TieredPlan {
            subtasks: plan.subtasks,
        }),
        Err(e) => {
            tracing::warn!("Failed to parse plan JSON: {}. Raw: {}", e, content);
            // Return empty plan on parse failure
            Ok(TieredPlan {
                subtasks: Vec::new(),
            })
        }
    }
}

/// Parse edit response to extract old_string and new_string.
fn parse_edit_response(content: &str) -> Option<(String, String)> {
    // Try to parse as JSON first
    #[derive(Deserialize)]
    struct EditResponse {
        old_string: Option<String>,
        new_string: Option<String>,
    }

    if let Ok(edit) = serde_json::from_str::<EditResponse>(&extract_json(content)) {
        if let (Some(old), Some(new)) = (edit.old_string, edit.new_string) {
            return Some((old, new));
        }
    }

    // Fallback: look for code blocks
    let old_marker = "<<<OLD>>>";
    let new_marker = "<<<NEW>>>";
    let end_marker = "<<<END>>>";

    if let (Some(old_start), Some(new_start), Some(end_pos)) = (
        content.find(old_marker),
        content.find(new_marker),
        content.find(end_marker),
    ) {
        let old_content = &content[old_start + old_marker.len()..new_start];
        let new_content = &content[new_start + new_marker.len()..end_pos];
        return Some((old_content.trim().to_string(), new_content.trim().to_string()));
    }

    None
}

/// Extract bash command from LLM output.
fn extract_bash_command(content: &str) -> String {
    // Try JSON first
    #[derive(Deserialize)]
    struct BashResponse {
        command: Option<String>,
    }

    if let Ok(resp) = serde_json::from_str::<BashResponse>(&extract_json(content)) {
        if let Some(cmd) = resp.command {
            return cmd;
        }
    }

    // Fallback: look for code block
    if let Some(start) = content.find("```bash") {
        if let Some(end) = content[start..].find("```\n").or_else(|| content[start..].rfind("```")) {
            let cmd_start = start + "```bash".len();
            return content[cmd_start..start + end].trim().to_string();
        }
    }

    // Last resort: use the whole content as command
    content.lines().next().unwrap_or("").trim().to_string()
}

/// Parse synthesis result into TaskResult.
fn parse_synthesis_result(content: &str, results: &[SubtaskResult]) -> Result<TaskResult, AdjutantError> {
    #[derive(Deserialize)]
    struct SynthesisResponse {
        success: Option<bool>,
        summary: Option<String>,
        modified_files: Option<Vec<String>>,
    }

    let json_str = extract_json(content);

    let (success, summary, modified_files) =
        if let Ok(resp) = serde_json::from_str::<SynthesisResponse>(&json_str) {
            (
                resp.success.unwrap_or(false),
                resp.summary.unwrap_or_else(|| "Task completed.".to_string()),
                resp.modified_files.unwrap_or_default(),
            )
        } else {
            // Fallback: determine success from subtask results
            let all_success = results.iter().all(|r| r.success);
            let summary = if all_success {
                format!("Completed {} subtasks successfully.", results.len())
            } else {
                let failed = results.iter().filter(|r| !r.success).count();
                format!(
                    "Completed with {} failures out of {} subtasks.",
                    failed,
                    results.len()
                )
            };
            (all_success, summary, Vec::new())
        };

    Ok(TaskResult {
        success,
        summary,
        modified_files,
        commit_hash: None,
        error: None,
    })
}

/// Extract JSON from a string that might contain markdown or other text.
fn extract_json(content: &str) -> String {
    // Look for ```json block
    if let Some(start) = content.find("```json") {
        let json_start = start + "```json".len();
        if let Some(end) = content[json_start..].find("```") {
            return content[json_start..json_start + end].trim().to_string();
        }
    }

    // Look for raw JSON object
    if let Some(start) = content.find('{') {
        if let Some(end) = content.rfind('}') {
            return content[start..=end].to_string();
        }
    }

    content.to_string()
}

const PLANNER_SYSTEM_PROMPT: &str = r#"You are a task planner. Break the given task into concrete, atomic subtasks.

Output ONLY valid JSON in this format:
{
  "subtasks": [
    {"id": "1", "action": "read", "target": "path/to/file.rs", "instruction": "Understand the current implementation"},
    {"id": "2", "action": "edit", "target": "path/to/file.rs", "instruction": "Add error handling to function X"},
    {"id": "3", "action": "bash", "target": "", "instruction": "Run cargo test to verify changes"}
  ]
}

Actions:
- "read": Read and analyze a file
- "edit": Modify a file (will receive old_string/new_string from executor)
- "bash": Run a shell command

Guidelines:
- Keep subtasks atomic and focused
- Order subtasks logically (read before edit, edit before test)
- Use specific file paths from the context
- Maximum 5 subtasks per task"#;

const EXECUTOR_SYSTEM_PROMPT: &str = r#"You are an executor. Perform the given action and return the result.

For "edit" actions, output JSON with the exact strings to find and replace:
{
  "old_string": "the exact text to find",
  "new_string": "the replacement text"
}

For "bash" actions, output JSON with the command:
{
  "command": "cargo test"
}

For "read" actions, summarize what you learned about the file.

Be precise with old_string - it must match exactly what's in the file."#;

const SYNTHESIZER_SYSTEM_PROMPT: &str = r#"You are a synthesis agent. Given subtask results, determine if the overall task succeeded and provide a summary.

Output JSON:
{
  "success": true/false,
  "summary": "Brief description of what was accomplished or what failed",
  "modified_files": ["list", "of", "modified", "files"]
}

Be concise but informative in the summary."#;

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_extract_json() {
        let input = r#"Here's the plan:
```json
{"subtasks": []}
```
Done."#;
        let result = extract_json(input);
        assert_eq!(result, r#"{"subtasks": []}"#);
    }

    #[test]
    fn test_parse_edit_response() {
        let input = r#"{"old_string": "foo", "new_string": "bar"}"#;
        let result = parse_edit_response(input);
        assert_eq!(result, Some(("foo".to_string(), "bar".to_string())));
    }
}
