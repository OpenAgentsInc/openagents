use serde::{Deserialize, Serialize};
use serde_json::Value;

/// LLM operational and confidence data for a single step.
///
/// All fields are optional as this entire object is optional.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct Metrics {
    /// Total input tokens sent to the model for this turn
    ///
    /// Includes both cached and non-cached tokens. This represents the full size
    /// of the prompt (system prompt, history, tool definitions, etc.) that was
    /// processed by the model, regardless of whether some tokens were served from cache.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub prompt_tokens: Option<i64>,

    /// Total tokens generated by the LLM response
    ///
    /// Includes reasoning and tool calls.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub completion_tokens: Option<i64>,

    /// Subset of `prompt_tokens` that were cache hits from prompt caching
    ///
    /// This counts tokens that were reused from cache rather than reprocessed.
    /// **This is included in the `prompt_tokens` count**, not separate from it.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cached_tokens: Option<i64>,

    /// Monetary cost of the API call based on current provider pricing for this step
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cost_usd: Option<f64>,

    /// Token IDs for the prompt (input) tokens sent to the LLM
    ///
    /// Includes previous chat history if applicable. Enables accurate analysis
    /// and debugging of prompt tokenization. Length should match `prompt_tokens` count.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub prompt_token_ids: Option<Vec<i64>>,

    /// Token IDs for the completion (response) tokens generated in this step
    ///
    /// Enables accurate RL training by avoiding retokenization drift. Should align
    /// with `logprobs` array if both are present. Length should match `completion_tokens` count.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub completion_token_ids: Option<Vec<i64>>,

    /// Log probabilities for each completion token
    ///
    /// Should align with `completion_token_ids` array if both are present.
    /// Length should match `completion_tokens` count.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub logprobs: Option<Vec<f64>>,

    /// Provider-specific or experimental metrics not covered by the core schema
    ///
    /// Examples: reasoning_tokens, cache_creation_input_tokens
    #[serde(skip_serializing_if = "Option::is_none")]
    pub extra: Option<Value>,
}

impl Metrics {
    /// Create new empty metrics
    pub fn new() -> Self {
        Self {
            prompt_tokens: None,
            completion_tokens: None,
            cached_tokens: None,
            cost_usd: None,
            prompt_token_ids: None,
            completion_token_ids: None,
            logprobs: None,
            extra: None,
        }
    }

    /// Calculate cost using the standard formula
    ///
    /// ```
    /// non_cached_prompt_tokens = prompt_tokens - cached_tokens
    /// cost_usd = (non_cached_prompt_tokens × cost_per_input_token) +
    ///            (cached_tokens × cost_per_cached_token) +
    ///            (completion_tokens × cost_per_completion_token)
    /// ```
    ///
    /// Note: This may not be accurate if there are additional cost factors in `extra`
    /// (e.g., cache_creation_input_tokens).
    pub fn calculate_cost(
        &self,
        cost_per_input_token: f64,
        cost_per_cached_token: f64,
        cost_per_completion_token: f64,
    ) -> Option<f64> {
        let prompt_tokens = self.prompt_tokens? as f64;
        let completion_tokens = self.completion_tokens.unwrap_or(0) as f64;
        let cached_tokens = self.cached_tokens.unwrap_or(0) as f64;

        let non_cached_prompt = prompt_tokens - cached_tokens;
        let cost = (non_cached_prompt * cost_per_input_token)
            + (cached_tokens * cost_per_cached_token)
            + (completion_tokens * cost_per_completion_token);

        Some(cost)
    }

    /// Validate that token ID arrays match token counts
    pub fn validate_token_ids(&self) -> Result<(), String> {
        if let (Some(prompt_ids), Some(prompt_count)) = (&self.prompt_token_ids, self.prompt_tokens)
        {
            if prompt_ids.len() as i64 != prompt_count {
                return Err(format!(
                    "prompt_token_ids length ({}) does not match prompt_tokens count ({})",
                    prompt_ids.len(),
                    prompt_count
                ));
            }
        }

        if let (Some(completion_ids), Some(completion_count)) =
            (&self.completion_token_ids, self.completion_tokens)
        {
            if completion_ids.len() as i64 != completion_count {
                return Err(format!(
                    "completion_token_ids length ({}) does not match completion_tokens count ({})",
                    completion_ids.len(),
                    completion_count
                ));
            }
        }

        if let (Some(logprobs), Some(completion_count)) = (&self.logprobs, self.completion_tokens) {
            if logprobs.len() as i64 != completion_count {
                return Err(format!(
                    "logprobs length ({}) does not match completion_tokens count ({})",
                    logprobs.len(),
                    completion_count
                ));
            }
        }

        Ok(())
    }
}

impl Default for Metrics {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_cost_calculation() {
        let metrics = Metrics {
            prompt_tokens: Some(1000),
            completion_tokens: Some(500),
            cached_tokens: Some(200),
            ..Default::default()
        };

        let cost = metrics.calculate_cost(0.001, 0.0001, 0.002).unwrap();
        // (800 * 0.001) + (200 * 0.0001) + (500 * 0.002) = 0.8 + 0.02 + 1.0 = 1.82
        assert!((cost - 1.82).abs() < 0.0001);
    }

    #[test]
    fn test_token_id_validation() {
        let mut metrics = Metrics {
            prompt_tokens: Some(5),
            prompt_token_ids: Some(vec![1, 2, 3, 4, 5]),
            ..Default::default()
        };

        assert!(metrics.validate_token_ids().is_ok());

        metrics.prompt_token_ids = Some(vec![1, 2, 3]); // Wrong length
        assert!(metrics.validate_token_ids().is_err());
    }
}
