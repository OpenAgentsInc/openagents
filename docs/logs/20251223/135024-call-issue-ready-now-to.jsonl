{"type":"system","message":{"subtype":"init","agents":["general-purpose","statusline-setup","Explore","Plan"],"apiKeySource":"none","betas":null,"claude_code_version":"2.0.76","cwd":"/home/christopherdavid/code/openagents","tools":["Task","TaskOutput","Bash","Glob","Grep","ExitPlanMode","Read","Edit","Write","NotebookEdit","WebFetch","TodoWrite","WebSearch","KillShell","AskUserQuestion","Skill","EnterPlanMode","LSP","mcp__effect-docs__effect_docs_search","mcp__effect-docs__get_effect_doc","ListMcpResourcesTool","ReadMcpResourceTool","mcp__issues__issue_list","mcp__issues__issue_create","mcp__issues__issue_get","mcp__issues__issue_claim","mcp__issues__issue_complete","mcp__issues__issue_block","mcp__issues__issue_ready","mcp__issues__issue_update","mcp__issues__enter_plan_mode","mcp__issues__exit_plan_mode","mcp__issues__advance_plan_phase","mcp__issues__get_current_phase","mcp__issues__issue_delete","mcp__issues__directive_list","mcp__issues__directive_get","mcp__issues__directive_create","mcp__issues__directive_update"],"mcp_servers":[{"name":"effect-docs","status":"connected"},{"name":"issues","status":"connected"}],"model":"claude-sonnet-4-5-20250929","permissionMode":"bypassPermissions","slash_commands":["codex","compact","context","cost","init","pr-comments","release-notes","review","security-review"],"output_style":"default","skills":["codex"],"plugins":[{"name":"rust-analyzer-lsp","path":"/home/christopherdavid/.claude/plugins/cache/claude-plugins-official/rust-analyzer-lsp/1.0.0"}],"uuid":"00c5780b-5341-4481-96f0-625a6515a6ca","session_id":"10585027-d28b-4c78-bc5f-2f55edc857a8"},"timestamp":"2025-12-23T19:50:52.341819974+00:00"}
{"type":"assistant","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01PTDf3p1Jhuw22tao6UrMi8","type":"message","role":"assistant","content":[{"type":"text","text":"I'll call issue_ready to get the first issue and begin working."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":11453,"cache_read_input_tokens":17184,"cache_creation":{"ephemeral_5m_input_tokens":11453,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"},"context_management":null},"timestamp":"2025-12-23T19:50:56.479987122+00:00"}
{"type":"assistant","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01PTDf3p1Jhuw22tao6UrMi8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019ofX2ZkzvbCMBtnjH7puPP","name":"mcp__issues__issue_ready","input":{}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":11453,"cache_read_input_tokens":17184,"cache_creation":{"ephemeral_5m_input_tokens":11453,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"},"context_management":null},"timestamp":"2025-12-23T19:50:56.672426037+00:00"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019ofX2ZkzvbCMBtnjH7puPP","type":"tool_result","content":[{"type":"text","text":"{\n  \"number\": 983,\n  \"title\": \"Implement automated weekly trend reports for autopilot metrics\",\n  \"description\": \"Generate weekly summary reports showing metric trends, improvements, and regressions. Save reports to docs/autopilot/reports/YYYY-WW.md.\\n\\nImplementation:\\n- Calculate weekly aggregates for all key metrics\\n- Compare to previous week and baseline\\n- Identify top improvements and regressions\\n- Generate markdown report with charts\\n- Add CLI command: cargo autopilot report weekly\\n- Optional: email/notify on completion\",\n  \"priority\": \"medium\",\n  \"issue_type\": \"task\",\n  \"agent\": \"claude\"\n}"}]}]},"timestamp":"2025-12-23T19:50:56.720938665+00:00"}
{"type":"assistant","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01FHZvJpSUHZAuAu3Bj6bHpp","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Q7pSnL6tabZXKf27NPt9QG","name":"mcp__issues__issue_claim","input":{"number":983,"run_id":"autonomous-20251223"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":228,"cache_read_input_tokens":28637,"cache_creation":{"ephemeral_5m_input_tokens":228,"ephemeral_1h_input_tokens":0},"output_tokens":32,"service_tier":"standard"},"context_management":null},"timestamp":"2025-12-23T19:50:59.780188968+00:00"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Q7pSnL6tabZXKf27NPt9QG","type":"tool_result","content":[{"type":"text","text":"Claimed issue #983"}]}]},"timestamp":"2025-12-23T19:50:59.855312112+00:00"}
{"type":"assistant","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01Bq5GPFBbF2MwYmohABPdKk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UrfUjVWi6CHk7N8LhiERDz","name":"TodoWrite","input":{"todos":[{"content":"Understand existing autopilot metrics infrastructure","activeForm":"Understanding existing autopilot metrics infrastructure","status":"in_progress"},{"content":"Implement weekly aggregation logic for metrics","activeForm":"Implementing weekly aggregation logic for metrics","status":"pending"},{"content":"Create markdown report generator with trend analysis","activeForm":"Creating markdown report generator with trend analysis","status":"pending"},{"content":"Add CLI command for weekly reports","activeForm":"Adding CLI command for weekly reports","status":"pending"},{"content":"Test report generation","activeForm":"Testing report generation","status":"pending"},{"content":"Commit and push changes","activeForm":"Committing and pushing changes","status":"pending"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":98,"cache_read_input_tokens":28865,"cache_creation":{"ephemeral_5m_input_tokens":98,"ephemeral_1h_input_tokens":0},"output_tokens":26,"service_tier":"standard"},"context_management":null},"timestamp":"2025-12-23T19:51:06.463947911+00:00"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UrfUjVWi6CHk7N8LhiERDz","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"timestamp":"2025-12-23T19:51:06.550423804+00:00"}
{"type":"assistant","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01YVKmT13WafqfjmPc23azU8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FF4HaUNbp9csWiMoXB6ci6","name":"Glob","input":{"pattern":"**/autopilot/**/*.rs"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":278,"cache_read_input_tokens":28963,"cache_creation":{"ephemeral_5m_input_tokens":278,"ephemeral_1h_input_tokens":0},"output_tokens":26,"service_tier":"standard"},"context_management":null},"timestamp":"2025-12-23T19:51:08.945394652+00:00"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FF4HaUNbp9csWiMoXB6ci6","type":"tool_result","content":"/home/christopherdavid/code/openagents/crates/autopilot/src/compaction.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/redact.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/timestamp.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/ui_renderer.rs\n/home/christopherdavid/code/openagents/crates/autopilot/examples/trajectory_analysis.rs\n/home/christopherdavid/code/openagents/crates/autopilot/examples/simple_task.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/goals.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/nostr_agent.rs\n/home/christopherdavid/code/openagents/crates/autopilot/benches/nip_sa_state.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/trajectory_publisher.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/dashboard/state.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/tests/mod.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/daemon/state.rs\n/home/christopherdavid/code/openagents/crates/autopilot/examples/issue_workflow.rs\n/home/christopherdavid/code/openagents/crates/autopilot/benches/task_execution.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/benchmark/tasks.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/nip_sa_trajectory.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/profiling.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/trajectory.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/tests/dashboard_snapshots.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/learning.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/tool_patterns.rs\n/home/christopherdavid/code/openagents/crates/autopilot/benches/trajectory_overhead.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/daemon/metrics.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/benchmark/mod.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/daemon/mod.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/tests/dashboard_api.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/daemon/http.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/notifications.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/alerts.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/apm_parser.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/rlog_writer.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/timestamp.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/trajectory_tracking.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/autonomous_loop.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/autopilot_run_e2e.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/export_issues.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/error_handling.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/benchmark_execution.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/trajectory.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/trajectory_error_handling.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/metrics/baseline.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/planmode.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/state.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/logs.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/replay.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/daemon/memory.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/rlog.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/dashboard.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/apm.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/daemon/config.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/apm_storage.rs\n/home/christopherdavid/code/openagents/crates/autopilot/tests/database_integration.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/auto_issues.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/daemon/supervisor.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/daemon/control.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/bin/autopilotd.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/memory.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/lib.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/lockfile.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/analyze.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/reports.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/metrics/mod.rs\n/home/christopherdavid/code/openagents/crates/autopilot/src/main.rs"}]},"timestamp":"2025-12-23T19:51:09.289591181+00:00"}
{"type":"assistant","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016mfad7h36RrB7kbTE23jEE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SjK4xncTCwvP1KdqgMCNFj","name":"Read","input":{"file_path":"/home/christopherdavid/code/openagents/crates/autopilot/src/reports.rs"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1977,"cache_read_input_tokens":29241,"cache_creation":{"ephemeral_5m_input_tokens":1977,"ephemeral_1h_input_tokens":0},"output_tokens":18,"service_tier":"standard"},"context_management":null},"timestamp":"2025-12-23T19:51:11.952293321+00:00"}
{"type":"assistant","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016mfad7h36RrB7kbTE23jEE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PRgKfwmFskegC3GMykiCrU","name":"Read","input":{"file_path":"/home/christopherdavid/code/openagents/crates/autopilot/src/metrics/mod.rs"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1977,"cache_read_input_tokens":29241,"cache_creation":{"ephemeral_5m_input_tokens":1977,"ephemeral_1h_input_tokens":0},"output_tokens":18,"service_tier":"standard"},"context_management":null},"timestamp":"2025-12-23T19:51:12.637677839+00:00"}
{"type":"assistant","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016mfad7h36RrB7kbTE23jEE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01R8N3KoR11FsKpJfjsmTJp5","name":"Read","input":{"file_path":"/home/christopherdavid/code/openagents/crates/autopilot/src/analyze.rs"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1977,"cache_read_input_tokens":29241,"cache_creation":{"ephemeral_5m_input_tokens":1977,"ephemeral_1h_input_tokens":0},"output_tokens":205,"service_tier":"standard"},"context_management":null},"timestamp":"2025-12-23T19:51:12.916475280+00:00"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SjK4xncTCwvP1KdqgMCNFj","type":"tool_result","content":"     1â†’//! Automated weekly trend reports for autopilot metrics\n     2â†’//!\n     3â†’//! This module implements automated weekly report generation for Phase 3 of d-004.\n     4â†’//! Reports include week-over-week comparisons, regression detection, and key metrics.\n     5â†’//!\n     6â†’//! # Usage\n     7â†’//!\n     8â†’//! ```no_run\n     9â†’//! use autopilot::reports::generate_weekly_report;\n    10â†’//! use autopilot::metrics::MetricsDb;\n    11â†’//!\n    12â†’//! let db = MetricsDb::open(\"autopilot-metrics.db\")?;\n    13â†’//! let report = generate_weekly_report(&db)?;\n    14â†’//!\n    15â†’//! // Save to file\n    16â†’//! std::fs::write(\"docs/reports/weekly-20251223.md\", report)?;\n    17â†’//! # Ok::<(), Box<dyn std::error::Error>>(())\n    18â†’//! ```\n    19â†’\n    20â†’use anyhow::Result;\n    21â†’use chrono::{DateTime, Utc};\n    22â†’use colored::*;\n    23â†’use std::path::PathBuf;\n    24â†’\n    25â†’use crate::analyze::{\n    26â†’    calculate_aggregate_stats_from_sessions, detect_regressions, get_sessions_in_period,\n    27â†’    get_top_error_tools, Regression, RegressionSeverity, TimePeriod,\n    28â†’};\n    29â†’use crate::metrics::MetricsDb;\n    30â†’\n    31â†’/// Weekly report containing all key metrics and trends\n    32â†’#[derive(Debug)]\n    33â†’pub struct WeeklyReport {\n    34â†’    pub week_start: DateTime<Utc>,\n    35â†’    pub week_end: DateTime<Utc>,\n    36â†’    pub current_week_stats: std::collections::HashMap<String, f64>,\n    37â†’    pub previous_week_stats: std::collections::HashMap<String, f64>,\n    38â†’    pub regressions: Vec<Regression>,\n    39â†’    pub top_errors: Vec<(String, u32)>,\n    40â†’    pub total_sessions: usize,\n    41â†’    pub total_issues_completed: i32,\n    42â†’    pub total_cost_usd: f64,\n    43â†’    pub sessions_comparison: SessionComparison,\n    44â†’    pub personal_bests_achieved: Vec<crate::metrics::PersonalBest>,\n    45â†’}\n    46â†’\n    47â†’/// Week-over-week session comparison\n    48â†’#[derive(Debug)]\n    49â†’pub struct SessionComparison {\n    50â†’    pub current_week_sessions: usize,\n    51â†’    pub previous_week_sessions: usize,\n    52â†’    pub current_week_issues: i32,\n    53â†’    pub previous_week_issues: i32,\n    54â†’    pub current_week_cost: f64,\n    55â†’    pub previous_week_cost: f64,\n    56â†’}\n    57â†’\n    58â†’/// Generate a comprehensive weekly report\n    59â†’pub fn generate_weekly_report(db: &MetricsDb) -> Result<WeeklyReport> {\n    60â†’    let current_week_period = TimePeriod::ThisWeek;\n    61â†’    let previous_week_period = TimePeriod::LastWeek;\n    62â†’\n    63â†’    // Get sessions for both weeks\n    64â†’    let current_sessions = get_sessions_in_period(db, current_week_period)?;\n    65â†’    let previous_sessions = get_sessions_in_period(db, previous_week_period)?;\n    66â†’\n    67â†’    // Calculate aggregate stats\n    68â†’    let current_stats = calculate_aggregate_stats_from_sessions(&current_sessions);\n    69â†’    let previous_stats = calculate_aggregate_stats_from_sessions(&previous_sessions);\n    70â†’\n    71â†’    // Extract mean values for comparison\n    72â†’    let current_week_stats: std::collections::HashMap<String, f64> = current_stats\n    73â†’        .iter()\n    74â†’        .map(|(k, v)| (k.clone(), v.mean))\n    75â†’        .collect();\n    76â†’\n    77â†’    let previous_week_stats: std::collections::HashMap<String, f64> = previous_stats\n    78â†’        .iter()\n    79â†’        .map(|(k, v)| (k.clone(), v.mean))\n    80â†’        .collect();\n    81â†’\n    82â†’    // Detect regressions\n    83â†’    let regressions = detect_regressions(db, current_week_period)?;\n    84â†’\n    85â†’    // Get top error tools\n    86â†’    let top_errors = get_top_error_tools(db, current_week_period, 5)?;\n    87â†’\n    88â†’    // Calculate totals\n    89â†’    let total_sessions = current_sessions.len();\n    90â†’    let total_issues_completed: i32 = current_sessions.iter().map(|s| s.issues_completed).sum();\n    91â†’    let total_cost_usd: f64 = current_sessions.iter().map(|s| s.cost_usd).sum();\n    92â†’\n    93â†’    // Session comparison\n    94â†’    let sessions_comparison = SessionComparison {\n    95â†’        current_week_sessions: current_sessions.len(),\n    96â†’        previous_week_sessions: previous_sessions.len(),\n    97â†’        current_week_issues: current_sessions.iter().map(|s| s.issues_completed).sum(),\n    98â†’        previous_week_issues: previous_sessions.iter().map(|s| s.issues_completed).sum(),\n    99â†’        current_week_cost: current_sessions.iter().map(|s| s.cost_usd).sum(),\n   100â†’        previous_week_cost: previous_sessions.iter().map(|s| s.cost_usd).sum(),\n   101â†’    };\n   102â†’\n   103â†’    // Get week boundaries\n   104â†’    let (week_start, week_end) = current_week_period.bounds();\n   105â†’\n   106â†’    // Get personal bests achieved this week\n   107â†’    let all_bests = db.get_all_personal_bests()?;\n   108â†’    let personal_bests_achieved: Vec<crate::metrics::PersonalBest> = all_bests\n   109â†’        .into_iter()\n   110â†’        .filter(|best| best.timestamp >= week_start && best.timestamp <= week_end)\n   111â†’        .collect();\n   112â†’\n   113â†’    Ok(WeeklyReport {\n   114â†’        week_start,\n   115â†’        week_end,\n   116â†’        current_week_stats,\n   117â†’        previous_week_stats,\n   118â†’        regressions,\n   119â†’        top_errors,\n   120â†’        total_sessions,\n   121â†’        total_issues_completed,\n   122â†’        total_cost_usd,\n   123â†’        sessions_comparison,\n   124â†’        personal_bests_achieved,\n   125â†’    })\n   126â†’}\n   127â†’\n   128â†’/// Format weekly report as markdown\n   129â†’pub fn format_report_markdown(report: &WeeklyReport) -> String {\n   130â†’    let mut output = String::new();\n   131â†’\n   132â†’    // Header\n   133â†’    output.push_str(\"# Weekly Autopilot Metrics Report\\n\\n\");\n   134â†’    output.push_str(&format!(\n   135â†’        \"**Week:** {} to {}\\n\\n\",\n   136â†’        report.week_start.format(\"%Y-%m-%d\"),\n   137â†’        report.week_end.format(\"%Y-%m-%d\")\n   138â†’    ));\n   139â†’    output.push_str(&format!(\"**Generated:** {}\\n\\n\", Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\")));\n   140â†’\n   141â†’    output.push_str(\"---\\n\\n\");\n   142â†’\n   143â†’    // Executive Summary\n   144â†’    output.push_str(\"## Executive Summary\\n\\n\");\n   145â†’    output.push_str(&format!(\"- **Total Sessions:** {}\\n\", report.total_sessions));\n   146â†’    output.push_str(&format!(\"- **Issues Completed:** {}\\n\", report.total_issues_completed));\n   147â†’    output.push_str(&format!(\"- **Total Cost:** ${:.4}\\n\", report.total_cost_usd));\n   148â†’\n   149â†’    if !report.regressions.is_empty() {\n   150â†’        let critical_count = report.regressions.iter()\n   151â†’            .filter(|r| matches!(r.severity, RegressionSeverity::Critical))\n   152â†’            .count();\n   153â†’        output.push_str(&format!(\"- **âš ï¸ Regressions Detected:** {} ({} critical)\\n\",\n   154â†’            report.regressions.len(), critical_count));\n   155â†’    } else {\n   156â†’        output.push_str(\"- **âœ… No Regressions:** All metrics within acceptable ranges\\n\");\n   157â†’    }\n   158â†’\n   159â†’    output.push_str(\"\\n\");\n   160â†’\n   161â†’    // Personal Bests Achieved\n   162â†’    if !report.personal_bests_achieved.is_empty() {\n   163â†’        output.push_str(\"## ðŸ† Personal Bests Achieved This Week\\n\\n\");\n   164â†’        for best in &report.personal_bests_achieved {\n   165â†’            output.push_str(&format!(\"- **{}:** {:.2}\", best.metric, best.value));\n   166â†’            if let Some(ref context) = best.context {\n   167â†’                output.push_str(&format!(\" ({})\", context));\n   168â†’            }\n   169â†’            output.push_str(\"\\n\");\n   170â†’        }\n   171â†’        output.push_str(\"\\n\");\n   172â†’    }\n   173â†’\n   174â†’    // Week-over-Week Comparison\n   175â†’    output.push_str(\"## Week-over-Week Comparison\\n\\n\");\n   176â†’\n   177â†’    let comp = &report.sessions_comparison;\n   178â†’    let sessions_change = if comp.previous_week_sessions > 0 {\n   179â†’        ((comp.current_week_sessions as f64 - comp.previous_week_sessions as f64)\n   180â†’            / comp.previous_week_sessions as f64) * 100.0\n   181â†’    } else {\n   182â†’        0.0\n   183â†’    };\n   184â†’\n   185â†’    let issues_change = if comp.previous_week_issues > 0 {\n   186â†’        ((comp.current_week_issues as f64 - comp.previous_week_issues as f64)\n   187â†’            / comp.previous_week_issues as f64) * 100.0\n   188â†’    } else {\n   189â†’        0.0\n   190â†’    };\n   191â†’\n   192â†’    let cost_change = if comp.previous_week_cost > 0.0 {\n   193â†’        ((comp.current_week_cost - comp.previous_week_cost)\n   194â†’            / comp.previous_week_cost) * 100.0\n   195â†’    } else {\n   196â†’        0.0\n   197â†’    };\n   198â†’\n   199â†’    output.push_str(\"| Metric | This Week | Last Week | Change |\\n\");\n   200â†’    output.push_str(\"|--------|-----------|-----------|--------|\\n\");\n   201â†’    output.push_str(&format!(\n   202â†’        \"| Sessions | {} | {} | {:+.1}% |\\n\",\n   203â†’        comp.current_week_sessions, comp.previous_week_sessions, sessions_change\n   204â†’    ));\n   205â†’    output.push_str(&format!(\n   206â†’        \"| Issues Completed | {} | {} | {:+.1}% |\\n\",\n   207â†’        comp.current_week_issues, comp.previous_week_issues, issues_change\n   208â†’    ));\n   209â†’    output.push_str(&format!(\n   210â†’        \"| Total Cost | ${:.4} | ${:.4} | {:+.1}% |\\n\",\n   211â†’        comp.current_week_cost, comp.previous_week_cost, cost_change\n   212â†’    ));\n   213â†’\n   214â†’    output.push_str(\"\\n\");\n   215â†’\n   216â†’    // Key Metrics\n   217â†’    output.push_str(\"## Key Metrics\\n\\n\");\n   218â†’\n   219â†’    let metrics_to_report = vec![\n   220â†’        (\"tool_error_rate\", \"Tool Error Rate\", \"%\", 100.0, true),\n   221â†’        (\"completion_rate\", \"Completion Rate\", \"%\", 100.0, false),\n   222â†’        (\"cost_per_issue\", \"Cost per Issue\", \"$\", 1.0, true),\n   223â†’        (\"duration_per_issue\", \"Duration per Issue\", \"s\", 1.0, true),\n   224â†’        (\"tokens_per_issue\", \"Tokens per Issue\", \"\", 1.0, true),\n   225â†’    ];\n   226â†’\n   227â†’    output.push_str(\"| Metric | This Week | Last Week | Change | Status |\\n\");\n   228â†’    output.push_str(\"|--------|-----------|-----------|--------|--------|\\n\");\n   229â†’\n   230â†’    for (key, name, unit, multiplier, lower_is_better) in metrics_to_report {\n   231â†’        let current_val = report.current_week_stats.get(key).copied().unwrap_or(0.0) * multiplier;\n   232â†’        let previous_val = report.previous_week_stats.get(key).copied().unwrap_or(0.0) * multiplier;\n   233â†’\n   234â†’        let change = if previous_val > 0.0 {\n   235â†’            ((current_val - previous_val) / previous_val) * 100.0\n   236â†’        } else {\n   237â†’            0.0\n   238â†’        };\n   239â†’\n   240â†’        let status = if change.abs() < 5.0 {\n   241â†’            \"â†’ Stable\"\n   242â†’        } else if lower_is_better {\n   243â†’            if change < 0.0 { \"âœ… Improving\" } else { \"âš ï¸ Degrading\" }\n   244â†’        } else {\n   245â†’            if change > 0.0 { \"âœ… Improving\" } else { \"âš ï¸ Degrading\" }\n   246â†’        };\n   247â†’\n   248â†’        let current_formatted = if unit == \"$\" {\n   249â†’            format!(\"{}{:.4}\", unit, current_val)\n   250â†’        } else if unit == \"%\" {\n   251â†’            format!(\"{:.1}{}\", current_val, unit)\n   252â†’        } else {\n   253â†’            format!(\"{:.1}{}\", current_val, unit)\n   254â†’        };\n   255â†’\n   256â†’        let previous_formatted = if unit == \"$\" {\n   257â†’            format!(\"{}{:.4}\", unit, previous_val)\n   258â†’        } else if unit == \"%\" {\n   259â†’            format!(\"{:.1}{}\", previous_val, unit)\n   260â†’        } else {\n   261â†’            format!(\"{:.1}{}\", previous_val, unit)\n   262â†’        };\n   263â†’\n   264â†’        output.push_str(&format!(\n   265â†’            \"| {} | {} | {} | {:+.1}% | {} |\\n\",\n   266â†’            name, current_formatted, previous_formatted, change, status\n   267â†’        ));\n   268â†’    }\n   269â†’\n   270â†’    output.push_str(\"\\n\");\n   271â†’\n   272â†’    // Regression Alerts\n   273â†’    if !report.regressions.is_empty() {\n   274â†’        output.push_str(\"## âš ï¸ Regression Alerts\\n\\n\");\n   275â†’\n   276â†’        for reg in &report.regressions {\n   277â†’            let severity_emoji = match reg.severity {\n   278â†’                RegressionSeverity::Critical => \"ðŸ”´\",\n   279â†’                RegressionSeverity::Error => \"ðŸŸ \",\n   280â†’                RegressionSeverity::Warning => \"ðŸŸ¡\",\n   281â†’            };\n   282â†’\n   283â†’            output.push_str(&format!(\n   284â†’                \"### {} {} - {:?}\\n\\n\",\n   285â†’                severity_emoji,\n   286â†’                reg.dimension.replace(\"_\", \" \").to_uppercase(),\n   287â†’                reg.severity\n   288â†’            ));\n   289â†’            output.push_str(&format!(\"- **Baseline:** {:.4}\\n\", reg.baseline_value));\n   290â†’            output.push_str(&format!(\"- **Current:** {:.4}\\n\", reg.current_value));\n   291â†’            output.push_str(&format!(\"- **Degradation:** {:.1}%\\n\", reg.percent_worse));\n   292â†’            output.push_str(&format!(\"- **Deviation:** {:.2}Ïƒ\\n\", reg.deviation_sigma));\n   293â†’            output.push_str(\"\\n\");\n   294â†’        }\n   295â†’    }\n   296â†’\n   297â†’    // Top Errors\n   298â†’    if !report.top_errors.is_empty() {\n   299â†’        output.push_str(\"## Top Error Tools (This Week)\\n\\n\");\n   300â†’        output.push_str(\"| Tool | Error Count |\\n\");\n   301â†’        output.push_str(\"|------|-------------|\\n\");\n   302â†’\n   303â†’        for (tool, count) in &report.top_errors {\n   304â†’            output.push_str(&format!(\"| {} | {} |\\n\", tool, count));\n   305â†’        }\n   306â†’\n   307â†’        output.push_str(\"\\n\");\n   308â†’    }\n   309â†’\n   310â†’    // APM Analysis (if available)\n   311â†’    if let Some(current_apm) = report.current_week_stats.get(\"apm\") {\n   312â†’        if let Some(previous_apm) = report.previous_week_stats.get(\"apm\") {\n   313â†’            output.push_str(\"## Actions Per Minute (APM) Trend\\n\\n\");\n   314â†’\n   315â†’            let apm_change = if *previous_apm > 0.0 {\n   316â†’                ((current_apm - previous_apm) / previous_apm) * 100.0\n   317â†’            } else {\n   318â†’                0.0\n   319â†’            };\n   320â†’\n   321â†’            output.push_str(&format!(\"- **This Week:** {:.1} APM\\n\", current_apm));\n   322â†’            output.push_str(&format!(\"- **Last Week:** {:.1} APM\\n\", previous_apm));\n   323â†’            output.push_str(&format!(\"- **Change:** {:+.1}%\\n\\n\", apm_change));\n   324â†’\n   325â†’            if apm_change > 10.0 {\n   326â†’                output.push_str(\"âœ¨ **Velocity increasing!** Autopilot is working faster.\\n\\n\");\n   327â†’            } else if apm_change < -10.0 {\n   328â†’                output.push_str(\"âš ï¸ **Velocity decreasing.** Consider investigating performance bottlenecks.\\n\\n\");\n   329â†’            }\n   330â†’        }\n   331â†’    }\n   332â†’\n   333â†’    // Recommendations\n   334â†’    output.push_str(\"## Recommendations\\n\\n\");\n   335â†’\n   336â†’    if report.regressions.is_empty() && report.top_errors.is_empty() {\n   337â†’        output.push_str(\"âœ… All metrics look good! Keep up the great work.\\n\\n\");\n   338â†’    } else {\n   339â†’        if !report.regressions.is_empty() {\n   340â†’            output.push_str(\"1. **Address Regressions:** Investigate the metrics that have degraded and identify root causes.\\n\");\n   341â†’        }\n   342â†’\n   343â†’        if !report.top_errors.is_empty() {\n   344â†’            output.push_str(\"2. **Reduce Tool Errors:** Focus on the top error-prone tools listed above.\\n\");\n   345â†’        }\n   346â†’\n   347â†’        if let Some(error_rate) = report.current_week_stats.get(\"tool_error_rate\") {\n   348â†’            if *error_rate > 0.10 {\n   349â†’                output.push_str(\"3. **High Error Rate:** Tool error rate exceeds 10%. Review error logs and improve error handling.\\n\");\n   350â†’            }\n   351â†’        }\n   352â†’\n   353â†’        output.push_str(\"\\n\");\n   354â†’    }\n   355â†’\n   356â†’    // Footer\n   357â†’    output.push_str(\"---\\n\\n\");\n   358â†’    output.push_str(\"*This report was automatically generated by the autopilot metrics system (d-004).*\\n\");\n   359â†’    output.push_str(\"*Run `cargo autopilot metrics report` to generate a new report.*\\n\");\n   360â†’\n   361â†’    output\n   362â†’}\n   363â†’\n   364â†’/// Print weekly report to console with colors\n   365â†’pub fn print_report_console(report: &WeeklyReport) {\n   366â†’    println!(\"{}\", \"=\".repeat(80).cyan());\n   367â†’    println!(\"{}\", \"WEEKLY AUTOPILOT METRICS REPORT\".cyan().bold());\n   368â†’    println!(\"{}\", \"=\".repeat(80).cyan());\n   369â†’    println!();\n   370â†’\n   371â†’    println!(\"{} {} to {}\",\n   372â†’        \"Week:\".bold(),\n   373â†’        report.week_start.format(\"%Y-%m-%d\"),\n   374â†’        report.week_end.format(\"%Y-%m-%d\")\n   375â†’    );\n   376â†’    println!(\"{} {}\", \"Generated:\".bold(), Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\"));\n   377â†’    println!();\n   378â†’\n   379â†’    // Executive Summary\n   380â†’    println!(\"{}\", \"EXECUTIVE SUMMARY\".yellow().bold());\n   381â†’    println!(\"  Sessions:          {}\", report.total_sessions.to_string().cyan());\n   382â†’    println!(\"  Issues Completed:  {}\", report.total_issues_completed.to_string().cyan());\n   383â†’    println!(\"  Total Cost:        {}\", format!(\"${:.4}\", report.total_cost_usd).cyan());\n   384â†’\n   385â†’    if !report.regressions.is_empty() {\n   386â†’        let critical = report.regressions.iter()\n   387â†’            .filter(|r| matches!(r.severity, RegressionSeverity::Critical))\n   388â†’            .count();\n   389â†’        println!(\"  Regressions:       {} ({} critical)\",\n   390â†’            report.regressions.len().to_string().red(),\n   391â†’            critical.to_string().red().bold()\n   392â†’        );\n   393â†’    } else {\n   394â†’        println!(\"  Regressions:       {}\", \"None\".green());\n   395â†’    }\n   396â†’    println!();\n   397â†’\n   398â†’    // Personal Bests\n   399â†’    if !report.personal_bests_achieved.is_empty() {\n   400â†’        println!(\"{}\", \"ðŸ† PERSONAL BESTS ACHIEVED THIS WEEK\".yellow().bold());\n   401â†’        for best in &report.personal_bests_achieved {\n   402â†’            print!(\"  {}: {:.2}\", best.metric.cyan().bold(), best.value.to_string().green().bold());\n   403â†’            if let Some(ref context) = best.context {\n   404â†’                print!(\" ({})\", context.dimmed());\n   405â†’            }\n   406â†’            println!();\n   407â†’        }\n   408â†’        println!();\n   409â†’    }\n   410â†’\n   411â†’    // Week-over-Week\n   412â†’    println!(\"{}\", \"WEEK-OVER-WEEK COMPARISON\".yellow().bold());\n   413â†’\n   414â†’    let comp = &report.sessions_comparison;\n   415â†’    let sessions_change = if comp.previous_week_sessions > 0 {\n   416â†’        ((comp.current_week_sessions as f64 - comp.previous_week_sessions as f64)\n   417â†’            / comp.previous_week_sessions as f64) * 100.0\n   418â†’    } else {\n   419â†’        0.0\n   420â†’    };\n   421â†’\n   422â†’    println!(\"  Sessions:   {} â†’ {} ({:+.1}%)\",\n   423â†’        comp.previous_week_sessions,\n   424â†’        comp.current_week_sessions,\n   425â†’        sessions_change\n   426â†’    );\n   427â†’\n   428â†’    let issues_change = if comp.previous_week_issues > 0 {\n   429â†’        ((comp.current_week_issues as f64 - comp.previous_week_issues as f64)\n   430â†’            / comp.previous_week_issues as f64) * 100.0\n   431â†’    } else {\n   432â†’        0.0\n   433â†’    };\n   434â†’\n   435â†’    println!(\"  Issues:     {} â†’ {} ({:+.1}%)\",\n   436â†’        comp.previous_week_issues,\n   437â†’        comp.current_week_issues,\n   438â†’        issues_change\n   439â†’    );\n   440â†’\n   441â†’    let cost_change = if comp.previous_week_cost > 0.0 {\n   442â†’        ((comp.current_week_cost - comp.previous_week_cost) / comp.previous_week_cost) * 100.0\n   443â†’    } else {\n   444â†’        0.0\n   445â†’    };\n   446â†’\n   447â†’    println!(\"  Cost:       ${:.4} â†’ ${:.4} ({:+.1}%)\",\n   448â†’        comp.previous_week_cost,\n   449â†’        comp.current_week_cost,\n   450â†’        cost_change\n   451â†’    );\n   452â†’    println!();\n   453â†’\n   454â†’    // Regressions\n   455â†’    if !report.regressions.is_empty() {\n   456â†’        println!(\"{}\", \"REGRESSIONS DETECTED\".red().bold());\n   457â†’        for reg in &report.regressions {\n   458â†’            let severity_str = match reg.severity {\n   459â†’                RegressionSeverity::Critical => \"CRITICAL\".red().bold(),\n   460â†’                RegressionSeverity::Error => \"ERROR\".red(),\n   461â†’                RegressionSeverity::Warning => \"WARNING\".yellow(),\n   462â†’            };\n   463â†’\n   464â†’            println!(\"  {} {}: {:.4} â†’ {:.4} ({:+.1}%)\",\n   465â†’                severity_str,\n   466â†’                reg.dimension,\n   467â†’                reg.baseline_value,\n   468â†’                reg.current_value,\n   469â†’                reg.percent_worse\n   470â†’            );\n   471â†’        }\n   472â†’        println!();\n   473â†’    }\n   474â†’\n   475â†’    // Top Errors\n   476â†’    if !report.top_errors.is_empty() {\n   477â†’        println!(\"{}\", \"TOP ERROR TOOLS\".yellow().bold());\n   478â†’        for (tool, count) in &report.top_errors {\n   479â†’            println!(\"  {:20} {} errors\", tool, count);\n   480â†’        }\n   481â†’        println!();\n   482â†’    }\n   483â†’\n   484â†’    println!(\"{}\", \"=\".repeat(80).cyan());\n   485â†’}\n   486â†’\n   487â†’/// Save report to a file in docs/reports/\n   488â†’pub fn save_report_to_file(report: &WeeklyReport) -> Result<PathBuf> {\n   489â†’    use std::fs;\n   490â†’    use std::path::PathBuf;\n   491â†’\n   492â†’    // Create reports directory if it doesn't exist\n   493â†’    let reports_dir = PathBuf::from(\"docs/reports\");\n   494â†’    fs::create_dir_all(&reports_dir)?;\n   495â†’\n   496â†’    // Generate filename: weekly-YYYYMMDD.md\n   497â†’    let filename = format!(\"weekly-{}.md\", report.week_end.format(\"%Y%m%d\"));\n   498â†’    let filepath = reports_dir.join(&filename);\n   499â†’\n   500â†’    // Generate markdown content\n   501â†’    let content = format_report_markdown(report);\n   502â†’\n   503â†’    // Write to file\n   504â†’    fs::write(&filepath, content)?;\n   505â†’\n   506â†’    Ok(filepath)\n   507â†’}\n   508â†’\n   509â†’#[cfg(test)]\n   510â†’mod tests {\n   511â†’    use super::*;\n   512â†’\n   513â†’    #[test]\n   514â†’    fn test_format_report_markdown() {\n   515â†’        use std::collections::HashMap;\n   516â†’\n   517â†’        let mut current_stats = HashMap::new();\n   518â†’        current_stats.insert(\"tool_error_rate\".to_string(), 0.05);\n   519â†’        current_stats.insert(\"completion_rate\".to_string(), 0.95);\n   520â†’\n   521â†’        let mut previous_stats = HashMap::new();\n   522â†’        previous_stats.insert(\"tool_error_rate\".to_string(), 0.08);\n   523â†’        previous_stats.insert(\"completion_rate\".to_string(), 0.90);\n   524â†’\n   525â†’        let report = WeeklyReport {\n   526â†’            week_start: Utc::now() - chrono::Duration::days(7),\n   527â†’            week_end: Utc::now(),\n   528â†’            current_week_stats: current_stats,\n   529â†’            previous_week_stats: previous_stats,\n   530â†’            regressions: vec![],\n   531â†’            top_errors: vec![],\n   532â†’            total_sessions: 10,\n   533â†’            total_issues_completed: 25,\n   534â†’            total_cost_usd: 1.5,\n   535â†’            sessions_comparison: SessionComparison {\n   536â†’                current_week_sessions: 10,\n   537â†’                previous_week_sessions: 8,\n   538â†’                current_week_issues: 25,\n   539â†’                previous_week_issues: 20,\n   540â†’                current_week_cost: 1.5,\n   541â†’                previous_week_cost: 1.2,\n   542â†’            },\n   543â†’            personal_bests_achieved: vec![],\n   544â†’        };\n   545â†’\n   546â†’        let markdown = format_report_markdown(&report);\n   547â†’\n   548â†’        assert!(markdown.contains(\"# Weekly Autopilot Metrics Report\"));\n   549â†’        assert!(markdown.contains(\"Executive Summary\"));\n   550â†’        assert!(markdown.contains(\"Week-over-Week Comparison\"));\n   551â†’        assert!(markdown.contains(\"Key Metrics\"));\n   552â†’    }\n   553â†’}\n   554â†’\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"timestamp":"2025-12-23T19:51:12.936030179+00:00"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01R8N3KoR11FsKpJfjsmTJp5","type":"tool_result","content":"     1â†’//! Trajectory analysis and metrics computation for autopilot performance monitoring.\n     2â†’//!\n     3â†’//! This module provides comprehensive analysis of autopilot execution trajectories,\n     4â†’//! extracting performance, cost, quality, and error metrics from trajectory logs.\n     5â†’//! Used by the `cargo autopilot analyze` command to generate reports and detect\n     6â†’//! regressions.\n     7â†’//!\n     8â†’//! # Key Types\n     9â†’//!\n    10â†’//! - [`TrajectoryAnalysis`]: Complete analysis results for a single trajectory\n    11â†’//! - [`PerformanceMetrics`]: Timing and duration measurements\n    12â†’//! - [`CostMetrics`]: Token usage and API cost calculations\n    13â†’//! - [`ErrorMetrics`]: Tool errors and failure patterns\n    14â†’//! - [`QualityMetrics`]: Task completion and success indicators\n    15â†’//! - [`ToolUsageMetrics`]: Per-tool usage statistics\n    16â†’//!\n    17â†’//! # Usage\n    18â†’//!\n    19â†’//! ```no_run\n    20â†’//! use autopilot::analyze::analyze_trajectory_file;\n    21â†’//! use std::path::Path;\n    22â†’//!\n    23â†’//! let trajectory_path = Path::new(\"docs/logs/20251222/094938-task.json\");\n    24â†’//! let analysis = analyze_trajectory_file(trajectory_path)?;\n    25â†’//!\n    26â†’//! println!(\"Duration: {}ms\", analysis.performance.total_duration_ms);\n    27â†’//! println!(\"Tokens: {}\", analysis.cost.total_tokens);\n    28â†’//! println!(\"Error rate: {:.1}%\", analysis.errors.error_rate * 100.0);\n    29â†’//! # Ok::<(), Box<dyn std::error::Error>>(())\n    30â†’//! ```\n    31â†’//!\n    32â†’//! # Related Modules\n    33â†’//!\n    34â†’//! - [`crate::dashboard`]: Web UI for viewing analysis results\n    35â†’//! - [`crate::trajectory`]: Trajectory log parsing and types\n    36â†’//! - [`crate::learning`]: Apply learnings from analysis\n    37â†’\n    38â†’use std::collections::HashMap;\n    39â†’use std::path::Path;\n    40â†’\n    41â†’use chrono::{DateTime, Utc};\n    42â†’use colored::*;\n    43â†’use serde::{Deserialize, Serialize};\n    44â†’\n    45â†’use crate::trajectory::{StepType, Trajectory};\n    46â†’\n    47â†’/// Complete analysis of a single trajectory\n    48â†’#[derive(Debug, Clone, Serialize, Deserialize)]\n    49â†’pub struct TrajectoryAnalysis {\n    50â†’    pub session_id: String,\n    51â†’    pub model: String,\n    52â†’    pub prompt_preview: String,\n    53â†’    pub started_at: DateTime<Utc>,\n    54â†’    pub ended_at: Option<DateTime<Utc>>,\n    55â†’    pub performance: PerformanceMetrics,\n    56â†’    pub cost: CostMetrics,\n    57â†’    pub errors: ErrorMetrics,\n    58â†’    pub quality: QualityMetrics,\n    59â†’    pub tool_usage: ToolUsageMetrics,\n    60â†’}\n    61â†’\n    62â†’/// Performance timing metrics\n    63â†’#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n    64â†’pub struct PerformanceMetrics {\n    65â†’    pub total_duration_ms: u64,\n    66â†’    pub tool_latency_stats: LatencyStats,\n    67â†’    pub parallel_tool_batches: u32,\n    68â†’    pub total_tool_calls: u32,\n    69â†’}\n    70â†’\n    71â†’/// Latency statistics for distributions\n    72â†’#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n    73â†’pub struct LatencyStats {\n    74â†’    pub min_ms: u64,\n    75â†’    pub max_ms: u64,\n    76â†’    pub mean_ms: f64,\n    77â†’    pub p50_ms: u64,\n    78â†’    pub p95_ms: u64,\n    79â†’    pub count: usize,\n    80â†’}\n    81â†’\n    82â†’/// Cost and token metrics\n    83â†’#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n    84â†’pub struct CostMetrics {\n    85â†’    pub total_cost_usd: f64,\n    86â†’    pub input_tokens: u64,\n    87â†’    pub output_tokens: u64,\n    88â†’    pub cache_read_tokens: u64,\n    89â†’    pub cache_hit_rate: f64,\n    90â†’    pub tokens_by_step_type: HashMap<String, u64>,\n    91â†’}\n    92â†’\n    93â†’/// Error and failure metrics\n    94â†’#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n    95â†’pub struct ErrorMetrics {\n    96â†’    pub success: bool,\n    97â†’    pub total_tool_calls: u32,\n    98â†’    pub failed_tool_calls: u32,\n    99â†’    pub tool_error_rate: f64,\n   100â†’    pub errors_by_tool: HashMap<String, u32>,\n   101â†’}\n   102â†’\n   103â†’/// Quality and behavioral metrics\n   104â†’#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n   105â†’pub struct QualityMetrics {\n   106â†’    pub num_turns: u32,\n   107â†’    pub thinking_blocks: u32,\n   108â†’    pub avg_thinking_length: f64,\n   109â†’    pub tool_diversity: f64,\n   110â†’    pub unique_tools: u32,\n   111â†’}\n   112â†’\n   113â†’/// Tool usage breakdown\n   114â†’#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n   115â†’pub struct ToolUsageMetrics {\n   116â†’    pub total_calls: u32,\n   117â†’    pub calls_by_tool: HashMap<String, u32>,\n   118â†’    pub success_rate_by_tool: HashMap<String, f64>,\n   119â†’    pub most_used_tool: Option<String>,\n   120â†’}\n   121â†’\n   122â†’/// Aggregated metrics across multiple trajectories\n   123â†’#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n   124â†’pub struct AggregateAnalysis {\n   125â†’    pub trajectory_count: usize,\n   126â†’    pub date_range: Option<(DateTime<Utc>, DateTime<Utc>)>,\n   127â†’    pub by_model: HashMap<String, ModelStats>,\n   128â†’    pub total_cost_usd: f64,\n   129â†’    pub avg_cost_usd: f64,\n   130â†’    pub avg_duration_ms: f64,\n   131â†’    pub overall_success_rate: f64,\n   132â†’    pub avg_tool_error_rate: f64,\n   133â†’    pub avg_cache_hit_rate: f64,\n   134â†’    pub total_tool_calls: u32,\n   135â†’    pub top_error_tools: Vec<(String, u32)>,\n   136â†’}\n   137â†’\n   138â†’#[derive(Debug, Clone, Default, Serialize, Deserialize)]\n   139â†’pub struct ModelStats {\n   140â†’    pub count: usize,\n   141â†’    pub avg_cost: f64,\n   142â†’    pub avg_duration_ms: f64,\n   143â†’    pub success_rate: f64,\n   144â†’}\n   145â†’\n   146â†’/// Load a trajectory from a JSON file\n   147â†’pub fn load_trajectory(path: &Path) -> anyhow::Result<Trajectory> {\n   148â†’    let content = std::fs::read_to_string(path)?;\n   149â†’    let trajectory: Trajectory = serde_json::from_str(&content)?;\n   150â†’    Ok(trajectory)\n   151â†’}\n   152â†’\n   153â†’/// Analyze a single trajectory\n   154â†’pub fn analyze_trajectory(trajectory: &Trajectory) -> TrajectoryAnalysis {\n   155â†’    let performance = compute_performance(trajectory);\n   156â†’    let cost = compute_cost(trajectory);\n   157â†’    let errors = compute_errors(trajectory);\n   158â†’    let quality = compute_quality(trajectory);\n   159â†’    let tool_usage = compute_tool_usage(trajectory);\n   160â†’\n   161â†’    TrajectoryAnalysis {\n   162â†’        session_id: trajectory.session_id.clone(),\n   163â†’        model: trajectory.model.clone(),\n   164â†’        prompt_preview: truncate(&trajectory.prompt, 80),\n   165â†’        started_at: trajectory.started_at,\n   166â†’        ended_at: trajectory.ended_at,\n   167â†’        performance,\n   168â†’        cost,\n   169â†’        errors,\n   170â†’        quality,\n   171â†’        tool_usage,\n   172â†’    }\n   173â†’}\n   174â†’\n   175â†’/// Compute performance metrics\n   176â†’fn compute_performance(trajectory: &Trajectory) -> PerformanceMetrics {\n   177â†’    let total_duration_ms = trajectory\n   178â†’        .result\n   179â†’        .as_ref()\n   180â†’        .map(|r| r.duration_ms)\n   181â†’        .unwrap_or(0);\n   182â†’\n   183â†’    // Track tool call timestamps to compute latencies\n   184â†’    let mut pending_calls: HashMap<String, DateTime<Utc>> = HashMap::new();\n   185â†’    let mut latencies: Vec<u64> = Vec::new();\n   186â†’    let mut tool_intervals: Vec<(DateTime<Utc>, DateTime<Utc>)> = Vec::new();\n   187â†’    let mut total_tool_calls = 0u32;\n   188â†’\n   189â†’    for step in &trajectory.steps {\n   190â†’        match &step.step_type {\n   191â†’            StepType::ToolCall { tool_id, .. } => {\n   192â†’                total_tool_calls += 1;\n   193â†’                pending_calls.insert(tool_id.clone(), step.timestamp);\n   194â†’            }\n   195â†’            StepType::ToolResult { tool_id, .. } => {\n   196â†’                if let Some(start_time) = pending_calls.remove(tool_id) {\n   197â†’                    let latency = (step.timestamp - start_time).num_milliseconds().max(0) as u64;\n   198â†’                    latencies.push(latency);\n   199â†’                    tool_intervals.push((start_time, step.timestamp));\n   200â†’                }\n   201â†’            }\n   202â†’            _ => {}\n   203â†’        }\n   204â†’    }\n   205â†’\n   206â†’    let tool_latency_stats = compute_latency_stats(&latencies);\n   207â†’    let parallel_tool_batches = detect_parallel_batches(&tool_intervals);\n   208â†’\n   209â†’    PerformanceMetrics {\n   210â†’        total_duration_ms,\n   211â†’        tool_latency_stats,\n   212â†’        parallel_tool_batches,\n   213â†’        total_tool_calls,\n   214â†’    }\n   215â†’}\n   216â†’\n   217â†’/// Compute latency statistics from a list of latencies\n   218â†’fn compute_latency_stats(latencies: &[u64]) -> LatencyStats {\n   219â†’    if latencies.is_empty() {\n   220â†’        return LatencyStats::default();\n   221â†’    }\n   222â†’\n   223â†’    let mut sorted = latencies.to_vec();\n   224â†’    sorted.sort();\n   225â†’\n   226â†’    let count = sorted.len();\n   227â†’    let sum: u64 = sorted.iter().sum();\n   228â†’\n   229â†’    LatencyStats {\n   230â†’        min_ms: sorted[0],\n   231â†’        max_ms: sorted[count - 1],\n   232â†’        mean_ms: sum as f64 / count as f64,\n   233â†’        p50_ms: sorted[count / 2],\n   234â†’        p95_ms: sorted[(count * 95 / 100).min(count - 1)],\n   235â†’        count,\n   236â†’    }\n   237â†’}\n   238â†’\n   239â†’/// Detect number of parallel tool batches (overlapping tool calls)\n   240â†’fn detect_parallel_batches(intervals: &[(DateTime<Utc>, DateTime<Utc>)]) -> u32 {\n   241â†’    if intervals.is_empty() {\n   242â†’        return 0;\n   243â†’    }\n   244â†’\n   245â†’    let mut sorted: Vec<_> = intervals.to_vec();\n   246â†’    sorted.sort_by_key(|(start, _)| *start);\n   247â†’\n   248â†’    let mut batches = 1u32;\n   249â†’    let mut current_batch_end = sorted[0].1;\n   250â†’\n   251â†’    for (start, end) in sorted.iter().skip(1) {\n   252â†’        if *start > current_batch_end {\n   253â†’            // New batch - no overlap\n   254â†’            batches += 1;\n   255â†’            current_batch_end = *end;\n   256â†’        } else {\n   257â†’            // Overlapping - extend batch\n   258â†’            current_batch_end = std::cmp::max(current_batch_end, *end);\n   259â†’        }\n   260â†’    }\n   261â†’\n   262â†’    batches\n   263â†’}\n   264â†’\n   265â†’/// Compute cost metrics\n   266â†’fn compute_cost(trajectory: &Trajectory) -> CostMetrics {\n   267â†’    let usage = &trajectory.usage;\n   268â†’\n   269â†’    // Compute cache hit rate\n   270â†’    let total_input = usage.input_tokens + usage.cache_read_tokens;\n   271â†’    let cache_hit_rate = if total_input > 0 {\n   272â†’        usage.cache_read_tokens as f64 / total_input as f64\n   273â†’    } else {\n   274â†’        0.0\n   275â†’    };\n   276â†’\n   277â†’    // Tokens by step type\n   278â†’    let mut tokens_by_step_type: HashMap<String, u64> = HashMap::new();\n   279â†’\n   280â†’    for step in &trajectory.steps {\n   281â†’        let step_name = match &step.step_type {\n   282â†’            StepType::Thinking { .. } => \"thinking\",\n   283â†’            StepType::Assistant { .. } => \"assistant\",\n   284â†’            StepType::ToolCall { .. } => \"tool_call\",\n   285â†’            StepType::ToolResult { .. } => \"tool_result\",\n   286â†’            StepType::User { .. } => \"user\",\n   287â†’            StepType::SystemInit { .. } => \"system_init\",\n   288â†’            StepType::SystemStatus { .. } => \"system_status\",\n   289â†’            StepType::Subagent { .. } => \"subagent\",\n   290â†’        };\n   291â†’\n   292â†’        let entry = tokens_by_step_type.entry(step_name.to_string()).or_insert(0);\n   293â†’        if let Some(t) = step.tokens_out {\n   294â†’            *entry += t;\n   295â†’        }\n   296â†’    }\n   297â†’\n   298â†’    CostMetrics {\n   299â†’        total_cost_usd: usage.cost_usd,\n   300â†’        input_tokens: usage.input_tokens,\n   301â†’        output_tokens: usage.output_tokens,\n   302â†’        cache_read_tokens: usage.cache_read_tokens,\n   303â†’        cache_hit_rate,\n   304â†’        tokens_by_step_type,\n   305â†’    }\n   306â†’}\n   307â†’\n   308â†’/// Compute error metrics\n   309â†’fn compute_errors(trajectory: &Trajectory) -> ErrorMetrics {\n   310â†’    let mut total_tool_calls = 0u32;\n   311â†’    let mut failed_tool_calls = 0u32;\n   312â†’    let mut errors_by_tool: HashMap<String, u32> = HashMap::new();\n   313â†’    let mut pending_tools: HashMap<String, String> = HashMap::new(); // tool_id -> tool_name\n   314â†’\n   315â†’    for step in &trajectory.steps {\n   316â†’        match &step.step_type {\n   317â†’            StepType::ToolCall { tool, tool_id, .. } => {\n   318â†’                total_tool_calls += 1;\n   319â†’                pending_tools.insert(tool_id.clone(), tool.clone());\n   320â†’            }\n   321â†’            StepType::ToolResult { tool_id, success, .. } => {\n   322â†’                if !*success {\n   323â†’                    failed_tool_calls += 1;\n   324â†’                    if let Some(tool_name) = pending_tools.get(tool_id) {\n   325â†’                        *errors_by_tool.entry(tool_name.clone()).or_insert(0) += 1;\n   326â†’                    }\n   327â†’                }\n   328â†’            }\n   329â†’            _ => {}\n   330â†’        }\n   331â†’    }\n   332â†’\n   333â†’    let tool_error_rate = if total_tool_calls > 0 {\n   334â†’        failed_tool_calls as f64 / total_tool_calls as f64\n   335â†’    } else {\n   336â†’        0.0\n   337â†’    };\n   338â†’\n   339â†’    ErrorMetrics {\n   340â†’        success: trajectory.result.as_ref().map(|r| r.success).unwrap_or(false),\n   341â†’        total_tool_calls,\n   342â†’        failed_tool_calls,\n   343â†’        tool_error_rate,\n   344â†’        errors_by_tool,\n   345â†’    }\n   346â†’}\n   347â†’\n   348â†’/// Compute quality metrics\n   349â†’fn compute_quality(trajectory: &Trajectory) -> QualityMetrics {\n   350â†’    let mut thinking_blocks = 0u32;\n   351â†’    let mut thinking_lengths: Vec<usize> = Vec::new();\n   352â†’    let mut unique_tools: std::collections::HashSet<String> = std::collections::HashSet::new();\n   353â†’    let mut tool_call_count = 0u32;\n   354â†’\n   355â†’    for step in &trajectory.steps {\n   356â†’        match &step.step_type {\n   357â†’            StepType::Thinking { content, .. } => {\n   358â†’                thinking_blocks += 1;\n   359â†’                thinking_lengths.push(content.len());\n   360â†’            }\n   361â†’            StepType::ToolCall { tool, .. } => {\n   362â†’                tool_call_count += 1;\n   363â†’                unique_tools.insert(tool.clone());\n   364â†’            }\n   365â†’            _ => {}\n   366â†’        }\n   367â†’    }\n   368â†’\n   369â†’    let avg_thinking_length = if thinking_lengths.is_empty() {\n   370â†’        0.0\n   371â†’    } else {\n   372â†’        thinking_lengths.iter().sum::<usize>() as f64 / thinking_lengths.len() as f64\n   373â†’    };\n   374â†’\n   375â†’    let tool_diversity = if tool_call_count > 0 {\n   376â†’        unique_tools.len() as f64 / tool_call_count as f64\n   377â†’    } else {\n   378â†’        0.0\n   379â†’    };\n   380â†’\n   381â†’    QualityMetrics {\n   382â†’        num_turns: trajectory.result.as_ref().map(|r| r.num_turns).unwrap_or(0),\n   383â†’        thinking_blocks,\n   384â†’        avg_thinking_length,\n   385â†’        tool_diversity,\n   386â†’        unique_tools: unique_tools.len() as u32,\n   387â†’    }\n   388â†’}\n   389â†’\n   390â†’/// Compute tool usage metrics\n   391â†’fn compute_tool_usage(trajectory: &Trajectory) -> ToolUsageMetrics {\n   392â†’    let mut calls_by_tool: HashMap<String, u32> = HashMap::new();\n   393â†’    let mut successes_by_tool: HashMap<String, u32> = HashMap::new();\n   394â†’    let mut pending_tools: HashMap<String, String> = HashMap::new();\n   395â†’\n   396â†’    for step in &trajectory.steps {\n   397â†’        match &step.step_type {\n   398â†’            StepType::ToolCall { tool, tool_id, .. } => {\n   399â†’                *calls_by_tool.entry(tool.clone()).or_insert(0) += 1;\n   400â†’                pending_tools.insert(tool_id.clone(), tool.clone());\n   401â†’            }\n   402â†’            StepType::ToolResult { tool_id, success, .. } => {\n   403â†’                if *success {\n   404â†’                    if let Some(tool_name) = pending_tools.get(tool_id) {\n   405â†’                        *successes_by_tool.entry(tool_name.clone()).or_insert(0) += 1;\n   406â†’                    }\n   407â†’                }\n   408â†’            }\n   409â†’            _ => {}\n   410â†’        }\n   411â†’    }\n   412â†’\n   413â†’    let total_calls: u32 = calls_by_tool.values().sum();\n   414â†’\n   415â†’    let success_rate_by_tool: HashMap<String, f64> = calls_by_tool\n   416â†’        .iter()\n   417â†’        .map(|(tool, count)| {\n   418â†’            let successes = successes_by_tool.get(tool).copied().unwrap_or(0);\n   419â†’            let rate = if *count > 0 {\n   420â†’                successes as f64 / *count as f64\n   421â†’            } else {\n   422â†’                0.0\n   423â†’            };\n   424â†’            (tool.clone(), rate)\n   425â†’        })\n   426â†’        .collect();\n   427â†’\n   428â†’    let most_used_tool = calls_by_tool\n   429â†’        .iter()\n   430â†’        .max_by_key(|(_, count)| *count)\n   431â†’        .map(|(tool, _)| tool.clone());\n   432â†’\n   433â†’    ToolUsageMetrics {\n   434â†’        total_calls,\n   435â†’        calls_by_tool,\n   436â†’        success_rate_by_tool,\n   437â†’        most_used_tool,\n   438â†’    }\n   439â†’}\n   440â†’\n   441â†’/// Aggregate analysis across multiple trajectories\n   442â†’pub fn aggregate_analyses(analyses: &[TrajectoryAnalysis]) -> AggregateAnalysis {\n   443â†’    if analyses.is_empty() {\n   444â†’        return AggregateAnalysis::default();\n   445â†’    }\n   446â†’\n   447â†’    let trajectory_count = analyses.len();\n   448â†’\n   449â†’    // Date range\n   450â†’    let min_date = analyses.iter().map(|a| a.started_at).min();\n   451â†’    let max_date = analyses.iter().filter_map(|a| a.ended_at).max();\n   452â†’    let date_range = min_date.and_then(|min| max_date.map(|max| (min, max)));\n   453â†’\n   454â†’    // By model stats\n   455â†’    let mut by_model: HashMap<String, Vec<&TrajectoryAnalysis>> = HashMap::new();\n   456â†’    for analysis in analyses {\n   457â†’        by_model\n   458â†’            .entry(analysis.model.clone())\n   459â†’            .or_default()\n   460â†’            .push(analysis);\n   461â†’    }\n   462â†’\n   463â†’    let by_model_stats: HashMap<String, ModelStats> = by_model\n   464â†’        .iter()\n   465â†’        .map(|(model, runs)| {\n   466â†’            let count = runs.len();\n   467â†’            let avg_cost = runs.iter().map(|r| r.cost.total_cost_usd).sum::<f64>() / count as f64;\n   468â†’            let avg_duration =\n   469â†’                runs.iter().map(|r| r.performance.total_duration_ms).sum::<u64>() as f64\n   470â†’                    / count as f64;\n   471â†’            let success_rate = runs.iter().filter(|r| r.errors.success).count() as f64 / count as f64;\n   472â†’            (\n   473â†’                model.clone(),\n   474â†’                ModelStats {\n   475â†’                    count,\n   476â†’                    avg_cost,\n   477â†’                    avg_duration_ms: avg_duration,\n   478â†’                    success_rate,\n   479â†’                },\n   480â†’            )\n   481â†’        })\n   482â†’        .collect();\n   483â†’\n   484â†’    // Aggregates\n   485â†’    let total_cost_usd: f64 = analyses.iter().map(|a| a.cost.total_cost_usd).sum();\n   486â†’    let avg_cost_usd = total_cost_usd / trajectory_count as f64;\n   487â†’    let avg_duration_ms = analyses\n   488â†’        .iter()\n   489â†’        .map(|a| a.performance.total_duration_ms)\n   490â†’        .sum::<u64>() as f64\n   491â†’        / trajectory_count as f64;\n   492â†’    let overall_success_rate =\n   493â†’        analyses.iter().filter(|a| a.errors.success).count() as f64 / trajectory_count as f64;\n   494â†’    let avg_tool_error_rate =\n   495â†’        analyses.iter().map(|a| a.errors.tool_error_rate).sum::<f64>() / trajectory_count as f64;\n   496â†’    let avg_cache_hit_rate =\n   497â†’        analyses.iter().map(|a| a.cost.cache_hit_rate).sum::<f64>() / trajectory_count as f64;\n   498â†’    let total_tool_calls: u32 = analyses.iter().map(|a| a.tool_usage.total_calls).sum();\n   499â†’\n   500â†’    // Top error tools\n   501â†’    let mut error_tools: HashMap<String, u32> = HashMap::new();\n   502â†’    for analysis in analyses {\n   503â†’        for (tool, count) in &analysis.errors.errors_by_tool {\n   504â†’            *error_tools.entry(tool.clone()).or_insert(0) += count;\n   505â†’        }\n   506â†’    }\n   507â†’    let mut top_error_tools: Vec<(String, u32)> = error_tools.into_iter().collect();\n   508â†’    top_error_tools.sort_by(|a, b| b.1.cmp(&a.1));\n   509â†’    top_error_tools.truncate(5);\n   510â†’\n   511â†’    AggregateAnalysis {\n   512â†’        trajectory_count,\n   513â†’        date_range,\n   514â†’        by_model: by_model_stats,\n   515â†’        total_cost_usd,\n   516â†’        avg_cost_usd,\n   517â†’        avg_duration_ms,\n   518â†’        overall_success_rate,\n   519â†’        avg_tool_error_rate,\n   520â†’        avg_cache_hit_rate,\n   521â†’        total_tool_calls,\n   522â†’        top_error_tools,\n   523â†’    }\n   524â†’}\n   525â†’\n   526â†’/// Print analysis in human-readable format\n   527â†’pub fn print_analysis(analysis: &TrajectoryAnalysis) {\n   528â†’    let sep = \"=\".repeat(80);\n   529â†’    println!(\"{}\", sep.bright_blue());\n   530â†’    println!(\n   531â†’        \"{}\",\n   532â†’        format!(\"Trajectory Analysis: {}\", &analysis.session_id[..8.min(analysis.session_id.len())])\n   533â†’            .bright_white()\n   534â†’            .bold()\n   535â†’    );\n   536â†’    println!(\"{}\", sep.bright_blue());\n   537â†’\n   538â†’    // Performance\n   539â†’    println!(\"\\n{}\", \"PERFORMANCE\".yellow().bold());\n   540â†’    println!(\n   541â†’        \"  Duration:          {:.1}s\",\n   542â†’        analysis.performance.total_duration_ms as f64 / 1000.0\n   543â†’    );\n   544â†’    if analysis.performance.tool_latency_stats.count > 0 {\n   545â†’        let stats = &analysis.performance.tool_latency_stats;\n   546â†’        println!(\n   547â†’            \"  Tool Latency:      p50={}ms, p95={}ms (n={})\",\n   548â†’            stats.p50_ms, stats.p95_ms, stats.count\n   549â†’        );\n   550â†’    }\n   551â†’    println!(\n   552â†’        \"  Parallel Batches:  {}\",\n   553â†’        analysis.performance.parallel_tool_batches\n   554â†’    );\n   555â†’    println!(\"  Total Tool Calls:  {}\", analysis.performance.total_tool_calls);\n   556â†’\n   557â†’    // Cost\n   558â†’    println!(\"\\n{}\", \"COST\".yellow().bold());\n   559â†’    println!(\"  Total:             ${:.4}\", analysis.cost.total_cost_usd);\n   560â†’    println!(\n   561â†’        \"  Input Tokens:      {}\",\n   562â†’        format_tokens(analysis.cost.input_tokens)\n   563â†’    );\n   564â†’    println!(\n   565â†’        \"  Output Tokens:     {}\",\n   566â†’        format_tokens(analysis.cost.output_tokens)\n   567â†’    );\n   568â†’    println!(\"  Cache Hit Rate:    {:.1}%\", analysis.cost.cache_hit_rate * 100.0);\n   569â†’\n   570â†’    // Errors\n   571â†’    println!(\"\\n{}\", \"ERRORS\".yellow().bold());\n   572â†’    let success_str = if analysis.errors.success {\n   573â†’        \"YES\".green()\n   574â†’    } else {\n   575â†’        \"NO\".red()\n   576â†’    };\n   577â†’    println!(\"  Success:           {}\", success_str);\n   578â†’    println!(\n   579â†’        \"  Tool Error Rate:   {:.1}% ({}/{})\",\n   580â†’        analysis.errors.tool_error_rate * 100.0,\n   581â†’        analysis.errors.failed_tool_calls,\n   582â†’        analysis.errors.total_tool_calls\n   583â†’    );\n   584â†’    if !analysis.errors.errors_by_tool.is_empty() {\n   585â†’        println!(\"  Errors by Tool:\");\n   586â†’        for (tool, count) in &analysis.errors.errors_by_tool {\n   587â†’            println!(\"    {}: {}\", tool, count);\n   588â†’        }\n   589â†’    }\n   590â†’\n   591â†’    // Quality\n   592â†’    println!(\"\\n{}\", \"QUALITY\".yellow().bold());\n   593â†’    println!(\"  Turns:             {}\", analysis.quality.num_turns);\n   594â†’    println!(\"  Thinking Blocks:   {}\", analysis.quality.thinking_blocks);\n   595â†’    println!(\n   596â†’        \"  Tool Diversity:    {:.0}% ({} unique)\",\n   597â†’        analysis.quality.tool_diversity * 100.0,\n   598â†’        analysis.quality.unique_tools\n   599â†’    );\n   600â†’\n   601â†’    // Tool Usage\n   602â†’    if !analysis.tool_usage.calls_by_tool.is_empty() {\n   603â†’        println!(\"\\n{}\", \"TOOL USAGE\".yellow().bold());\n   604â†’        let mut tools: Vec<_> = analysis.tool_usage.calls_by_tool.iter().collect();\n   605â†’        tools.sort_by(|a, b| b.1.cmp(a.1));\n   606â†’        for (tool, count) in tools.iter().take(10) {\n   607â†’            let success_rate = analysis\n   608â†’                .tool_usage\n   609â†’                .success_rate_by_tool\n   610â†’                .get(*tool)\n   611â†’                .copied()\n   612â†’                .unwrap_or(0.0);\n   613â†’            println!(\"  {:20} {} calls, {:.0}% success\", tool, count, success_rate * 100.0);\n   614â†’        }\n   615â†’    }\n   616â†’\n   617â†’    println!(\"\\n{}\", sep.bright_blue());\n   618â†’}\n   619â†’\n   620â†’/// Print aggregate analysis\n   621â†’pub fn print_aggregate(analysis: &AggregateAnalysis) {\n   622â†’    let sep = \"=\".repeat(80);\n   623â†’    println!(\"{}\", sep.bright_blue());\n   624â†’    println!(\n   625â†’        \"{}\",\n   626â†’        format!(\"Aggregate Analysis: {} trajectories\", analysis.trajectory_count)\n   627â†’            .bright_white()\n   628â†’            .bold()\n   629â†’    );\n   630â†’    println!(\"{}\", sep.bright_blue());\n   631â†’\n   632â†’    // Overview\n   633â†’    println!(\"\\n{}\", \"OVERVIEW\".yellow().bold());\n   634â†’    println!(\"  Trajectories:      {}\", analysis.trajectory_count);\n   635â†’    println!(\"  Total Cost:        ${:.4}\", analysis.total_cost_usd);\n   636â†’    println!(\"  Avg Cost:          ${:.4}\", analysis.avg_cost_usd);\n   637â†’    println!(\"  Avg Duration:      {:.1}s\", analysis.avg_duration_ms / 1000.0);\n   638â†’    println!(\"  Success Rate:      {:.1}%\", analysis.overall_success_rate * 100.0);\n   639â†’    println!(\"  Avg Tool Errors:   {:.1}%\", analysis.avg_tool_error_rate * 100.0);\n   640â†’    println!(\"  Avg Cache Hit:     {:.1}%\", analysis.avg_cache_hit_rate * 100.0);\n   641â†’    println!(\"  Total Tool Calls:  {}\", analysis.total_tool_calls);\n   642â†’\n   643â†’    // By Model\n   644â†’    if !analysis.by_model.is_empty() {\n   645â†’        println!(\"\\n{}\", \"BY MODEL\".yellow().bold());\n   646â†’        for (model, stats) in &analysis.by_model {\n   647â†’            let model_short = model.split('-').take(3).collect::<Vec<_>>().join(\"-\");\n   648â†’            println!(\n   649â†’                \"  {:30} {} runs, ${:.4} avg, {:.1}% success\",\n   650â†’                model_short,\n   651â†’                stats.count,\n   652â†’                stats.avg_cost,\n   653â†’                stats.success_rate * 100.0\n   654â†’            );\n   655â†’        }\n   656â†’    }\n   657â†’\n   658â†’    // Top Error Tools\n   659â†’    if !analysis.top_error_tools.is_empty() {\n   660â†’        println!(\"\\n{}\", \"TOP ERROR TOOLS\".yellow().bold());\n   661â†’        for (tool, count) in &analysis.top_error_tools {\n   662â†’            println!(\"  {:20} {} errors\", tool, count);\n   663â†’        }\n   664â†’    }\n   665â†’\n   666â†’    println!(\"\\n{}\", sep.bright_blue());\n   667â†’}\n   668â†’\n   669â†’fn truncate(s: &str, max_len: usize) -> String {\n   670â†’    if s.len() <= max_len {\n   671â†’        s.to_string()\n   672â†’    } else {\n   673â†’        format!(\"{}...\", &s[..max_len - 3])\n   674â†’    }\n   675â†’}\n   676â†’\n   677â†’fn format_tokens(tokens: u64) -> String {\n   678â†’    if tokens >= 1_000_000 {\n   679â†’        format!(\"{:.1}M\", tokens as f64 / 1_000_000.0)\n   680â†’    } else if tokens >= 1_000 {\n   681â†’        format!(\"{:.1}K\", tokens as f64 / 1_000.0)\n   682â†’    } else {\n   683â†’        tokens.to_string()\n   684â†’    }\n   685â†’}\n   686â†’\n   687â†’//\n   688â†’// ===== Aggregate Metrics Analysis =====\n   689â†’//\n   690â†’\n   691â†’use crate::metrics::{MetricsDb, SessionMetrics};\n   692â†’\n   693â†’/// Aggregate statistics for a metric dimension from metrics database\n   694â†’#[derive(Debug, Clone, Serialize, Deserialize)]\n   695â†’pub struct MetricAggregateStats {\n   696â†’    pub dimension: String,\n   697â†’    pub count: usize,\n   698â†’    pub mean: f64,\n   699â†’    pub median: f64,\n   700â†’    pub p90: f64,\n   701â†’    pub p99: f64,\n   702â†’    pub min: f64,\n   703â†’    pub max: f64,\n   704â†’    pub stddev: f64,\n   705â†’}\n   706â†’\n   707â†’/// Trend direction for a metric\n   708â†’#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\n   709â†’pub enum TrendDirection {\n   710â†’    Improving,\n   711â†’    Stable,\n   712â†’    Degrading,\n   713â†’}\n   714â†’\n   715â†’/// Trend analysis for a metric over time\n   716â†’#[derive(Debug, Clone, Serialize, Deserialize)]\n   717â†’pub struct MetricTrend {\n   718â†’    pub dimension: String,\n   719â†’    pub direction: TrendDirection,\n   720â†’    pub percent_change: f64,\n   721â†’    pub recent: MetricAggregateStats,\n   722â†’    pub baseline: Option<MetricAggregateStats>,\n   723â†’}\n   724â†’\n   725â†’/// Detected regression in metrics\n   726â†’#[derive(Debug, Clone, Serialize, Deserialize)]\n   727â†’pub struct Regression {\n   728â†’    pub dimension: String,\n   729â†’    pub baseline_value: f64,\n   730â†’    pub current_value: f64,\n   731â†’    pub percent_worse: f64,\n   732â†’    pub is_critical: bool,\n   733â†’    pub severity: RegressionSeverity,\n   734â†’    pub deviation_sigma: f64,\n   735â†’}\n   736â†’\n   737â†’#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\n   738â†’pub enum RegressionSeverity {\n   739â†’    Warning,\n   740â†’    Error,\n   741â†’    Critical,\n   742â†’}\n   743â†’\n   744â†’/// Time period for analysis\n   745â†’#[derive(Debug, Clone, Copy)]\n   746â†’pub enum TimePeriod {\n   747â†’    Last7Days,\n   748â†’    Last30Days,\n   749â†’    LastWeek,\n   750â†’    ThisWeek,\n   751â†’    Custom { start: DateTime<Utc>, end: DateTime<Utc> },\n   752â†’}\n   753â†’\n   754â†’impl TimePeriod {\n   755â†’    /// Get the start and end timestamps for this period\n   756â†’    pub fn bounds(&self) -> (DateTime<Utc>, DateTime<Utc>) {\n   757â†’        use chrono::Datelike;\n   758â†’\n   759â†’        let now = Utc::now();\n   760â†’        match self {\n   761â†’            TimePeriod::Last7Days => (now - chrono::Duration::days(7), now),\n   762â†’            TimePeriod::Last30Days => (now - chrono::Duration::days(30), now),\n   763â†’            TimePeriod::LastWeek => {\n   764â†’                let days_since_monday = now.weekday().num_days_from_monday();\n   765â†’                let last_monday = now - chrono::Duration::days((days_since_monday + 7) as i64);\n   766â†’                let last_sunday = last_monday + chrono::Duration::days(6);\n   767â†’                (last_monday, last_sunday)\n   768â†’            }\n   769â†’            TimePeriod::ThisWeek => {\n   770â†’                let days_since_monday = now.weekday().num_days_from_monday();\n   771â†’                let this_monday = now - chrono::Duration::days(days_since_monday as i64);\n   772â†’                (this_monday, now)\n   773â†’            }\n   774â†’            TimePeriod::Custom { start, end } => (*start, *end),\n   775â†’        }\n   776â†’    }\n   777â†’\n   778â†’    pub fn name(&self) -> &'static str {\n   779â†’        match self {\n   780â†’            TimePeriod::Last7Days => \"Last 7 Days\",\n   781â†’            TimePeriod::Last30Days => \"Last 30 Days\",\n   782â†’            TimePeriod::LastWeek => \"Last Week\",\n   783â†’            TimePeriod::ThisWeek => \"This Week\",\n   784â†’            TimePeriod::Custom { .. } => \"Custom Period\",\n   785â†’        }\n   786â†’    }\n   787â†’}\n   788â†’\n   789â†’/// Calculate aggregate statistics from a list of values\n   790â†’fn calculate_metric_stats(dimension: &str, values: &[f64]) -> Option<MetricAggregateStats> {\n   791â†’    if values.is_empty() {\n   792â†’        return None;\n   793â†’    }\n   794â†’\n   795â†’    use statrs::statistics::{Data, Distribution, OrderStatistics, Min, Max};\n   796â†’\n   797â†’    let mut data = Data::new(values.to_vec());\n   798â†’    let mean = data.mean().unwrap_or(0.0);\n   799â†’    let stddev = data.std_dev().unwrap_or(0.0);\n   800â†’    let median = data.median();\n   801â†’    let p90 = data.percentile(90);\n   802â†’    let p99 = data.percentile(99);\n   803â†’    let min = data.min();\n   804â†’    let max = data.max();\n   805â†’\n   806â†’    Some(MetricAggregateStats {\n   807â†’        dimension: dimension.to_string(),\n   808â†’        count: values.len(),\n   809â†’        mean,\n   810â†’        median,\n   811â†’        p90,\n   812â†’        p99,\n   813â†’        min,\n   814â†’        max,\n   815â†’        stddev,\n   816â†’    })\n   817â†’}\n   818â†’\n   819â†’/// Get sessions within a time period\n   820â†’pub fn get_sessions_in_period(\n   821â†’    db: &MetricsDb,\n   822â†’    period: TimePeriod,\n   823â†’) -> anyhow::Result<Vec<SessionMetrics>> {\n   824â†’    let (start, end) = period.bounds();\n   825â†’    let all_sessions = db.get_all_sessions()?;\n   826â†’\n   827â†’    Ok(all_sessions\n   828â†’        .into_iter()\n   829â†’        .filter(|s| s.timestamp >= start && s.timestamp <= end)\n   830â†’        .collect())\n   831â†’}\n   832â†’\n   833â†’/// Get sessions between two specific dates\n   834â†’pub fn get_sessions_between_dates(\n   835â†’    db: &MetricsDb,\n   836â†’    start: DateTime<Utc>,\n   837â†’    end: DateTime<Utc>,\n   838â†’) -> anyhow::Result<Vec<SessionMetrics>> {\n   839â†’    let all_sessions = db.get_all_sessions()?;\n   840â†’\n   841â†’    Ok(all_sessions\n   842â†’        .into_iter()\n   843â†’        .filter(|s| s.timestamp >= start && s.timestamp <= end)\n   844â†’        .collect())\n   845â†’}\n   846â†’\n   847â†’/// Calculate aggregate statistics for all metrics from sessions\n   848â†’pub fn calculate_aggregate_stats_from_sessions(sessions: &[SessionMetrics]) -> HashMap<String, MetricAggregateStats> {\n   849â†’    let mut stats_map = HashMap::new();\n   850â†’\n   851â†’    // Tool error rate\n   852â†’    let error_rates: Vec<f64> = sessions\n   853â†’        .iter()\n   854â†’        .filter(|s| s.tool_calls > 0)\n   855â†’        .map(|s| (s.tool_errors as f64) / (s.tool_calls as f64))\n   856â†’        .collect();\n   857â†’    if let Some(stats) = calculate_metric_stats(\"tool_error_rate\", &error_rates) {\n   858â†’        stats_map.insert(\"tool_error_rate\".to_string(), stats);\n   859â†’    }\n   860â†’\n   861â†’    // Tokens per issue\n   862â†’    let tokens_per_issue: Vec<f64> = sessions\n   863â†’        .iter()\n   864â†’        .filter(|s| s.issues_completed > 0)\n   865â†’        .map(|s| ((s.tokens_in + s.tokens_out) as f64) / (s.issues_completed as f64))\n   866â†’        .collect();\n   867â†’    if let Some(stats) = calculate_metric_stats(\"tokens_per_issue\", &tokens_per_issue) {\n   868â†’        stats_map.insert(\"tokens_per_issue\".to_string(), stats);\n   869â†’    }\n   870â†’\n   871â†’    // Duration per issue\n   872â†’    let duration_per_issue: Vec<f64> = sessions\n   873â†’        .iter()\n   874â†’        .filter(|s| s.issues_completed > 0)\n   875â†’        .map(|s| s.duration_seconds / (s.issues_completed as f64))\n   876â†’        .collect();\n   877â†’    if let Some(stats) = calculate_metric_stats(\"duration_per_issue\", &duration_per_issue) {\n   878â†’        stats_map.insert(\"duration_per_issue\".to_string(), stats);\n   879â†’    }\n   880â†’\n   881â†’    // Cost per issue\n   882â†’    let cost_per_issue: Vec<f64> = sessions\n   883â†’        .iter()\n   884â†’        .filter(|s| s.issues_completed > 0)\n   885â†’        .map(|s| s.cost_usd / (s.issues_completed as f64))\n   886â†’        .collect();\n   887â†’    if let Some(stats) = calculate_metric_stats(\"cost_per_issue\", &cost_per_issue) {\n   888â†’        stats_map.insert(\"cost_per_issue\".to_string(), stats);\n   889â†’    }\n   890â†’\n   891â†’    // Session duration\n   892â†’    let durations: Vec<f64> = sessions.iter().map(|s| s.duration_seconds).collect();\n   893â†’    if let Some(stats) = calculate_metric_stats(\"session_duration\", &durations) {\n   894â†’        stats_map.insert(\"session_duration\".to_string(), stats);\n   895â†’    }\n   896â†’\n   897â†’    // Completion rate\n   898â†’    let completion_rates: Vec<f64> = sessions\n   899â†’        .iter()\n   900â†’        .filter(|s| s.issues_claimed > 0)\n   901â†’        .map(|s| (s.issues_completed as f64) / (s.issues_claimed as f64))\n   902â†’        .collect();\n   903â†’    if let Some(stats) = calculate_metric_stats(\"completion_rate\", &completion_rates) {\n   904â†’        stats_map.insert(\"completion_rate\".to_string(), stats);\n   905â†’    }\n   906â†’\n   907â†’    stats_map\n   908â†’}\n   909â†’\n   910â†’/// Detect trends by comparing recent vs baseline periods\n   911â†’pub fn detect_trends(\n   912â†’    db: &MetricsDb,\n   913â†’    recent_period: TimePeriod,\n   914â†’    baseline_period: Option<TimePeriod>,\n   915â†’) -> anyhow::Result<Vec<MetricTrend>> {\n   916â†’    let recent_sessions = get_sessions_in_period(db, recent_period)?;\n   917â†’    let recent_stats = calculate_aggregate_stats_from_sessions(&recent_sessions);\n   918â†’\n   919â†’    let baseline_sessions = if let Some(bp) = baseline_period {\n   920â†’        Some(get_sessions_in_period(db, bp)?)\n   921â†’    } else {\n   922â†’        None\n   923â†’    };\n   924â†’\n   925â†’    let baseline_stats = baseline_sessions\n   926â†’        .as_ref()\n   927â†’        .map(|sessions| calculate_aggregate_stats_from_sessions(sessions));\n   928â†’\n   929â†’    let mut trends = Vec::new();\n   930â†’\n   931â†’    for (dimension, recent) in recent_stats {\n   932â†’        let baseline = baseline_stats\n   933â†’            .as_ref()\n   934â†’            .and_then(|map| map.get(&dimension).cloned());\n   935â†’\n   936â†’        let (direction, percent_change) = if let Some(ref base) = baseline {\n   937â†’            let change = if base.mean != 0.0 {\n   938â†’                ((recent.mean - base.mean) / base.mean) * 100.0\n   939â†’            } else {\n   940â†’                0.0\n   941â†’            };\n   942â†’\n   943â†’            // Determine if change is improvement or degradation based on metric type\n   944â†’            let direction = match dimension.as_str() {\n   945â†’                \"tool_error_rate\" | \"cost_per_issue\" | \"duration_per_issue\" => {\n   946â†’                    // Lower is better\n   947â†’                    if change < -5.0 {\n   948â†’                        TrendDirection::Improving\n   949â†’                    } else if change > 5.0 {\n   950â†’                        TrendDirection::Degrading\n   951â†’                    } else {\n   952â†’                        TrendDirection::Stable\n   953â†’                    }\n   954â†’                }\n   955â†’                \"completion_rate\" => {\n   956â†’                    // Higher is better\n   957â†’                    if change > 5.0 {\n   958â†’                        TrendDirection::Improving\n   959â†’                    } else if change < -5.0 {\n   960â†’                        TrendDirection::Degrading\n   961â†’                    } else {\n   962â†’                        TrendDirection::Stable\n   963â†’                    }\n   964â†’                }\n   965â†’                _ => TrendDirection::Stable,\n   966â†’            };\n   967â†’\n   968â†’            (direction, change)\n   969â†’        } else {\n   970â†’            (TrendDirection::Stable, 0.0)\n   971â†’        };\n   972â†’\n   973â†’        trends.push(MetricTrend {\n   974â†’            dimension,\n   975â†’            direction,\n   976â†’            percent_change,\n   977â†’            recent,\n   978â†’            baseline,\n   979â†’        });\n   980â†’    }\n   981â†’\n   982â†’    Ok(trends)\n   983â†’}\n   984â†’\n   985â†’/// Detect regressions by comparing against baselines\n   986â†’pub fn detect_regressions(db: &MetricsDb, period: TimePeriod) -> anyhow::Result<Vec<Regression>> {\n   987â†’    let sessions = get_sessions_in_period(db, period)?;\n   988â†’    let current_stats = calculate_aggregate_stats_from_sessions(&sessions);\n   989â†’    let mut regressions = Vec::new();\n   990â†’\n   991â†’    // Check each dimension against stored baseline\n   992â†’    for (dimension, current) in current_stats {\n   993â†’        if let Some(baseline) = db.get_baseline(&dimension)? {\n   994â†’            // Calculate standard deviation-based regression threshold\n   995â†’            // A metric is regressed if it's >2 standard deviations worse than baseline\n   996â†’            let deviation_sigma = if baseline.stddev > 0.0 {\n   997â†’                (current.mean - baseline.mean).abs() / baseline.stddev\n   998â†’            } else {\n   999â†’                0.0\n  1000â†’            };\n  1001â†’\n  1002â†’            let percent_worse = match dimension.as_str() {\n  1003â†’                \"tool_error_rate\" | \"cost_per_issue\" | \"duration_per_issue\" => {\n  1004â†’                    // Lower is better - check if current is higher than baseline\n  1005â†’                    if current.mean > baseline.mean && baseline.mean > 0.0 {\n  1006â†’                        ((current.mean - baseline.mean) / baseline.mean) * 100.0\n  1007â†’                    } else {\n  1008â†’                        continue; // Not a regression\n  1009â†’                    }\n  1010â†’                }\n  1011â†’                \"completion_rate\" => {\n  1012â†’                    // Higher is better - check if current is lower than baseline\n  1013â†’                    if current.mean < baseline.mean && baseline.mean > 0.0 {\n  1014â†’                        ((baseline.mean - current.mean) / baseline.mean) * 100.0\n  1015â†’                    } else {\n  1016â†’                        continue; // Not a regression\n  1017â†’                    }\n  1018â†’                }\n  1019â†’                _ => continue,\n  1020â†’            };\n  1021â†’\n  1022â†’            // Determine severity based on both percent change and standard deviations\n  1023â†’            let severity = if percent_worse > 50.0 || deviation_sigma > 3.0 {\n  1024â†’                RegressionSeverity::Critical\n  1025â†’            } else if percent_worse > 25.0 || deviation_sigma > 2.5 {\n  1026â†’                RegressionSeverity::Error\n  1027â†’            } else if percent_worse > 10.0 || deviation_sigma > 2.0 {\n  1028â†’                RegressionSeverity::Warning\n  1029â†’            } else {\n  1030â†’                continue; // Not significant enough to report\n  1031â†’            };\n  1032â†’\n  1033â†’            regressions.push(Regression {\n  1034â†’                dimension,\n  1035â†’                baseline_value: baseline.mean,\n  1036â†’                current_value: current.mean,\n  1037â†’                percent_worse,\n  1038â†’                is_critical: percent_worse > 50.0,\n  1039â†’                severity,\n  1040â†’                deviation_sigma,\n  1041â†’            });\n  1042â†’        }\n  1043â†’    }\n  1044â†’\n  1045â†’    Ok(regressions)\n  1046â†’}\n  1047â†’\n  1048â†’/// Get top error tools from sessions\n  1049â†’pub fn get_top_error_tools(db: &MetricsDb, period: TimePeriod, limit: usize) -> anyhow::Result<Vec<(String, u32)>> {\n  1050â†’    let sessions = get_sessions_in_period(db, period)?;\n  1051â†’    let mut error_counts: HashMap<String, u32> = HashMap::new();\n  1052â†’\n  1053â†’    for session in &sessions {\n  1054â†’        let tool_calls = db.get_tool_calls(&session.id)?;\n  1055â†’        for tc in tool_calls {\n  1056â†’            if !tc.success {\n  1057â†’                *error_counts.entry(tc.tool_name).or_insert(0) += 1;\n  1058â†’            }\n  1059â†’        }\n  1060â†’    }\n  1061â†’\n  1062â†’    let mut errors: Vec<(String, u32)> = error_counts.into_iter().collect();\n  1063â†’    errors.sort_by(|a, b| b.1.cmp(&a.1));\n  1064â†’    errors.truncate(limit);\n  1065â†’\n  1066â†’    Ok(errors)\n  1067â†’}\n  1068â†’\n  1069â†’/// Get slowest tools by average duration\n  1070â†’pub fn get_slowest_tools(db: &MetricsDb, period: TimePeriod, limit: usize) -> anyhow::Result<Vec<(String, f64, usize)>> {\n  1071â†’    let sessions = get_sessions_in_period(db, period)?;\n  1072â†’    let mut tool_durations: HashMap<String, Vec<i64>> = HashMap::new();\n  1073â†’\n  1074â†’    for session in &sessions {\n  1075â†’        let tool_calls = db.get_tool_calls(&session.id)?;\n  1076â†’        for tc in tool_calls {\n  1077â†’            tool_durations\n  1078â†’                .entry(tc.tool_name)\n  1079â†’                .or_default()\n  1080â†’                .push(tc.duration_ms);\n  1081â†’        }\n  1082â†’    }\n  1083â†’\n  1084â†’    let mut slowest: Vec<(String, f64, usize)> = tool_durations\n  1085â†’        .into_iter()\n  1086â†’        .map(|(tool, durations)| {\n  1087â†’            let count = durations.len();\n  1088â†’            let avg = durations.iter().sum::<i64>() as f64 / count as f64;\n  1089â†’            (tool, avg, count)\n  1090â†’        })\n  1091â†’        .collect();\n  1092â†’\n  1093â†’    slowest.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));\n  1094â†’    slowest.truncate(limit);\n  1095â†’\n  1096â†’    Ok(slowest)\n  1097â†’}\n  1098â†’\n  1099â†’#[cfg(test)]\n  1100â†’mod tests_edge_cases {\n  1101â†’    use super::*;\n  1102â†’    use crate::trajectory::{Step, StepType, TokenUsage, TrajectoryResult};\n  1103â†’    use chrono::Utc;\n  1104â†’\n  1105â†’    /// Helper to create a minimal trajectory for testing\n  1106â†’    fn create_test_trajectory() -> Trajectory {\n  1107â†’        Trajectory {\n  1108â†’            session_id: \"test-session-id\".to_string(),\n  1109â†’            prompt: \"Test prompt\".to_string(),\n  1110â†’            model: \"claude-sonnet-4-5\".to_string(),\n  1111â†’            cwd: \"/test\".to_string(),\n  1112â†’            repo_sha: \"abc123\".to_string(),\n  1113â†’            branch: Some(\"main\".to_string()),\n  1114â†’            started_at: Utc::now(),\n  1115â†’            ended_at: Some(Utc::now()),\n  1116â†’            steps: vec![],\n  1117â†’            result: Some(TrajectoryResult {\n  1118â†’                success: true,\n  1119â†’                num_turns: 1,\n  1120â†’                duration_ms: 1000,\n  1121â†’                result_text: None,\n  1122â†’                errors: vec![],\n  1123â†’                issues_completed: 0,\n  1124â†’                apm: None,\n  1125â†’            }),\n  1126â†’            usage: TokenUsage {\n  1127â†’                input_tokens: 100,\n  1128â†’                output_tokens: 50,\n  1129â†’                cache_read_tokens: 20,\n  1130â†’                cache_creation_tokens: 0,\n  1131â†’                cost_usd: 0.001,\n  1132â†’            },\n  1133â†’        }\n  1134â†’    }\n  1135â†’\n  1136â†’    #[test]\n  1137â†’    fn test_empty_trajectory() {\n  1138â†’        let mut trajectory = create_test_trajectory();\n  1139â†’        trajectory.steps = vec![];\n  1140â†’        trajectory.result = None;\n  1141â†’\n  1142â†’        let analysis = analyze_trajectory(&trajectory);\n  1143â†’\n  1144â†’        // Should not panic, should return zero/default values\n  1145â†’        assert_eq!(analysis.performance.total_tool_calls, 0);\n  1146â†’        assert_eq!(analysis.performance.parallel_tool_batches, 0);\n  1147â†’        assert_eq!(analysis.errors.total_tool_calls, 0);\n  1148â†’        assert_eq!(analysis.errors.failed_tool_calls, 0);\n  1149â†’        assert_eq!(analysis.quality.thinking_blocks, 0);\n  1150â†’        assert_eq!(analysis.tool_usage.total_calls, 0);\n  1151â†’    }\n  1152â†’\n  1153â†’    #[test]\n  1154â†’    fn test_malformed_step_data_missing_tokens() {\n  1155â†’        let mut trajectory = create_test_trajectory();\n  1156â†’        trajectory.steps = vec![Step {\n  1157â†’            step_id: 1,\n  1158â†’            timestamp: Utc::now(),\n  1159â†’            step_type: StepType::Thinking {\n  1160â†’                content: \"test\".to_string(),\n  1161â†’                signature: None,\n  1162â†’            },\n  1163â†’            tokens_in: None,  // Missing token data\n  1164â†’            tokens_out: None,\n  1165â†’            tokens_cached: None,\n  1166â†’        }];\n  1167â†’\n  1168â†’        let analysis = analyze_trajectory(&trajectory);\n  1169â†’\n  1170â†’        // Should handle missing token data gracefully\n  1171â†’        assert_eq!(analysis.quality.thinking_blocks, 1);\n  1172â†’    }\n  1173â†’\n  1174â†’    #[test]\n  1175â†’    fn test_zero_tokens_no_division_by_zero() {\n  1176â†’        let mut trajectory = create_test_trajectory();\n  1177â†’        trajectory.usage = TokenUsage {\n  1178â†’            input_tokens: 0,\n  1179â†’            output_tokens: 0,\n  1180â†’            cache_read_tokens: 0,\n  1181â†’            cache_creation_tokens: 0,\n  1182â†’            cost_usd: 0.0,\n  1183â†’        };\n  1184â†’\n  1185â†’        let analysis = analyze_trajectory(&trajectory);\n  1186â†’\n  1187â†’        // Cache hit rate should be 0, not NaN or panic\n  1188â†’        assert_eq!(analysis.cost.cache_hit_rate, 0.0);\n  1189â†’    }\n  1190â†’\n  1191â†’    #[test]\n  1192â†’    fn test_zero_tool_calls_no_division_by_zero() {\n  1193â†’        let trajectory = create_test_trajectory();\n  1194â†’\n  1195â†’        let analysis = analyze_trajectory(&trajectory);\n  1196â†’\n  1197â†’        // Error rate should be 0 when no tool calls\n  1198â†’        assert_eq!(analysis.errors.tool_error_rate, 0.0);\n  1199â†’        assert_eq!(analysis.quality.tool_diversity, 0.0);\n  1200â†’    }\n  1201â†’\n  1202â†’    #[test]\n  1203â†’    fn test_orphaned_tool_result_no_matching_call() {\n  1204â†’        let mut trajectory = create_test_trajectory();\n  1205â†’        let now = Utc::now();\n  1206â†’\n  1207â†’        // Tool result without matching tool call\n  1208â†’        trajectory.steps = vec![Step {\n  1209â†’            step_id: 1,\n  1210â†’            timestamp: now,\n  1211â†’            step_type: StepType::ToolResult {\n  1212â†’                tool_id: \"nonexistent\".to_string(),\n  1213â†’                success: false,\n  1214â†’                output: None,\n  1215â†’            },\n  1216â†’            tokens_in: None,\n  1217â†’            tokens_out: None,\n  1218â†’            tokens_cached: None,\n  1219â†’        }];\n  1220â†’\n  1221â†’        let analysis = analyze_trajectory(&trajectory);\n  1222â†’\n  1223â†’        // Should not panic, orphaned result should not affect counts\n  1224â†’        assert_eq!(analysis.errors.total_tool_calls, 0);\n  1225â†’    }\n  1226â†’\n  1227â†’    #[test]\n  1228â†’    fn test_unicode_in_content() {\n  1229â†’        let mut trajectory = create_test_trajectory();\n  1230â†’        trajectory.prompt = \"æµ‹è¯• ðŸš€ Ù…Ø±Ø­Ø¨Ø§ Ð¢ÐµÑÑ‚\".to_string();\n  1231â†’\n  1232â†’        trajectory.steps = vec![Step {\n  1233â†’            step_id: 1,\n  1234â†’            timestamp: Utc::now(),\n  1235â†’            step_type: StepType::Thinking {\n  1236â†’                content: \"Emoji test ðŸ”¥ðŸ’¯âœ¨ and unicode ä½ å¥½ä¸–ç•Œ\".to_string(),\n  1237â†’                signature: None,\n  1238â†’            },\n  1239â†’            tokens_in: None,\n  1240â†’            tokens_out: None,\n  1241â†’            tokens_cached: None,\n  1242â†’        }];\n  1243â†’\n  1244â†’        let analysis = analyze_trajectory(&trajectory);\n  1245â†’\n  1246â†’        // Should handle unicode characters properly\n  1247â†’        assert_eq!(analysis.quality.thinking_blocks, 1);\n  1248â†’        assert!(analysis.prompt_preview.contains(\"æµ‹è¯•\"));\n  1249â†’    }\n  1250â†’\n  1251â†’    #[test]\n  1252â†’    fn test_very_long_trajectory() {\n  1253â†’        let mut trajectory = create_test_trajectory();\n  1254â†’        let now = Utc::now();\n  1255â†’\n  1256â†’        // Create 10,000 steps\n  1257â†’        for i in 0..10_000 {\n  1258â†’            trajectory.steps.push(Step {\n  1259â†’                step_id: i,\n  1260â†’                timestamp: now,\n  1261â†’                step_type: StepType::Thinking {\n  1262â†’                    content: format!(\"Step {}\", i),\n  1263â†’                    signature: None,\n  1264â†’                },\n  1265â†’                tokens_in: Some(10),\n  1266â†’                tokens_out: Some(5),\n  1267â†’                tokens_cached: None,\n  1268â†’            });\n  1269â†’        }\n  1270â†’\n  1271â†’        let analysis = analyze_trajectory(&trajectory);\n  1272â†’\n  1273â†’        // Should complete without timeout or memory issues\n  1274â†’        assert_eq!(analysis.quality.thinking_blocks, 10_000);\n  1275â†’    }\n  1276â†’\n  1277â†’    #[test]\n  1278â†’    fn test_latency_stats_single_value() {\n  1279â†’        let latencies = vec![100];\n  1280â†’        let stats = compute_latency_stats(&latencies);\n  1281â†’\n  1282â†’        // Single value should work correctly\n  1283â†’        assert_eq!(stats.min_ms, 100);\n  1284â†’        assert_eq!(stats.max_ms, 100);\n  1285â†’        assert_eq!(stats.mean_ms, 100.0);\n  1286â†’        assert_eq!(stats.p50_ms, 100);\n  1287â†’        assert_eq!(stats.p95_ms, 100);\n  1288â†’        assert_eq!(stats.count, 1);\n  1289â†’    }\n  1290â†’\n  1291â†’    #[test]\n  1292â†’    fn test_latency_stats_empty() {\n  1293â†’        let latencies = vec![];\n  1294â†’        let stats = compute_latency_stats(&latencies);\n  1295â†’\n  1296â†’        // Empty latencies should return default\n  1297â†’        assert_eq!(stats.count, 0);\n  1298â†’        assert_eq!(stats.min_ms, 0);\n  1299â†’        assert_eq!(stats.max_ms, 0);\n  1300â†’    }\n  1301â†’\n  1302â†’    #[test]\n  1303â†’    fn test_detect_parallel_batches_empty() {\n  1304â†’        let intervals = vec![];\n  1305â†’        let batches = detect_parallel_batches(&intervals);\n  1306â†’\n  1307â†’        assert_eq!(batches, 0);\n  1308â†’    }\n  1309â†’\n  1310â†’    #[test]\n  1311â†’    fn test_detect_parallel_batches_no_overlap() {\n  1312â†’        let now = Utc::now();\n  1313â†’        let intervals = vec![\n  1314â†’            (now, now + chrono::Duration::milliseconds(100)),\n  1315â†’            (now + chrono::Duration::milliseconds(200), now + chrono::Duration::milliseconds(300)),\n  1316â†’        ];\n  1317â†’\n  1318â†’        let batches = detect_parallel_batches(&intervals);\n  1319â†’\n  1320â†’        // No overlap = 2 separate batches\n  1321â†’        assert_eq!(batches, 2);\n  1322â†’    }\n  1323â†’\n  1324â†’    #[test]\n  1325â†’    fn test_detect_parallel_batches_complete_overlap() {\n  1326â†’        let now = Utc::now();\n  1327â†’        let intervals = vec![\n  1328â†’            (now, now + chrono::Duration::milliseconds(500)),\n  1329â†’            (now + chrono::Duration::milliseconds(100), now + chrono::Duration::milliseconds(200)),\n  1330â†’            (now + chrono::Duration::milliseconds(300), now + chrono::Duration::milliseconds(400)),\n  1331â†’        ];\n  1332â†’\n  1333â†’        let batches = detect_parallel_batches(&intervals);\n  1334â†’\n  1335â†’        // All overlap within first interval = 1 batch\n  1336â†’        assert_eq!(batches, 1);\n  1337â†’    }\n  1338â†’\n  1339â†’    #[test]\n  1340â†’    fn test_aggregate_analyses_empty() {\n  1341â†’        let analyses = vec![];\n  1342â†’        let aggregate = aggregate_analyses(&analyses);\n  1343â†’\n  1344â†’        assert_eq!(aggregate.trajectory_count, 0);\n  1345â†’        assert_eq!(aggregate.total_cost_usd, 0.0);\n  1346â†’        assert!(aggregate.by_model.is_empty());\n  1347â†’    }\n  1348â†’\n  1349â†’    #[test]\n  1350â†’    fn test_aggregate_analyses_single() {\n  1351â†’        let trajectory = create_test_trajectory();\n  1352â†’        let analysis = analyze_trajectory(&trajectory);\n  1353â†’\n  1354â†’        let aggregate = aggregate_analyses(&[analysis]);\n  1355â†’\n  1356â†’        assert_eq!(aggregate.trajectory_count, 1);\n  1357â†’        assert!(aggregate.total_cost_usd > 0.0);\n  1358â†’    }\n  1359â†’\n  1360â†’    #[test]\n  1361â†’    fn test_tool_error_tracking_all_successful() {\n  1362â†’        let mut trajectory = create_test_trajectory();\n  1363â†’        let now = Utc::now();\n  1364â†’\n  1365â†’        trajectory.steps = vec![\n  1366â†’            Step {\n  1367â†’                step_id: 1,\n  1368â†’                timestamp: now,\n  1369â†’                step_type: StepType::ToolCall {\n  1370â†’                    tool: \"Read\".to_string(),\n  1371â†’                    tool_id: \"t1\".to_string(),\n  1372â†’                    input: serde_json::json!({}),\n  1373â†’                },\n  1374â†’                tokens_in: None,\n  1375â†’                tokens_out: None,\n  1376â†’                tokens_cached: None,\n  1377â†’            },\n  1378â†’            Step {\n  1379â†’                step_id: 2,\n  1380â†’                timestamp: now + chrono::Duration::milliseconds(100),\n  1381â†’                step_type: StepType::ToolResult {\n  1382â†’                    tool_id: \"t1\".to_string(),\n  1383â†’                    success: true,\n  1384â†’                    output: Some(\"ok\".to_string()),\n  1385â†’                },\n  1386â†’                tokens_in: None,\n  1387â†’                tokens_out: None,\n  1388â†’                tokens_cached: None,\n  1389â†’            },\n  1390â†’        ];\n  1391â†’\n  1392â†’        let analysis = analyze_trajectory(&trajectory);\n  1393â†’\n  1394â†’        assert_eq!(analysis.errors.total_tool_calls, 1);\n  1395â†’        assert_eq!(analysis.errors.failed_tool_calls, 0);\n  1396â†’        assert_eq!(analysis.errors.tool_error_rate, 0.0);\n  1397â†’        assert!(analysis.errors.errors_by_tool.is_empty());\n  1398â†’    }\n  1399â†’\n  1400â†’    #[test]\n  1401â†’    fn test_tool_error_tracking_all_failed() {\n  1402â†’        let mut trajectory = create_test_trajectory();\n  1403â†’        let now = Utc::now();\n  1404â†’\n  1405â†’        trajectory.steps = vec![\n  1406â†’            Step {\n  1407â†’                step_id: 1,\n  1408â†’                timestamp: now,\n  1409â†’                step_type: StepType::ToolCall {\n  1410â†’                    tool: \"Read\".to_string(),\n  1411â†’                    tool_id: \"t1\".to_string(),\n  1412â†’                    input: serde_json::json!({}),\n  1413â†’                },\n  1414â†’                tokens_in: None,\n  1415â†’                tokens_out: None,\n  1416â†’                tokens_cached: None,\n  1417â†’            },\n  1418â†’            Step {\n  1419â†’                step_id: 2,\n  1420â†’                timestamp: now + chrono::Duration::milliseconds(100),\n  1421â†’                step_type: StepType::ToolResult {\n  1422â†’                    tool_id: \"t1\".to_string(),\n  1423â†’                    success: false,\n  1424â†’                    output: Some(\"error\".to_string()),\n  1425â†’                },\n  1426â†’                tokens_in: None,\n  1427â†’                tokens_out: None,\n  1428â†’                tokens_cached: None,\n  1429â†’            },\n  1430â†’        ];\n  1431â†’\n  1432â†’        let analysis = analyze_trajectory(&trajectory);\n  1433â†’\n  1434â†’        assert_eq!(analysis.errors.total_tool_calls, 1);\n  1435â†’        assert_eq!(analysis.errors.failed_tool_calls, 1);\n  1436â†’        assert_eq!(analysis.errors.tool_error_rate, 1.0);\n  1437â†’        assert_eq!(analysis.errors.errors_by_tool.get(\"Read\"), Some(&1));\n  1438â†’    }\n  1439â†’\n  1440â†’    #[test]\n  1441â†’    fn test_tool_diversity_single_tool_many_calls() {\n  1442â†’        let mut trajectory = create_test_trajectory();\n  1443â†’        let now = Utc::now();\n  1444â†’\n  1445â†’        // 5 calls to same tool\n  1446â†’        for i in 0..5 {\n  1447â†’            trajectory.steps.push(Step {\n  1448â†’                step_id: i,\n  1449â†’                timestamp: now,\n  1450â†’                step_type: StepType::ToolCall {\n  1451â†’                    tool: \"Read\".to_string(),\n  1452â†’                    tool_id: format!(\"t{}\", i),\n  1453â†’                    input: serde_json::json!({}),\n  1454â†’                },\n  1455â†’                tokens_in: None,\n  1456â†’                tokens_out: None,\n  1457â†’                tokens_cached: None,\n  1458â†’            });\n  1459â†’        }\n  1460â†’\n  1461â†’        let analysis = analyze_trajectory(&trajectory);\n  1462â†’\n  1463â†’        // 1 unique tool / 5 calls = 0.2 diversity\n  1464â†’        assert_eq!(analysis.quality.unique_tools, 1);\n  1465â†’        assert!((analysis.quality.tool_diversity - 0.2).abs() < 0.01);\n  1466â†’    }\n  1467â†’\n  1468â†’    #[test]\n  1469â†’    fn test_tool_diversity_many_tools_one_call_each() {\n  1470â†’        let mut trajectory = create_test_trajectory();\n  1471â†’        let now = Utc::now();\n  1472â†’\n  1473â†’        // 5 different tools, 1 call each\n  1474â†’        for i in 0..5 {\n  1475â†’            trajectory.steps.push(Step {\n  1476â†’                step_id: i,\n  1477â†’                timestamp: now,\n  1478â†’                step_type: StepType::ToolCall {\n  1479â†’                    tool: format!(\"Tool{}\", i),\n  1480â†’                    tool_id: format!(\"t{}\", i),\n  1481â†’                    input: serde_json::json!({}),\n  1482â†’                },\n  1483â†’                tokens_in: None,\n  1484â†’                tokens_out: None,\n  1485â†’                tokens_cached: None,\n  1486â†’            });\n  1487â†’        }\n  1488â†’\n  1489â†’        let analysis = analyze_trajectory(&trajectory);\n  1490â†’\n  1491â†’        // 5 unique tools / 5 calls = 1.0 diversity\n  1492â†’        assert_eq!(analysis.quality.unique_tools, 5);\n  1493â†’        assert_eq!(analysis.quality.tool_diversity, 1.0);\n  1494â†’    }\n  1495â†’\n  1496â†’    #[test]\n  1497â†’    fn test_truncate_very_long_prompt() {\n  1498â†’        let long_prompt = \"a\".repeat(500);\n  1499â†’        let truncated = truncate(&long_prompt, 80);\n  1500â†’\n  1501â†’        assert_eq!(truncated.len(), 80);\n  1502â†’        assert!(truncated.ends_with(\"...\"));\n  1503â†’    }\n  1504â†’\n  1505â†’    #[test]\n  1506â†’    fn test_truncate_short_prompt() {\n  1507â†’        let short_prompt = \"Short prompt\";\n  1508â†’        let truncated = truncate(short_prompt, 80);\n  1509â†’\n  1510â†’        assert_eq!(truncated, \"Short prompt\");\n  1511â†’    }\n  1512â†’\n  1513â†’    #[test]\n  1514â†’    fn test_tokens_by_step_type_all_types() {\n  1515â†’        let mut trajectory = create_test_trajectory();\n  1516â†’        let now = Utc::now();\n  1517â†’\n  1518â†’        trajectory.steps = vec![\n  1519â†’            Step {\n  1520â†’                step_id: 1,\n  1521â†’                timestamp: now,\n  1522â†’                step_type: StepType::Thinking {\n  1523â†’                    content: \"think\".to_string(),\n  1524â†’                    signature: None,\n  1525â†’                },\n  1526â†’                tokens_in: None,\n  1527â†’                tokens_out: Some(100),\n  1528â†’                tokens_cached: None,\n  1529â†’            },\n  1530â†’            Step {\n  1531â†’                step_id: 2,\n  1532â†’                timestamp: now,\n  1533â†’                step_type: StepType::Assistant {\n  1534â†’                    content: \"response\".to_string(),\n  1535â†’                },\n  1536â†’                tokens_in: None,\n  1537â†’                tokens_out: Some(50),\n  1538â†’                tokens_cached: None,\n  1539â†’            },\n  1540â†’            Step {\n  1541â†’                step_id: 3,\n  1542â†’                timestamp: now,\n  1543â†’                step_type: StepType::User {\n  1544â†’                    content: \"question\".to_string(),\n  1545â†’                },\n  1546â†’                tokens_in: None,\n  1547â†’                tokens_out: Some(25),\n  1548â†’                tokens_cached: None,\n  1549â†’            },\n  1550â†’        ];\n  1551â†’\n  1552â†’        let analysis = analyze_trajectory(&trajectory);\n  1553â†’\n  1554â†’        assert_eq!(analysis.cost.tokens_by_step_type.get(\"thinking\"), Some(&100));\n  1555â†’        assert_eq!(analysis.cost.tokens_by_step_type.get(\"assistant\"), Some(&50));\n  1556â†’        assert_eq!(analysis.cost.tokens_by_step_type.get(\"user\"), Some(&25));\n  1557â†’    }\n  1558â†’\n  1559â†’    #[test]\n  1560â†’    fn test_negative_timestamp_delta_latency() {\n  1561â†’        let mut trajectory = create_test_trajectory();\n  1562â†’        let now = Utc::now();\n  1563â†’\n  1564â†’        // Tool result BEFORE tool call (time anomaly)\n  1565â†’        trajectory.steps = vec![\n  1566â†’            Step {\n  1567â†’                step_id: 1,\n  1568â†’                timestamp: now + chrono::Duration::milliseconds(200),\n  1569â†’                step_type: StepType::ToolCall {\n  1570â†’                    tool: \"Read\".to_string(),\n  1571â†’                    tool_id: \"t1\".to_string(),\n  1572â†’                    input: serde_json::json!({}),\n  1573â†’                },\n  1574â†’                tokens_in: None,\n  1575â†’                tokens_out: None,\n  1576â†’                tokens_cached: None,\n  1577â†’            },\n  1578â†’            Step {\n  1579â†’                step_id: 2,\n  1580â†’                timestamp: now, // Earlier timestamp\n  1581â†’                step_type: StepType::ToolResult {\n  1582â†’                    tool_id: \"t1\".to_string(),\n  1583â†’                    success: true,\n  1584â†’                    output: None,\n  1585â†’                },\n  1586â†’                tokens_in: None,\n  1587â†’                tokens_out: None,\n  1588â†’                tokens_cached: None,\n  1589â†’            },\n  1590â†’        ];\n  1591â†’\n  1592â†’        let analysis = analyze_trajectory(&trajectory);\n  1593â†’\n  1594â†’        // Should handle gracefully with .max(0)\n  1595â†’        assert_eq!(analysis.performance.tool_latency_stats.min_ms, 0);\n  1596â†’    }\n  1597â†’}\n  1598â†’\n  1599â†’/// Calculate improvement velocity from trends\n  1600â†’pub fn calculate_velocity(\n  1601â†’    db: &MetricsDb,\n  1602â†’    period: TimePeriod,\n  1603â†’) -> anyhow::Result<crate::metrics::VelocitySnapshot> {\n  1604â†’    use crate::metrics::{MetricVelocity, VelocitySnapshot};\n  1605â†’    use chrono::Utc;\n  1606â†’\n  1607â†’    // Get trends comparing this period vs previous period\n  1608â†’    let baseline_period = match period {\n  1609â†’        TimePeriod::Last7Days | TimePeriod::ThisWeek => Some(TimePeriod::LastWeek),\n  1610â†’        TimePeriod::Last30Days => Some(TimePeriod::Last30Days), // Compare vs same period\n  1611â†’        _ => None,\n  1612â†’    };\n  1613â†’\n  1614â†’    let trends = detect_trends(db, period, baseline_period)?;\n  1615â†’\n  1616â†’    let mut improving_count = 0;\n  1617â†’    let mut degrading_count = 0;\n  1618â†’    let mut stable_count = 0;\n  1619â†’    let mut key_metrics = Vec::new();\n  1620â†’\n  1621â†’    // Key metrics to track for velocity\n  1622â†’    let key_metric_names = [\"tool_error_rate\",\n  1623â†’        \"completion_rate\",\n  1624â†’        \"cost_per_issue\",\n  1625â†’        \"duration_per_issue\"];\n  1626â†’\n  1627â†’    for trend in trends {\n  1628â†’        // Only include key metrics in the snapshot\n  1629â†’        if key_metric_names.contains(&trend.dimension.as_str()) {\n  1630â†’            let direction_str = match trend.direction {\n  1631â†’                TrendDirection::Improving => {\n  1632â†’                    improving_count += 1;\n  1633â†’                    \"improving\"\n  1634â†’                }\n  1635â†’                TrendDirection::Degrading => {\n  1636â†’                    degrading_count += 1;\n  1637â†’                    \"degrading\"\n  1638â†’                }\n  1639â†’                TrendDirection::Stable => {\n  1640â†’                    stable_count += 1;\n  1641â†’                    \"stable\"\n  1642â†’                }\n  1643â†’            };\n  1644â†’\n  1645â†’            key_metrics.push(MetricVelocity {\n  1646â†’                dimension: trend.dimension.clone(),\n  1647â†’                percent_change: trend.percent_change,\n  1648â†’                direction: direction_str.to_string(),\n  1649â†’            });\n  1650â†’        } else {\n  1651â†’            // Still count for the totals\n  1652â†’            match trend.direction {\n  1653â†’                TrendDirection::Improving => improving_count += 1,\n  1654â†’                TrendDirection::Degrading => degrading_count += 1,\n  1655â†’                TrendDirection::Stable => stable_count += 1,\n  1656â†’            }\n  1657â†’        }\n  1658â†’    }\n  1659â†’\n  1660â†’    // Calculate velocity score (-1.0 to 1.0)\n  1661â†’    // Weighted: improving metrics add positive, degrading subtract\n  1662â†’    let total_metrics = (improving_count + degrading_count + stable_count) as f64;\n  1663â†’    let velocity_score = if total_metrics > 0.0 {\n  1664â†’        (improving_count as f64 - degrading_count as f64) / total_metrics\n  1665â†’    } else {\n  1666â†’        0.0\n  1667â†’    };\n  1668â†’\n  1669â†’    // Count total issues completed in period\n  1670â†’    let sessions = get_sessions_in_period(db, period)?;\n  1671â†’    let issues_completed: i32 = sessions.iter().map(|s| s.issues_completed).sum();\n  1672â†’\n  1673â†’    Ok(VelocitySnapshot {\n  1674â†’        timestamp: Utc::now(),\n  1675â†’        period: period.name().to_string(),\n  1676â†’        velocity_score,\n  1677â†’        improving_metrics: improving_count,\n  1678â†’        degrading_metrics: degrading_count,\n  1679â†’        stable_metrics: stable_count,\n  1680â†’        issues_completed,\n  1681â†’        key_metrics,\n  1682â†’    })\n  1683â†’}\n  1684â†’\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"timestamp":"2025-12-23T19:51:13.217151329+00:00"}