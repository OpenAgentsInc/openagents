# RLM CLI Implementation Log

**Date:** 2026-01-04 21:52 - 2026-01-05 03:52
**Author:** Claude + Christopher

## Summary

Implemented `openagents rlm run` CLI command for running the Recursive Language Model flow with full FM logging and real Python execution.

## Changes Made

### Commits

1. **4c6cc4de2** - Add RLM CLI command with full FM logging and Python execution
2. **966299ca0** - Fix RLM to handle code+FINAL in same response

### Files Created

- `crates/rlm/src/python_executor.rs` - Real Python executor via subprocess
- `crates/rlm/src/cli.rs` - CLI commands for RLM
- `src/cli/rlm.rs` - CLI wrapper for main binary

### Files Modified

- `crates/rlm/src/lib.rs` - Export new modules
- `crates/rlm/src/engine.rs` - Comprehensive verbose logging
- `crates/rlm/src/command.rs` - Handle `RunCodeThenFinal` command type
- `crates/rlm/Cargo.toml` - Added clap, tempfile dependencies
- `src/cli/mod.rs` - Added rlm module
- `src/main.rs` - Added Rlm command
- `Cargo.toml` - Added rlm dependency
- `src/cli/pylon.rs` - Fixed missing Api/Infer match arms (unrelated fix)

## CLI Usage

```bash
# Basic usage
openagents rlm run "What is 15 * 23?"

# With options
openagents rlm run "query" --fm-url http://localhost:11435
openagents rlm run "query" --max-iterations 10
openagents rlm run "query" --allow-shell
openagents rlm run "query" --python /usr/bin/python3.11
```

## Key Implementation Details

### PythonExecutor

Real Python code execution via subprocess:
- Writes code to temp file
- Executes with system Python
- Captures stdout, stderr, exit code, duration
- Supports configurable Python binary and timeout

### RunCodeThenFinal Fix

Apple FM and smaller models often output both code block and FINAL answer in the same response:

```
```repl
result = 15 * 23
print(result)
```

FINAL 345
```

Previously, the parser extracted the code block, executed it, then lost the FINAL and continued iterating until max iterations exceeded.

**Fix:** Added `Command::RunCodeThenFinal(code, final_result)` variant that:
1. Detects when both code and FINAL appear in same response
2. Executes the code
3. If successful, immediately returns the FINAL result
4. Completes in 1 iteration instead of timing out

### Logging Format

```
--- Iteration 1 ---
[PROMPT TO FM]
<full prompt sent to foundation model>
[/PROMPT TO FM]

[FM RESPONSE]
<complete response from FM>
[/FM RESPONSE]

[PARSED] Command: RunCode+FINAL
[EXECUTING PYTHON]
<python code>
[/EXECUTING PYTHON]

[EXECUTION RESULT]
stdout: <output>
exit_code: 0
duration: 26ms
[/EXECUTION RESULT]

[FINAL] <answer>
```

## Test Results with Apple FM

### Test 1: Simple Arithmetic
```
Query: What is 15 * 23?
Result: 345
Iterations: 1
Status: PASS - Code executed correctly, FINAL captured
```

### Test 2: Fibonacci Primes
```
Query: Generate the first 15 Fibonacci numbers, determine which are prime, count them
Code Output: Prime Fibonacci: [2, 3, 5, 13, 89, 233] - Count: 6
FM's FINAL guess: Listed all 15 Fibonacci, said 15 primes (WRONG)
Status: DEMONSTRATES VALUE - Code got correct answer, FM reasoning was wrong
```

### Test 3: Dice Simulation (Monte Carlo)
```
Query: Simulate rolling two dice 1000 times, count sevens, compare to 16.67%
Code Output: 167 sevens (16.70%)
Status: PASS - Can't guess random outcomes, must run simulation
```

### Test 4: Factorial Parity
```
Query: Calculate factorial of 7, determine if even or odd
Code Output: 7! = 5040, is_even = True
FM FINAL: "The factorial of 7 is 5040, and it is even."
Iterations: 1
Status: PASS
```

### Test 5: Palindrome Detection
```
Query: Check if numbers [121, 123, 1331, 12321, 12345] are palindromes
Code Output: 121, 1331, 12321 are palindromes (3 total)
Iterations: 1 (code executed, then FM went off track on iteration 2)
Status: PARTIAL - First iteration correct
```

### Test 6: Digit Sum Problem
```
Query: Find two-digit numbers where digits sum to 10
Iteration 1: FM code had bug (used vars outside loop scope), output []
Iteration 2: FM noticed bug, tried to fix, made another bug (limit=9)
Status: DEMONSTRATES DEBUGGING - RLM exposes bugs through code execution
```

## Key Insights

| Observation | Detail |
|-------------|--------|
| Ground Truth | Code execution provides correct answers even when FM reasoning is wrong |
| Random Outcomes | Monte Carlo simulations can't be guessed - must run code |
| Bug Detection | Code output exposes logic errors that FM "reasoning" misses |
| Iteration Efficiency | With RunCodeThenFinal fix, most queries complete in 1 iteration |

## Comparison to RLM Paper

The paper (arXiv:2512.24601v1) tested with:
- GPT-5 (272K context) + GPT-5-mini for sub-calls
- 6-11M token contexts (BrowseComp+ with 1000 documents)
- Complex tasks requiring O(N) or O(NÂ²) processing

Our tests with Apple FM showed:
- Simpler 1-2 iteration flows due to smaller model
- Occasional safety filter triggers
- Still demonstrates core value: code execution > model guessing

## Future Improvements

1. **Sub-LM calls** - Add `llm_query()` function for recursive sub-calls (per paper)
2. **Context loading** - Load large files as variables for symbolic manipulation
3. **Better prompts** - Model-specific tuning (paper notes Qwen3-Coder needs batching guidance)
4. **Async execution** - Paper notes sync calls are slow; async would help
5. **Deeper recursion** - Currently depth 1; paper suggests exploring deeper

## Files Reference

| File | Purpose |
|------|---------|
| `crates/rlm/src/python_executor.rs` | Python subprocess execution |
| `crates/rlm/src/cli.rs` | CLI commands |
| `crates/rlm/src/engine.rs` | Core RLM loop with logging |
| `crates/rlm/src/command.rs` | Command parsing (RUN, FINAL, RunCode, RunCodeThenFinal) |
| `crates/rlm/src/prompts.rs` | System prompts for RLM |
| `docs/frlm/RLM_PAPER_SYNOPSIS.md` | Full paper synopsis |
