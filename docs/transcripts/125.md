# OpenAgents Video Series - Episode 125

## Video Information

- **Title**: OpenAgents ⚡ - Episode 125: The Master Plan  We detail our master plan:  1. Build th...
- **Creator**: OpenAgents ⚡
- **Duration**: 10:09
- **Published**: September 12, 2024
- **URL**: https://x.com/OpenAgentsInc/status/1834087017132511419
- **Transcribed**: June 08, 2025
- **Language**: en

## Full Transcript

So here's the plan. Step one, we build the best agents. Easy. We're pretty much there. Two, we sell the agents and we pay you a cut, proportional to how you help. Maybe you'll be incentivized to help us build better agents. Sell them more. You get a large river cut. And then we're going to repeat one and two until World Conquest. Is this clear? Hopefully, this is quick. Okay, let's dig in a little bit. So the idea is that we are building agents out of graphs. This is not a unique concept. However, I haven't seen any projects combine two types of graphs, both knowledge graphs and execution graphs. You've got like, Langchain has a Lang graph thing. There's a bunch of people building agents out of graphs representing execution steps, his nose and edges. Okay, fine. Make sense. Here's an example of an execution graph. We're using this flow in our current auto dev, long lived coding agents flow. If a user sends a message, is the user mentioning or referencing GitHub repo? So, if so, have we indexed repo? If not, build the index. If yes, just go and query the index for context and then pass that to the LLM. That's one example of an execution graph. It's like one particular set of routes that can govern the agent. If you've used our V2 open agents, you can see how powerful it is to just have like one agent with access to 12 different tools. We've gotten a lot of really good feedback from people who've played with this enough to get it. Like, holy shit, this actually works to help me code really freaking fast because this has direct access to your code base and can make intelligent changes. But there's no reason that any agent should have access to only 12 tools or that you, the user, need to be like manually selecting. There's a lot of automation that can be added here because ideally, the user doesn't need to choose any of this stuff. They're just like talking to the interface and they're getting results back. So that's an example execution graph. And then example knowledge graph would be, here's just us kind of playing around with graphing files in a code repo along with the connections between them like the imports, definitions, blah, blah, blah. Here's that applied to a PDF with too much granularity, all those like our nodes around the circle. And the idea behind connecting all of the knowledge of a code base is to enable the rag process where you're feeding context by your code base to the model. If you've used cursor or any of these other tools, aider where you have to like manually specify the files, like that's even like, why are you needing to manually specify the files? The all that knowledge is in the repo. It's just not organized or the connections that are there are not like being properly serviced. And so just taking this idea from the Microsoft LOL research group graph rag, graph rag, they kind of do this over PDFs and like text documents, is basically combining graphs with retrieval augmented generation. I haven't seen anyone apply this to code bases. We are doing that. If you check back two or so videos in this series, we've got a kind of an introductory walk through to yeah code base indexing via graph rag. We just did like a very basic kind of chatting with our V2 proof of concept. And we are almost ready to show off a demo of like using that, seeing that in our little new little dashboard. Oh, that we're building here. We've got like 236 passing tests for this portal app. Where we got that. Anyways, so let's talk briefly about our code bases. So we have a new mono repo. There's open source. We've open sourced our current app at openages.com by the way that's on V2 there. And then in this code base, we're going to be open sourcing under creative commons, both the new mobile app forthcoming as well as the relay, which is a custom nost, nost relay and nip90 service provider will go soon into more details in other videos about why that's important. So those are both open source and then we've got a private client app that we are starting to sign businesses up to. And you know, I didn't want to go the business route right off the bat because I really want to build the consumer platform. But the problem is that we need to identify paid usage because we have to pay the bills. So it's like, it's hard to reason about solving problems that people only value at $10 a month. And like if we do this right and we can like literally create coding agents for people that should be something that people are willing to pay $1,000 a month for because you're talking about replacing or dramatically augmenting existing development teams. So we'll be gradually opening up access to this hopefully over the next month in the meantime if you are a developer or looking to hire developers. If you run a company, yeah, you're going to want that. So part of the idea here is we want to be able to represent graphs in a decentralized and open way so that anyone can contribute to them. And we're going to be using Goster for that. And then for the payments, we're going to be using the Bitcoin Lightning Network, which is the obvious payments network for machine to machine payments. And we'll be using either L402, which is the kind of HTTP402 protocol from Lightning Labs has fleshed a lot of this out. And we'll maybe be doing some combination of that with this new NOS specification, NIP 69. This is kind of like a drop-in replacement for LNURL. More NOS native and doesn't rely on DNS something, something. So check out that video. So the idea there is that instead of all these different companies building like singular agents that do one thing, like where is the... Open agent substrate where you can take advantage of all of the agents that other people have built. And if someone has built the best rag algorithm, the best code-based indexer, the best whatever it is, and you can kind of pull in that set of execution and or knowledge graphs. And then you just, you know, some of the payments from your agent just like streamed to whoever contributed that, that enables a true marketplace of the sort of building blocks for agents. So to borrow a line from Tiny Grad who's commoditizing the peda flop, I kind of came up with commoditizing the pull request, but really it's more than that because we're not just organizing the building blocks of agents. So I think that that graph structure is going to be crucial for that. And then what this enables is, you know, once we have a lot of these agents, we have like data flowing through this. You know, you've got people like Mark Zuckerberg and others saying how in order to get to the next wave of truly useful compound AI systems or agents, we're going to need really good data flows or data sets. Like we're going to have all sorts of amazing data sets generated through these agents that can train next generations of agents. And because we're like building this streaming money into our platform, like we're already set up to compensate people, you find people proportional to how you contribute. So if you contribute to some algorithm that other people use, you'll get paid. If you generate data that people want to use, you get paid. If you're just good at shit posting and like you drive some sales on Twitter, you get a stream of permanent fucking referral income on the backend. So to come back to the beginning here, how are we building the best agents? Because we're going to be building on and with and for open source. And we're going to be paying people to contribute to our massive fucking open agents swarm.

## Timestamped Transcript

[0:01 - 0:03] So here's the plan.

[0:04 - 0:06] Step one, we build the best agents.

[0:06 - 0:07] Easy.

[0:07 - 0:08] We're pretty much there.

[0:08 - 0:14] Two, we sell the agents and we pay you a cut, proportional to how you help.

[0:16 - 0:20] Maybe you'll be incentivized to help us build better agents.

[0:21 - 0:22] Sell them more.

[0:22 - 0:23] You get a large river cut.

[0:24 - 0:29] And then we're going to repeat one and two until World Conquest.

[0:29 - 0:29] Is this clear?

[0:30 - 0:31] Hopefully, this is quick.

[0:32 - 0:34] Okay, let's dig in a little bit.

[0:34 - 0:40] So the idea is that we are building agents out of graphs.

[0:40 - 0:43] This is not a unique concept.

[0:45 - 0:51] However, I haven't seen any projects combine two types of graphs, both knowledge graphs

[0:51 - 0:52] and execution graphs.

[0:52 - 0:55] You've got like, Langchain has a Lang graph thing.

[0:55 - 1:00] There's a bunch of people building agents out of graphs representing execution steps,

[1:00 - 1:01] his nose and edges.

[1:01 - 1:02] Okay, fine.

[1:02 - 1:03] Make sense.

[1:04 - 1:06] Here's an example of an execution graph.

[1:06 - 1:12] We're using this flow in our current auto dev, long lived coding agents flow.

[1:13 - 1:19] If a user sends a message, is the user mentioning or referencing GitHub repo?

[1:19 - 1:23] So, if so, have we indexed repo?

[1:23 - 1:24] If not, build the index.

[1:24 - 1:30] If yes, just go and query the index for context and then pass that to the LLM.

[1:31 - 1:34] That's one example of an execution graph.

[1:34 - 1:38] It's like one particular set of routes that can govern the agent.

[1:39 - 1:46] If you've used our V2 open agents, you can see how powerful it is to just have like one

[1:46 - 1:50] agent with access to 12 different tools.

[1:50 - 1:55] We've gotten a lot of really good feedback from people who've played with this enough

[1:55 - 1:55] to get it.

[1:56 - 2:00] Like, holy shit, this actually works to help me code really freaking fast because this

[2:00 - 2:04] has direct access to your code base and can make intelligent changes.

[2:05 - 2:13] But there's no reason that any agent should have access to only 12 tools or that you, the

[2:13 - 2:15] user, need to be like manually selecting.

[2:15 - 2:19] There's a lot of automation that can be added here because ideally, the user doesn't

[2:19 - 2:20] need to choose any of this stuff.

[2:20 - 2:26] They're just like talking to the interface and they're getting results back.

[2:28 - 2:30] So that's an example execution graph.

[2:31 - 2:36] And then example knowledge graph would be, here's just us kind of playing around with

[2:38 - 2:46] graphing files in a code repo along with the connections between them like the imports,

[2:47 - 2:49] definitions, blah, blah, blah.

[2:50 - 2:56] Here's that applied to a PDF with too much granularity, all those like our nodes around

[2:56 - 2:56] the circle.

[3:05 - 3:13] And the idea behind connecting all of the knowledge of a code base is to enable the

[3:13 - 3:20] rag process where you're feeding context by your code base to the model.

[3:20 - 3:24] If you've used cursor or any of these other tools, aider where you have to like manually

[3:24 - 3:30] specify the files, like that's even like, why are you needing to manually specify the files?

[3:30 - 3:32] The all that knowledge is in the repo.

[3:32 - 3:37] It's just not organized or the connections that are there are not like being properly

[3:37 - 3:37] serviced.

[3:38 - 3:49] And so just taking this idea from the Microsoft LOL research group graph rag, graph rag,

[3:49 - 3:56] they kind of do this over PDFs and like text documents, is basically combining graphs

[3:56 - 3:57] with retrieval augmented generation.

[4:01 - 4:03] I haven't seen anyone apply this to code bases.

[4:03 - 4:05] We are doing that.

[4:05 - 4:11] If you check back two or so videos in this series, we've got a kind of an introductory walk

[4:11 - 4:16] through to yeah code base indexing via graph rag.

[4:16 - 4:21] We just did like a very basic kind of chatting with our V2 proof of concept.

[4:21 - 4:29] And we are almost ready to show off a demo of like using that, seeing that in our little

[4:29 - 4:30] new little dashboard.

[4:31 - 4:33] Oh, that we're building here.

[4:33 - 4:38] We've got like 236 passing tests for this portal app.

[4:39 - 4:40] Where we got that.

[4:40 - 4:46] Anyways, so let's talk briefly about our code bases.

[4:47 - 4:49] So we have a new mono repo.

[4:50 - 4:51] There's open source.

[4:51 - 4:59] We've open sourced our current app at openages.com by the way that's on V2 there.

[5:05 - 5:09] And then in this code base, we're going to be open sourcing under creative commons,

[5:09 - 5:14] both the new mobile app forthcoming as well as the relay, which is a custom nost, nost

[5:14 - 5:20] relay and nip90 service provider will go soon into more details in other videos about

[5:20 - 5:21] why that's important.

[5:22 - 5:28] So those are both open source and then we've got a private client app that we are starting

[5:28 - 5:32] to sign businesses up to.

[5:35 - 5:41] And you know, I didn't want to go the business route right off the bat because I really want

[5:41 - 5:42] to build the consumer platform.

[5:42 - 5:49] But the problem is that we need to identify paid usage because we have to pay the bills.

[5:49 - 5:55] So it's like, it's hard to reason about solving problems that people only value at $10

[5:55 - 5:56] a month.

[5:57 - 6:01] And like if we do this right and we can like literally create coding agents for people

[6:01 - 6:05] that should be something that people are willing to pay $1,000 a month for because you're

[6:05 - 6:09] talking about replacing or dramatically augmenting existing development teams.

[6:11 - 6:16] So we'll be gradually opening up access to this hopefully over the next month in the meantime

[6:16 - 6:19] if you are a developer or looking to hire developers.

[6:21 - 6:23] If you run a company, yeah, you're going to want that.

[6:27 - 6:34] So part of the idea here is we want to be able to represent graphs in a decentralized

[6:34 - 6:39] and open way so that anyone can contribute to them.

[6:39 - 6:41] And we're going to be using Goster for that.

[6:42 - 6:46] And then for the payments, we're going to be using the Bitcoin Lightning Network, which

[6:46 - 6:49] is the obvious payments network for machine to machine payments.

[6:51 - 7:03] And we'll be using either L402, which is the kind of HTTP402 protocol from Lightning

[7:03 - 7:05] Labs has fleshed a lot of this out.

[7:07 - 7:14] And we'll maybe be doing some combination of that with this new NOS specification, NIP

[7:14 - 7:14] 69.

[7:15 - 7:18] This is kind of like a drop-in replacement for LNURL.

[7:19 - 7:24] More NOS native and doesn't rely on DNS something, something.

[7:24 - 7:26] So check out that video.

[7:30 - 7:39] So the idea there is that instead of all these different companies building like singular

[7:39 - 7:44] agents that do one thing, like where is the...

[7:45 - 7:52] Open agent substrate where you can take advantage of all of the agents that other people

[7:52 - 7:52] have built.

[7:53 - 7:59] And if someone has built the best rag algorithm, the best code-based indexer, the best whatever

[7:59 - 8:07] it is, and you can kind of pull in that set of execution and or knowledge graphs.

[8:07 - 8:12] And then you just, you know, some of the payments from your agent just like streamed to whoever

[8:13 - 8:21] contributed that, that enables a true marketplace of the sort of building blocks for agents.

[8:23 - 8:35] So to borrow a line from Tiny Grad who's commoditizing the peda flop, I kind of came up with

[8:35 - 8:41] commoditizing the pull request, but really it's more than that because we're not just

[8:41 - 8:43] organizing the building blocks of agents.

[8:45 - 8:48] So I think that that graph structure is going to be crucial for that.

[8:50 - 8:54] And then what this enables is, you know, once we have a lot of these agents, we have like

[8:54 - 8:55] data flowing through this.

[8:55 - 8:59] You know, you've got people like Mark Zuckerberg and others saying how in order to get to

[8:59 - 9:05] the next wave of truly useful compound AI systems or agents, we're going to need really

[9:05 - 9:07] good data flows or data sets.

[9:07 - 9:11] Like we're going to have all sorts of amazing data sets generated through these agents

[9:11 - 9:13] that can train next generations of agents.

[9:14 - 9:19] And because we're like building this streaming money into our platform, like we're already

[9:19 - 9:27] set up to compensate people, you find people proportional to how you contribute.

[9:29 - 9:32] So if you contribute to some algorithm that other people use, you'll get paid.

[9:32 - 9:35] If you generate data that people want to use, you get paid.

[9:36 - 9:40] If you're just good at shit posting and like you drive some sales on Twitter, you get

[9:41 - 9:45] a stream of permanent fucking referral income on the backend.

[9:45 - 9:51] So to come back to the beginning here, how are we building the best agents?

[9:52 - 9:57] Because we're going to be building on and with and for open source.

[9:57 - 10:03] And we're going to be paying people to contribute to our massive fucking open agents swarm.


## Notes

This transcript was automatically generated using OpenAI Whisper (base model) from the video at https://x.com/OpenAgentsInc/status/1834087017132511419.

Transcription accuracy may vary. Please refer to the original video for definitive content.
