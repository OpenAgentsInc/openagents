# OpenAgents Video Series - Episode 166

## Video Information

- **Title**: OpenAgents ⚡ - Episode 166: OpenAI Delenda Est  OpenAI calls on government to ban De...
- **Creator**: OpenAgents ⚡
- **Duration**: 6:54
- **Published**: March 14, 2025
- **URL**: https://x.com/OpenAgentsInc/status/1900430864623768056
- **Transcribed**: June 07, 2025
- **Language**: en

## Full Transcript

TechCrunch today, OpenAI calls deep-seek state controlled calls for bands on PRC-produced models. OpenAI is much more deep-state controlled than deep-seek is PRC controlled. Hypocrates, regulatory capture. So I got two things to say. One is, cartago d'alenda est. Carthage must be destroyed. OpenAI must be destroyed. Number two, we made a meme. Stop using deep-seek. We're going to use deep-seek even harder now. So I've just added deep-seek R1, the full one, to open agents for pro users. This is hosted via OpenRouter. And it's hosted on some of these. I think these are all US-based or I don't really know. I'm trying to base the ones in here. I don't think our data is collecting. The reasoning models cannot use tools, but you can use them in conjunction with models that can. We could go into a historical chat. I've got to broke something with the chat history. Let's do a new chat. Let's look through the V4 repo for deep-seek-related code. And summarize in two paragraphs. The best model for tool use of this batch is 3.5 sonnet. Maybe 3.7 sonnet is better at something. But 3.5 is definitely the most reliable. Okay, so we did a nice little grip there. Let's see if deep-seek R1 can do anything interesting with that. I'm going to analyze the above and suggest next steps for how best to leverage deep-seek R1's power. Come on. I wonder if it's passing all 81 matches? Let's see what happens. Ooh. No, don't use tools. Just analyze what you see in our history. Interesting. Okay, let me start by understanding the user request. They want me to analyze the previous conversation history where they asked about deep-seek-related code. The user's repo is several references to deep-seek R1, especially the handling of boba. Based on the deep-seek-related code and documentation found in the V4 repo, here are strategic next steps. Reasoning centric workflows. Leverage at scale for COD analysis tests like architectural pattern detection, multi-separ factory suggestions, cross file, dependency mapping. Disclination pipeline optimization. Implement automated benchmarking between R1 base and distilled variance, Quen Lama. Create AB testing framework for distilled model performance on. That's actually a great idea. If there's some things where the distilled models can be fine enough if we're just mass tagging or labeling stuff. Don't need the full one, but yeah. Hybrid orchestration. Develop model routing logic that combines R1s reasoning with smaller models to execution. Yeah. S-sensorship workaround. Folks, this is R1. We're not using any special one. It's just one from open router. So I'm pretty sure this is just the one like hot off the presses of deep-seek in PRC. Ooh. Sam Altman, you fucking... It's like, hey, you should implement some censorship workaround. Okay. Performance monitoring, community integration, build MCP compatible adapters for R1 to tool bridging, reasoning trace visualization, collaborative reasoning sessions. This leverages R1's scale while respecting its tool limitations through intelligent orchestration and distillation monitoring. This is amazing. Okay. Lastly, hopefully the closed AI labs fail in their attempted regulatory capture. And that y'all, this is me responding to AI's R-sacks, y'all can balance across both dimensions, US versus China, and open versus closed. Seeing way too many calls for closing a strict AI, further wrong approach. USA must lead on open source AI or else. Okay. I'm on team America, because I'm American. I'm also on team open. So in that way, I consider deep-seek and when fang and everything, they're all, we're on the same team. We're on team open. America needs to be on team open. It should be. If they're going to be falling for this regulatory capture ploy of Altman and Anthropic and the closed AI people, then we're going to have some problems. See you soon.

## Timestamped Transcript

[0:00 - 0:06] TechCrunch today, OpenAI calls deep-seek state controlled calls for bands on

[0:06 - 0:09] PRC-produced models.

[0:19 - 0:23] OpenAI is much more deep-state controlled than deep-seek is PRC controlled.

[0:28 - 0:30] Hypocrates, regulatory capture.

[0:37 - 0:41] So I got two things to say. One is,

[0:43 - 0:47] cartago d'alenda est. Carthage must be destroyed.

[0:50 - 0:51] OpenAI must be destroyed.

[0:55 - 0:57] Number two, we made a meme.

[1:03 - 1:08] Stop using deep-seek. We're going to use deep-seek even harder now.

[1:10 - 1:13] So I've just added deep-seek R1, the full one,

[1:15 - 1:17] to open agents for pro users.

[1:24 - 1:27] This is hosted via OpenRouter.

[1:32 - 1:39] And it's hosted on some of these. I think these are all US-based or I don't really know.

[1:39 - 1:41] I'm trying to base the ones in here.

[1:42 - 1:46] I don't think our data is collecting.

[1:50 - 1:55] The reasoning models cannot use tools, but you can use them in conjunction with models that can.

[1:57 - 2:00] We could go into a historical chat.

[2:02 - 2:05] I've got to broke something with the chat history.

[2:06 - 2:07] Let's do a new chat.

[2:11 - 2:17] Let's look through the V4 repo for deep-seek-related code.

[2:21 - 2:24] And summarize in two paragraphs.

[2:27 - 2:32] The best model for tool use of this batch is 3.5 sonnet.

[2:33 - 2:35] Maybe 3.7 sonnet is better at something.

[2:38 - 2:40] But 3.5 is definitely the most reliable.

[2:41 - 2:43] Okay, so we did a nice little grip there.

[2:50 - 2:52] Let's see if deep-seek R1 can do anything interesting with that.

[2:53 - 3:09] I'm going to analyze the above and suggest next steps for how best to leverage deep-seek R1's power.

[3:14 - 3:15] Come on.

[3:15 - 3:20] I wonder if it's passing all 81 matches?

[3:21 - 3:21] Let's see what happens.

[3:28 - 3:29] Ooh.

[3:34 - 3:36] No, don't use tools.

[3:37 - 3:40] Just analyze what you see in our history.

[3:44 - 3:44] Interesting.

[3:45 - 3:48] Okay, let me start by understanding the user request.

[3:49 - 3:53] They want me to analyze the previous conversation history where they asked about deep-seek-related code.

[3:54 - 3:57] The user's repo is several references to deep-seek R1, especially the handling of boba.

[3:59 - 4:06] Based on the deep-seek-related code and documentation found in the V4 repo, here are strategic next steps.

[4:07 - 4:08] Reasoning centric workflows.

[4:08 - 4:15] Leverage at scale for COD analysis tests like architectural pattern detection, multi-separ factory suggestions, cross file, dependency mapping.

[4:18 - 4:19] Disclination pipeline optimization.

[4:20 - 4:25] Implement automated benchmarking between R1 base and distilled variance, Quen Lama.

[4:28 - 4:31] Create AB testing framework for distilled model performance on.

[4:32 - 4:33] That's actually a great idea.

[4:35 - 4:41] If there's some things where the distilled models can be fine enough if we're just mass tagging or labeling stuff.

[4:42 - 4:43] Don't need the full one, but yeah.

[4:45 - 4:46] Hybrid orchestration.

[4:46 - 4:50] Develop model routing logic that combines R1s reasoning with smaller models to execution.

[4:50 - 4:50] Yeah.

[4:52 - 4:54] S-sensorship workaround.

[5:00 - 5:02] Folks, this is R1.

[5:02 - 5:06] We're not using any special one. It's just one from open router.

[5:06 - 5:10] So I'm pretty sure this is just the one like hot off the presses of deep-seek in PRC.

[5:11 - 5:12] Ooh.

[5:13 - 5:15] Sam Altman, you fucking...

[5:17 - 5:21] It's like, hey, you should implement some censorship workaround.

[5:21 - 5:21] Okay.

[5:23 - 5:31] Performance monitoring, community integration, build MCP compatible adapters for R1 to tool bridging,

[5:31 - 5:35] reasoning trace visualization, collaborative reasoning sessions.

[5:35 - 5:43] This leverages R1's scale while respecting its tool limitations through intelligent orchestration and distillation monitoring.

[5:44 - 5:45] This is amazing.

[5:45 - 5:46] Okay.

[5:47 - 5:48] Lastly,

[5:55 - 5:59] hopefully the closed AI labs fail in their attempted regulatory capture.

[6:00 - 6:03] And that y'all, this is me responding to AI's R-sacks,

[6:04 - 6:09] y'all can balance across both dimensions, US versus China, and open versus closed.

[6:09 - 6:13] Seeing way too many calls for closing a strict AI, further wrong approach.

[6:13 - 6:15] USA must lead on open source AI or else.

[6:15 - 6:16] Okay.

[6:16 - 6:18] I'm on team America, because I'm American.

[6:20 - 6:21] I'm also on team open.

[6:23 - 6:28] So in that way, I consider deep-seek and when fang and everything,

[6:28 - 6:30] they're all, we're on the same team. We're on team open.

[6:32 - 6:33] America needs to be on team open.

[6:34 - 6:34] It should be.

[6:35 - 6:47] If they're going to be falling for this regulatory capture ploy of Altman and Anthropic and the closed AI people,

[6:48 - 6:50] then we're going to have some problems.

[6:52 - 6:53] See you soon.


## Notes

This transcript was automatically generated using OpenAI Whisper (base model) from the video at https://x.com/OpenAgentsInc/status/1900430864623768056.

Transcription accuracy may vary. Please refer to the original video for definitive content.
