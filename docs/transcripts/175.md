# OpenAgents Video Series - Episode 175

## Video Information

- **Title**: Episode 175: Commander v0.0.1
- **Creator**: OpenAgents âš¡
- **Duration**: 1:46
- **Published**: May 15, 2025
- **URL**: https://x.com/OpenAgentsInc/status/1923126952870703509
- **Transcribed**: June 07, 2025
- **Language**: en

## Full Transcript

Live now is the very first build of our Commander app. This is our new flagship product, a desktop app through which you will buy and sell compute for our new compute network as well as build and sell agents. And this is just a very early dev build intended for developers to sanity check that the connection to Olamma works on people's computers other than mine. So I'm going to say hello world and this is going to stream a chat from my local Olamma which has Gemma 3 a very good small model from Google loaded and you can just have a little simple conversation here but this is all running locally. This is important because this inference is what we are soon going to be connecting to the broader market. So other people can be paying Bitcoin to run inference on your machine then you just give them the result and this will just be in a simple desktop that app that you can run. And then we'll do some fun things here with building the actual agents and visualizing them like you saw in the last few videos about the sync edge and all that stuff we're going to pull that in as well as a built-in Bitcoin wallet here. So again not really like meant for consumption by a broad audience mostly just to kind of test this out and we'll ask people in our discord to help test this out but this is on the new Commander repo here 100% open source under releases the 0.0.1 you can install this by following the local development instructions you clone down the repo you run PNPM I start blah blah blah if you get stuck on any part of this you can hit us up in the discord. All right first of many builds to come see us in

## Timestamped Transcript

[0:00 - 0:05] Live now is the very first build of our Commander app. This is our new flagship

[0:05 - 0:09] product, a desktop app through which you will buy and sell compute for our new

[0:09 - 0:14] compute network as well as build and sell agents. And this is just a very early

[0:14 - 0:19] dev build intended for developers to sanity check that the connection to

[0:19 - 0:24] Olamma works on people's computers other than mine. So I'm going to say hello

[0:24 - 0:29] world and this is going to stream a chat from my local Olamma which has Gemma

[0:29 - 0:35] 3 a very good small model from Google loaded and you can just have a little

[0:35 - 0:39] simple conversation here but this is all running locally. This is important

[0:39 - 0:43] because this inference is what we are soon going to be connecting to the broader

[0:43 - 0:49] market. So other people can be paying Bitcoin to run inference on your machine

[0:49 - 0:53] then you just give them the result and this will just be in a simple desktop

[0:53 - 0:57] that app that you can run. And then we'll do some fun things here with building

[0:57 - 1:02] the actual agents and visualizing them like you saw in the last few videos

[1:02 - 1:05] about the sync edge and all that stuff we're going to pull that in as well as a

[1:05 - 1:11] built-in Bitcoin wallet here. So again not really like meant for consumption by

[1:11 - 1:16] a broad audience mostly just to kind of test this out and we'll ask people in

[1:16 - 1:22] our discord to help test this out but this is on the new Commander repo here

[1:22 - 1:30] 100% open source under releases the 0.0.1 you can install this by following

[1:30 - 1:35] the local development instructions you clone down the repo you run PNPM I start

[1:35 - 1:40] blah blah blah if you get stuck on any part of this you can hit us up in the

[1:40 - 1:46] discord. All right first of many builds to come see us in


## Notes

This transcript was automatically generated using OpenAI Whisper (base model) from the video at https://x.com/OpenAgentsInc/status/1923126952870703509.

Transcription accuracy may vary. Please refer to the original video for definitive content.
