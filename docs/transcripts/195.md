# OpenAgents Video Series - Episode 195

## Video Information

- **Title**: OpenAgents - Episode 195: Designing 10x Better  How can our product become â€˜10x be... #1
- **Creator**: OpenAgents
- **Duration**: 8:21
- **Published**: November 11, 2025
- **URL**: https://x.com/OpenAgentsInc/status/1988293182942228779
- **Transcribed**: December 16, 2025
- **Language**: en

This transcript was automatically generated using Whisper (base).

## Full Transcript

They say new products should be a 10X improvement over what came before. So what does a 10X improvement over Claude code over code X look like? Overcurse from look like. Here's 10 areas that we think make sense. Let's go through each of them. Ditch the T UI. Okay, these janky fake terminals that everyone is just copying off of Claude code because that's what they did. Where you're like pretending you're a developer and cool in the terminal. Where there's no reason to be in the terminal because you're not using like actual terminal commands. There's nothing about the T UI that you couldn't also do from a desktop app. Give me a sidebar. Get rid of this screen flicker. I can't copy paste properly. All this stuff that's already been solved by like actual good you want. Give me a chat GPT style desktop app with like history on the side. Some widgets down here if I want to manage long running agents like. Why does that not exist? Keep it simple. Number two, go mobile. Okay, I want to have a desktop app that sinks to my mobile phone. So give me the exact same flow, the same UI components, the same controls. If I'm at home doing my usual workflow, let me have the desktop app. But if I want to go to the store, let me be able to do all of the same stuff for my mobile phone. Okay, we figured out how to do that. See the previous episodes. Some people say like, oh, use, you know, you know, what about open a eyes codex? You can use it on the web. You can. Have you tried it codex? Watch this. Oh, get started. Codex web takes you to the mobile app. You can't use it from the mobile app. There's no codex option here. So are these $500 billion companies or what? No, they need to start up, I guess, to make an actual freaking out. Let's do that. Code overnight. I want to be able to let stuff run overnight and not in this hilarious. Horrible way that you have to do with codex. Oh, yeah, it fixes thousands of overnight. How do you actually do that right now? You have to just queue up, continue, continue, continue, continue. Like, and it's, it's so dumb. So yeah, but hey, this is an idea for a new feature scheduled prompts. In three hours, do this in four hours, do this in six hours after a limit resets, do this. Or make it even more intelligent. Like give the agents a little bit of discretion about like checking to see what's been done or what's not to advance your kind of higher level objective of adding more tests or whatever. I did like a basic version of this last night. You can see here, I like set up an orchestration to run overnight. It ran, made like a few, it's basically like a glorified Cron with different kind of like sub agents. It's kind of orchestrated to different codex things. You can read the audit of what went well and not without. But I'm going to iterate on this and in a very soon version, we'll have this out. Okay. CLI agents is sub agents. You know how Clawed will like delegate to a sub agent. And it will kind of like have its own context window when it like issues a task. That's what it's doing. Why can't I just have my main open agents chat delegate to codex delegates to Clawed code like in the context of a single conversation with all of that context available to agents who want it. So here is like, you know, a tool call that my Apple foundation model chat model, which is basically a little glorified router that we built with a few basic tool calls where it can delegate to codex. It's going to delegate to Clawed code. It can have them like talk with each other whole lot of design space to explore there. History and memory like, yeah, just give me the sidebar with the chat so I can actually see like what's already happened. And like, let me easily reference past chats like in this other chat or let it retrieve it itself. There should be a local SQL like database where it's able to be like, oh yeah, like, you know, three days ago, we discussed this. I saw that we came to this conclusion right now of the like Clawed code and codex conversations are just in these like giant JSON blobs, not optimized for discovery at all. Has to free interrupt all the debate and like, hoops, you have to jump through to get MCP working. People, oh yeah, no, yeah, the, so the tool registry definitions are too long. So now you need to like create an API from it, but then you need to like create a script that'll consume that or rewrite. Like, stop it. Stop, stop making me think in those terms. Like if you're in a app, you should be able to like easily pull in integrations. I'll figure all this shit out, but like make it available to other people that they don't have to like go through all these insane hoops. Embrace open source. The leader here in my view on the app side for coding agents is open code. They've built a massive community of contributors. They've got like very healthy community people actually building like props to codex for being open source. I think that's cool, but like embracing it and like having a whole bunch of people contribute and add to it is great. I just want to do that kind of thing, but for our more opinionated, agentic flow here with open agents. Okay, local swarm and cloud inference. If I've got a bunch of compute on my computer, if I've got stuff that my foundation models like M2 chip is able to do for summarization for updating title summaries, like use your local compute where it's needed. Let's say that there's a whole bunch of other people that have free compute. Hey, maybe I'm able to like pay them and like use that swarm compute more on that in a second. And then cloud like, yeah, obviously the we're steering codex and cloud code, which are cloud based agents, but like maybe I do want to like go hit GROC GROQ for they've got let's say they put Kimmy's new thinking model up with that and I want to like use that like there should be a mix of inference possibilities. People should be able to like mix and match based on their their cost preferences or have that done automatically after setting some preferences. Compute fracking. Okay. You you have compute available to you that you are not doing anything with. Why are you not doing anything with it? Okay. You've got an M2 chip that's just sitting there. Are you using that compute right now to run agents? No, then you're wasting electricity. Well, there just hasn't been any software for you to run that on your computer. It was just able to like have agents run around the clock or if you don't have any economically sensible use cases, why can't you sell that to your neighbor who will pay you a tiny fraction of a dollar tiny fraction of a Bitcoin to use your compute? See episode I don't know. 140. We did some compute marketplace stuff. We're going to be folding that back into this. Sam Altman and all these people talking about oh, we're bought on a buy compute. Okay. You've got every fricking device. You know, the two billion Apple devices. What percentage of those are iOS 16 and can now run or 26 and can now run the on device foundation models. Where is it? CR recent tweets about yeah, yeah, so what percentage of these global AI workloads are going to run on Apple Silicon? The big labs are not going to innovate in this direction because they are now like in the Nvidia, drinking the Nvidia cool aid, but we have no such limitations. So just remember compute fracking. You heard it here first. Revenue sharing. Now to anyone who's like, Chris, why are you spilling all these all the juice here? The sauce you're giving it all away. The alpha you're just leaking it out here. No, no, no. We're here to build network effects. So we're going to be open source. We're going to be building in public. We're going to monetize this and how we're going to be building the biggest network is because we're going to be getting developers paid by building an actual marketplace. Hey developer, and this is going to solve so many of the coordination problems around like YMCPs, suck in implementation because no one has an actual financial incentive to maintain them or make them good. Hey developers, you wrote an agent plug in. Would you like to put that in a registry and get paid a tiny fraction of a cent every time someone uses it? How do you do that? Built in Bitcoin wallet. Oh, have you built this already? We built this already. Like that's the benefit of having been around for two years and on episode 190. We've built all of this stuff in prototype form and now we're just mushing it into a single product now that we've got the sort of agent code and go to market piece figured out. Okay, what would you add to this list? Please tell us. We are aiming to get at least basic versions of every one of these 10 upgrades in place by the end of this year, six weeks from now. What would you add to it? See you soon.

## Timestamped Transcript

[00:00 - 00:04] They say new products should be a 10X improvement over what came before.
[00:04 - 00:10] So what does a 10X improvement over Claude code over code X look like? Overcurse from look like.
[00:11 - 00:13] Here's 10 areas that we think make sense.
[00:13 - 00:15] Let's go through each of them.
[00:15 - 00:17] Ditch the T UI.
[00:17 - 00:22] Okay, these janky fake terminals that everyone is just copying off of Claude code because that's what they did.
[00:22 - 00:25] Where you're like pretending you're a developer and cool in the terminal.
[00:25 - 00:30] Where there's no reason to be in the terminal because you're not using like actual terminal commands.
[00:30 - 00:34] There's nothing about the T UI that you couldn't also do from a desktop app.
[00:34 - 00:37] Give me a sidebar. Get rid of this screen flicker.
[00:37 - 00:38] I can't copy paste properly.
[00:38 - 00:42] All this stuff that's already been solved by like actual good you want.
[00:42 - 00:50] Give me a chat GPT style desktop app with like history on the side.
[00:50 - 00:53] Some widgets down here if I want to manage long running agents like.
[00:54 - 00:55] Why does that not exist?
[00:55 - 00:56] Keep it simple.
[00:57 - 01:00] Number two, go mobile.
[01:00 - 01:05] Okay, I want to have a desktop app that sinks to my mobile phone.
[01:05 - 01:10] So give me the exact same flow, the same UI components, the same controls.
[01:11 - 01:15] If I'm at home doing my usual workflow, let me have the desktop app.
[01:16 - 01:20] But if I want to go to the store, let me be able to do all of the same stuff for my mobile phone.
[01:20 - 01:22] Okay, we figured out how to do that.
[01:22 - 01:23] See the previous episodes.
[01:25 - 01:30] Some people say like, oh, use, you know, you know, what about open a eyes codex?
[01:30 - 01:31] You can use it on the web.
[01:31 - 01:32] You can.
[01:32 - 01:34] Have you tried it codex?
[01:34 - 01:34] Watch this.
[01:35 - 01:36] Oh, get started.
[01:36 - 01:40] Codex web takes you to the mobile app.
[01:40 - 01:41] You can't use it from the mobile app.
[01:41 - 01:42] There's no codex option here.
[01:42 - 01:45] So are these $500 billion companies or what?
[01:45 - 01:47] No, they need to start up, I guess, to make an actual freaking out.
[01:47 - 01:48] Let's do that.
[01:48 - 01:49] Code overnight.
[01:50 - 01:54] I want to be able to let stuff run overnight and not in this hilarious.
[01:55 - 01:57] Horrible way that you have to do with codex.
[01:57 - 01:59] Oh, yeah, it fixes thousands of overnight.
[01:59 - 02:00] How do you actually do that right now?
[02:00 - 02:02] You have to just queue up, continue, continue, continue, continue.
[02:02 - 02:05] Like, and it's, it's so dumb.
[02:08 - 02:11] So yeah, but hey, this is an idea for a new feature scheduled prompts.
[02:11 - 02:15] In three hours, do this in four hours, do this in six hours after a limit resets, do this.
[02:17 - 02:18] Or make it even more intelligent.
[02:18 - 02:22] Like give the agents a little bit of discretion about like checking to see what's been done or what's not
[02:23 - 02:27] to advance your kind of higher level objective of adding more tests or whatever.
[02:27 - 02:28] I did like a basic version of this last night.
[02:28 - 02:32] You can see here, I like set up an orchestration to run overnight.
[02:32 - 02:36] It ran, made like a few, it's basically like a glorified Cron with different kind of like
[02:36 - 02:37] sub agents.
[02:37 - 02:39] It's kind of orchestrated to different codex things.
[02:39 - 02:41] You can read the audit of what went well and not without.
[02:41 - 02:45] But I'm going to iterate on this and in a very soon version, we'll have this out.
[02:45 - 02:45] Okay.
[02:46 - 02:48] CLI agents is sub agents.
[02:48 - 02:52] You know how Clawed will like delegate to a sub agent.
[02:52 - 02:56] And it will kind of like have its own context window when it like issues a task.
[02:56 - 02:56] That's what it's doing.
[02:57 - 03:03] Why can't I just have my main open agents chat delegate to codex delegates to Clawed code like in
[03:03 - 03:08] the context of a single conversation with all of that context available to agents who want it.
[03:09 - 03:15] So here is like, you know, a tool call that my Apple foundation model chat model,
[03:15 - 03:19] which is basically a little glorified router that we built with a few basic tool calls where it can
[03:19 - 03:20] delegate to codex.
[03:20 - 03:22] It's going to delegate to Clawed code.
[03:22 - 03:26] It can have them like talk with each other whole lot of design space to explore there.
[03:27 - 03:31] History and memory like, yeah, just give me the sidebar with the chat so I can actually see like
[03:31 - 03:33] what's already happened.
[03:33 - 03:37] And like, let me easily reference past chats like in this other chat or let it retrieve it itself.
[03:37 - 03:40] There should be a local SQL like database where it's able to be like, oh yeah, like,
[03:41 - 03:42] you know, three days ago, we discussed this.
[03:42 - 03:47] I saw that we came to this conclusion right now of the like Clawed code and codex conversations
[03:47 - 03:50] are just in these like giant JSON blobs, not optimized for discovery at all.
[03:51 - 03:57] Has to free interrupt all the debate and like, hoops, you have to jump through to get MCP working.
[03:57 - 04:01] People, oh yeah, no, yeah, the, so the tool registry definitions are too long.
[04:01 - 04:06] So now you need to like create an API from it, but then you need to like create a script that'll consume that or rewrite.
[04:06 - 04:08] Like, stop it.
[04:08 - 04:11] Stop, stop making me think in those terms.
[04:11 - 04:16] Like if you're in a app, you should be able to like easily pull in integrations.
[04:17 - 04:23] I'll figure all this shit out, but like make it available to other people that they don't have to like go through all these insane hoops.
[04:23 - 04:24] Embrace open source.
[04:25 - 04:30] The leader here in my view on the app side for coding agents is open code.
[04:30 - 04:32] They've built a massive community of contributors.
[04:32 - 04:37] They've got like very healthy community people actually building like props to codex for being open source.
[04:37 - 04:42] I think that's cool, but like embracing it and like having a whole bunch of people contribute and add to it is great.
[04:42 - 04:46] I just want to do that kind of thing, but for our more opinionated,
[04:46 - 04:48] agentic flow here with open agents.
[04:48 - 04:50] Okay, local swarm and cloud inference.
[04:51 - 05:03] If I've got a bunch of compute on my computer, if I've got stuff that my foundation models like M2 chip is able to do for summarization for updating title summaries, like use your local compute where it's needed.
[05:04 - 05:08] Let's say that there's a whole bunch of other people that have free compute.
[05:09 - 05:13] Hey, maybe I'm able to like pay them and like use that swarm compute more on that in a second.
[05:14 - 05:25] And then cloud like, yeah, obviously the we're steering codex and cloud code, which are cloud based agents, but like maybe I do want to like go hit GROC GROQ for they've got let's say they put
[05:25 - 05:31] Kimmy's new thinking model up with that and I want to like use that like there should be a mix of inference possibilities.
[05:32 - 05:37] People should be able to like mix and match based on their their cost preferences or have that done automatically after setting some preferences.
[05:39 - 05:40] Compute fracking. Okay.
[05:42 - 05:49] You you have compute available to you that you are not doing anything with.
[05:49 - 05:51] Why are you not doing anything with it? Okay.
[05:51 - 05:54] You've got an M2 chip that's just sitting there.
[05:54 - 05:59] Are you using that compute right now to run agents? No, then you're wasting electricity.
[05:59 - 06:02] Well, there just hasn't been any software for you to run that on your computer.
[06:02 - 06:08] It was just able to like have agents run around the clock or if you don't have any economically sensible use cases,
[06:08 - 06:16] why can't you sell that to your neighbor who will pay you a tiny fraction of a dollar tiny fraction of a Bitcoin to use your compute?
[06:17 - 06:22] See episode I don't know. 140. We did some compute marketplace stuff. We're going to be folding that back into this.
[06:23 - 06:26] Sam Altman and all these people talking about oh, we're bought on a buy compute.
[06:26 - 06:30] Okay. You've got every fricking device.
[06:30 - 06:36] You know, the two billion Apple devices. What percentage of those are iOS 16 and can now run or 26 and can now run the
[06:39 - 06:42] on device foundation models. Where is it?
[06:42 - 06:47] CR recent tweets about yeah, yeah, so what percentage of these global AI workloads are going to run on Apple Silicon?
[06:48 - 06:54] The big labs are not going to innovate in this direction because they are now like in the Nvidia,
[06:54 - 06:58] drinking the Nvidia cool aid, but we have no such limitations.
[07:00 - 07:04] So just remember compute fracking. You heard it here first. Revenue sharing.
[07:04 - 07:08] Now to anyone who's like, Chris, why are you spilling all these all the juice here?
[07:08 - 07:12] The sauce you're giving it all away. The alpha you're just leaking it out here. No, no, no.
[07:12 - 07:16] We're here to build network effects. So we're going to be open source. We're going to be building in public.
[07:17 - 07:22] We're going to monetize this and how we're going to be building the biggest network is because we're going
[07:22 - 07:28] to be getting developers paid by building an actual marketplace. Hey developer, and this is going
[07:28 - 07:33] to solve so many of the coordination problems around like YMCPs, suck in implementation because no one
[07:33 - 07:38] has an actual financial incentive to maintain them or make them good. Hey developers, you wrote an agent
[07:38 - 07:44] plug in. Would you like to put that in a registry and get paid a tiny fraction of a cent every time
[07:44 - 07:50] someone uses it? How do you do that? Built in Bitcoin wallet. Oh, have you built this already?
[07:50 - 07:54] We built this already. Like that's the benefit of having been around for two years and on episode 190.
[07:54 - 08:00] We've built all of this stuff in prototype form and now we're just mushing it into a single product now
[08:00 - 08:06] that we've got the sort of agent code and go to market piece figured out. Okay, what would you add
[08:06 - 08:12] to this list? Please tell us. We are aiming to get at least basic versions of every one of these 10
[08:12 - 08:20] upgrades in place by the end of this year, six weeks from now. What would you add to it? See you soon.
